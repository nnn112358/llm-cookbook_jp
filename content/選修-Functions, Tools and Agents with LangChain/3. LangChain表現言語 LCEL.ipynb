{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5f7fce3",
      "metadata": {
        "id": "c5f7fce3"
      },
      "source": [
        "# ç¬¬ä¸‰ç«  LangChain è¡¨è¾¾å¼è¯­è¨€ LangChain Expression Language\n",
        "\n",
        "åœ¨è¿™ä¸€ç« æˆ‘ä»¬ä¼šä»‹ç» LangChain Expression Languageï¼ˆæˆ–ç§°ä¸º LCELï¼‰ï¼Œè¢«ç§°ä¹‹ä¸º Langchain çš„è¡¨è¾¾å¼è¯­è¨€ã€‚LCEL æ˜¯ä¸€ç§æ–°çš„è¯­æ³•ï¼Œæ˜¯ LangChain å·¥å…·åŒ…çš„é‡è¦è¡¥å……ï¼Œä»–æœ‰è®¸å¤šä¼˜ç‚¹ï¼Œä½¿å¾—æˆ‘ä»¬å¤„ç† LangChain å’Œä»£ç†æ›´åŠ ç®€å•æ–¹ä¾¿ã€‚\n",
        "\n",
        "1. LCEL æä¾›äº†å¼‚æ­¥ã€æ‰¹å¤„ç†å’Œæµå¤„ç†æ”¯æŒï¼Œè¿™ä½¿å¾—ä»£ç å¤šåŠŸèƒ½åŒ–ï¼Œå¹¶ä¸”ä»£ç å¯ä»¥å¿«é€Ÿåœ¨ä¸åŒæœåŠ¡å™¨ä¸­åº”ç”¨å’Œè¿è¡Œã€‚\n",
        "    - å¼‚æ­¥ï¼šç¨‹åºå¯ä»¥åŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œè€Œä¸æ˜¯æŒ‰ç…§é¡ºåºä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æ‰§è¡Œ\n",
        "    - æ‰¹å¤„ç†ï¼šæ˜¯ä¸€ç§å°†ä¸€ç»„ä»»åŠ¡æˆ–æ•°æ®ä½œä¸ºä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œå¤„ç†çš„æ–¹æ³•ï¼Œè€Œä¸æ˜¯é€ä¸ªå¤„ç†\n",
        "    - æµå¼å¤„ç†ï¼šç†æ˜¯ä¸€ç§è¿ç»­å¤„ç†æ•°æ®çš„æ–¹æ³•ï¼Œæ•°æ®ä¼šæŒç»­ä¸æ–­åœ°è¿›å…¥ç³»ç»Ÿå¹¶è¢«å¤„ç†ï¼Œæµå¼å¤„ç†èƒ½å¤Ÿåœ¨æ•°æ®åˆ°è¾¾æ—¶ç«‹å³è¿›è¡Œå¤„ç†ï¼Œå¹¶ä¸”å¯ä»¥ä»¥æŒç»­ä¸”ä½å»¶è¿Ÿçš„æ–¹å¼å¤„ç†æ•°æ®ã€‚\n",
        "\n",
        "2. LCEL æ‹¥æœ‰ fallbacks æªæ–½ï¼Œä¹Ÿå«å›é€€å®‰å…¨æœºåˆ¶ï¼Œæœ‰æ—¶LLMå¾—åˆ°çš„ç»“æœä¸å¯æ§ï¼Œè¿™æ—¶ä½ å¯ä»¥å°†ç»“æœè¿›è¡Œå›é€€ï¼Œç”šè‡³å¯ä»¥é™„åŠ åˆ°æ•´ä¸ªé“¾ä¸Š\n",
        "\n",
        "3. LCEL å¢åŠ äº† LLM çš„å¹¶è¡Œæ€§ï¼ŒLLM è¿è¡Œé€šå¸¸æ˜¯è€—è´¹æ—¶é—´çš„ï¼Œå¹¶è¡Œå¯ä»¥åŠ å¿«å¾—åˆ°ç»“æœçš„é€Ÿåº¦ã€‚\n",
        "\n",
        "4. LCEL å†…ç½®äº†æ—¥å¿—è®°å½•ï¼Œè®°å½•ä»£ç†çš„è¿è¡Œæƒ…å†µã€‚å³ä½¿ä»£ç†å¤æ‚ï¼Œæ—¥å¿—ä¹Ÿæœ‰åŠ©äºç†è§£å¤æ‚é“¾æ¡å’Œä»£ç†çš„è¿è¡Œæƒ…å†µã€‚\n",
        "\n",
        "åœ¨å‰é¢çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“ LangChain æä¾›äº†ç»„ä»¶ é“¾ï¼ˆchainï¼‰ å¯ä»¥å°†ç»„ä»¶ç»„åˆèµ·æ¥å‘æŒ¥ LLM æ›´å¼ºå¤§çš„åŠŸèƒ½ï¼Œä½†æ˜¯è¯­æ³•éå¸¸å¤æ‚ã€‚åœ¨è¿™é‡Œï¼ŒLCEL æä¾›äº†ä¸€ç§ç®¡é“è¯­æ³•ï¼Œä½¿ä»åŸºæœ¬ç»„ä»¶æ„å»ºå¤æ‚é“¾å˜å¾—å®¹æ˜“ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ LangChain å®Œæˆ`Chain = prompt | LLM |OutputParser `çš„ç»„åˆï¼Œå…·ä½“ä½¿ç”¨æˆ‘ä»¬å°†åœ¨ä¸‹æ–‡å†…å®¹ä¸­è®¨è®ºã€‚é“¾ï¼ˆChainsï¼‰é€šå¸¸å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æç¤ºï¼ˆPromptï¼‰ç»“åˆåœ¨ä¸€èµ·ï¼ŒåŸºäºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ–‡æœ¬æˆ–æ•°æ®è¿›è¡Œä¸€ç³»åˆ—æ“ä½œã€‚\n",
        "\n",
        "![image.png](../../figures/LCEL.png)\n",
        "\n",
        "- [ä¸€ã€ç®€å•é“¾ Simple Chain](#ä¸€ã€ç®€å•é“¾-Simple-Chain)\n",
        "- [äºŒã€æ›´å¤æ‚çš„é“¾ More complex chain](#äºŒã€æ›´å¤æ‚çš„é“¾-More-complex-chain)\n",
        "  - [1.1 æ„å»ºç®€å•å‘é‡æ•°æ®åº“](#1.1-æ„å»ºç®€å•å‘é‡æ•°æ®åº“)\n",
        "  - [1.2 ä½¿ç”¨RunnableMap](#1.2-ä½¿ç”¨RunnableMap)\n",
        "- [ä¸‰ã€ç»‘å®š Bind](#ä¸‰ã€ç»‘å®š-Bind)\n",
        "  - [3.1 å•å‡½æ•°ç»‘å®š](#3.1-å•å‡½æ•°ç»‘å®š)\n",
        "  - [3.2 å¤šä¸ªå‡½æ•°ç»‘å®š](#3.2-å¤šä¸ªå‡½æ•°ç»‘å®š)\n",
        "- [å››ã€åå¤‡æªæ–½ Fallbacks](#å››ã€åå¤‡æªæ–½-Fallbacks)\n",
        "  - [4.1 ä½¿ç”¨æ—©æœŸæ¨¡å‹æ ¼å¼åŒ–è¾“å‡º](#4.1-ä½¿ç”¨æ—©æœŸæ¨¡å‹æ ¼å¼åŒ–è¾“å‡º)\n",
        "  - [4.2 ä½¿ç”¨æ–°æ¨¡å‹æ ¼å¼åŒ–è¾“å‡º](#4.2-ä½¿ç”¨æ–°æ¨¡å‹æ ¼å¼åŒ–è¾“å‡º)\n",
        "  - [4.3 fallbacksæ–¹æ³•](#4.3-fallbacksæ–¹æ³•)\n",
        "- [äº”ã€æ¥å£ Interface](#äº”ã€æ¥å£-Interface)\n",
        "  - [5.1 invokeæ¥å£](#5.1-invokeæ¥å£)\n",
        "  - [5.2 batchæ¥å£](#5.2-batchæ¥å£)\n",
        "  - [5.3 streamæ¥å£](#5.3-streamæ¥å£)\n",
        "  - [5.4 å¼‚æ­¥æ¥å£](#5.4-å¼‚æ­¥æ¥å£)\n",
        "- [å…­ã€è‹±æ–‡ç‰ˆæç¤º](#å…­ã€è‹±æ–‡ç‰ˆæç¤º)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1242116-2c9e-4dac-8ba4-8549f8edcaa8",
      "metadata": {},
      "source": [
        "ä¸ºäº†å¤§å®¶å®éªŒæ–¹ä¾¿ï¼Œå…³äºä»¥ä¸‹ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„APIï¼Œäºæ˜¯ç›¸å…³çš„ä»£ç ä¹Ÿä¼šä¿®æ”¹ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b631e459",
      "metadata": {},
      "source": [
        "## ä¸€ã€ç®€å•é“¾ Simple Chain\n",
        "\n",
        "æ¥ä¸‹æ¥æˆ‘ä»¬ä¾æ—§ä¼šä½¿ç”¨ OpenAI çš„ APIï¼Œæ‰€ä»¥é¦–å…ˆæˆ‘ä»¬è¦åˆå§‹åŒ–æˆ‘ä»¬çš„ API_Keyï¼Œè¿™ä¸ªæ–¹æ³•å’Œä¸Šä¸€ç« çš„æ–¹å¼æ˜¯ä¸€æ ·çš„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacb572a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cacb572a",
        "outputId": "1acef39b-494e-445e-bde0-2e8f83a2a84c"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai==0.28\n",
        "# !pip install \"langchain[docarray]\"\n",
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c52952e6",
      "metadata": {
        "id": "c52952e6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "loaded = load_dotenv(find_dotenv(), override=True)\n",
        "# ä»ç¯å¢ƒå˜é‡ä¸­è·å– OpenAI API Key æˆ–è€…ç›´æ¥èµ‹å€¼\n",
        "API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "# å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯å®˜æ–¹ APIï¼Œå°±ç›´æ¥ç”¨ https://api.siliconflow.cn/v1 å°±è¡Œã€‚\n",
        "BASE_URL = \"https://api.siliconflow.cn/v1\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7f48e9",
      "metadata": {
        "id": "0a7f48e9"
      },
      "source": [
        "æ¥ä¸‹æ¥é¦–å…ˆå¯¼å…¥ LangChain çš„åº“ï¼Œå¹¶ä¸”å®šä¹‰ä¸€ä¸ªç®€å•çš„é“¾ï¼Œè¿™ä¸ªé“¾åŒ…æ‹¬æç¤ºæ¨¡æ¿ï¼Œå¤§è¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªè¾“å‡ºè§£æå™¨ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒæˆåŠŸè¾“å‡ºäº†å¤§è¯­è¨€æ¨¡å‹çš„ç»“æœï¼Œå®Œæˆäº†ä¸€ä¸ªç®€å•çš„é“¾ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "81ac70fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "81ac70fe",
        "outputId": "00302a8a-42eb-4eaa-ff0f-8540245932cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºç†Šçš„çŸ­ç¬‘è¯ï¼š\n",
            "\n",
            "æœ‰ä¸€å¤©ï¼Œä¸€åªç†Šèµ°è¿›äº†ä¸€å®¶é…’å§ï¼Œç‚¹äº†ä¸€æ¯å•¤é…’ï¼Œç„¶åè¯´ï¼šâ€œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\n",
            "\n",
            "é…’ä¿çœ‹äº†çœ‹å®ƒï¼Œè¯´ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘ä»¬è¿™é‡Œä¸æ¬¢è¿ç†Šã€‚â€\n",
            "\n",
            "ç†Šè€¸è€¸è‚©ï¼Œè¯´ï¼šâ€œé‚£æˆ‘æ¢ä¸ªåœ°æ–¹ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\n",
            "\n",
            "é…’ä¿æ— å¥ˆåœ°è¯´ï¼šâ€œä½ çœŸæ˜¯ä¸ªçˆ±å–çš„ç†Šã€‚â€ ğŸ˜„\n",
            "\n",
            "å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªç¬‘è¯ï¼å¦‚æœæƒ³è¦æ›´å¤šï¼Œæˆ‘ä¹Ÿå¯ä»¥ç»§ç»­è®²ã€‚\n"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥LangChainæ‰€éœ€çš„æ¨¡å—\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# ä½¿ç”¨ ChatPromptTemplate ä»æ¨¡æ¿åˆ›å»ºä¸€ä¸ªæç¤ºï¼Œæ¨¡æ¿ä¸­çš„ {topic} å°†åœ¨åç»­ä»£ç ä¸­æ›¿æ¢ä¸ºå®é™…çš„è¯é¢˜\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"å‘Šè¯‰æˆ‘ä¸€ä¸ªå…³äº{topic}çš„çŸ­ç¬‘è¯\"\n",
        ")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ª ChatOpenAI æ¨¡å‹å®ä¾‹ï¼Œé»˜è®¤ä½¿ç”¨ Qwen/Qwen3-8B æ¨¡å‹\n",
        "model = ChatOpenAI(temperature=0, model_name=\"Qwen/Qwen3-8B\", max_tokens=4096,\n",
        "                   openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
        "                   seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
        "                   extra_body={\n",
        "                       \"enable_thinking\": False\n",
        "                   }\n",
        "                  )\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªStrOutputParserå®ä¾‹ï¼Œç”¨äºè§£æè¾“å‡º\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªé“¾å¼è°ƒç”¨ï¼Œå°† promptã€model å’Œoutput_parser è¿æ¥åœ¨ä¸€èµ·\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# è°ƒç”¨é“¾å¼è°ƒç”¨ï¼Œå¹¶ä¼ å…¥å‚æ•°\n",
        "print(chain.invoke({\"topic\": \"ç†Š\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7563f727",
      "metadata": {
        "id": "7563f727"
      },
      "source": [
        "å¦‚æœæˆ‘ä»¬å»æŸ¥çœ‹`Chain`çš„è¾“å‡ºï¼Œæˆ‘ä»¬ä¼šå‘ç°ï¼Œä»–è·Ÿæˆ‘ä»¬å®šä¹‰çš„æ˜¯ä¸€æ ·çš„ï¼Œä¸€å…±æœ‰ä¸‰éƒ¨åˆ†è¿›è¡Œç»„æˆï¼Œä¹Ÿå°±æ˜¯`Chain = prompt | LLM |OutputParser `ã€‚`|`ç¬¦å·ç±»ä¼¼äº unix ç®¡é“æ“ä½œç¬¦ï¼Œå®ƒå°†ä¸åŒçš„ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼Œå°†ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºä½œä¸ºè¾“å…¥æä¾›ç»™ä¸‹ä¸€ä¸ªç»„ä»¶ã€‚åœ¨è¿™ä¸ªé“¾ä¸­ï¼Œç”¨æˆ·è¾“å…¥è¢«ä¼ é€’ç»™æç¤ºæ¨¡æ¿ï¼Œç„¶åæç¤ºæ¨¡æ¿è¾“å‡ºè¢«ä¼ é€’ç»™æ¨¡å‹ï¼Œç„¶åæ¨¡å‹è¾“å‡ºè¢«ä¼ é€’åˆ°è¾“å‡ºè§£æå™¨ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a351d14a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a351d14a",
        "outputId": "e9a7f195-fdfb-4523-eb34-a708ce0e0b24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='å‘Šè¯‰æˆ‘ä¸€ä¸ªå…³äº{topic}çš„çŸ­ç¬‘è¯'), additional_kwargs={})])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001AE22E1F4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001AE233237A0>, root_client=<openai.OpenAI object at 0x000001AE2121AF90>, root_async_client=<openai.AsyncOpenAI object at 0x000001AE23280CE0>, model_name='Qwen/Qwen3-8B', temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.siliconflow.cn/v1', max_retries=3, presence_penalty=0.1, frequency_penalty=0.1, seed=42, max_tokens=4096, extra_body={'enable_thinking': False})\n",
              "| StrOutputParser()"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# æŸ¥çœ‹Chainçš„å€¼\n",
        "chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f8c80e",
      "metadata": {
        "id": "35f8c80e"
      },
      "source": [
        "## äºŒã€æ›´å¤æ‚çš„é“¾ More complex chain\n",
        "\n",
        "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¼šåˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„é“¾æ¡ï¼Œåœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ¥è§¦è¿‡å¦‚ä½•è¿›è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆã€‚æ‰€ä»¥æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨ LCEL æ¥é‡å¤ä¹‹å‰çš„è¿‡ç¨‹ï¼Œå°†ç”¨æˆ·çš„é—®é¢˜å’Œå‘é‡æ•°æ®åº“æ£€ç´¢ç»“æœç»“åˆèµ·æ¥ï¼Œä½¿ç”¨ RunnableMap æ¥æ„å»ºä¸€ä¸ªæ›´å¤æ‚çš„é“¾ã€‚\n",
        "\n",
        "### 2.1 æ„å»ºç®€å•å‘é‡æ•°æ®åº“\n",
        "é¦–å…ˆæˆ‘ä»¬æ„å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“ï¼Œè¿™ä¸ªç®€å•çš„å‘é‡æ•°æ®åº“åªåŒ…å«ä¸¤å¥è¯ï¼Œä½¿ç”¨ OpenAI çš„ Embedding ä½œä¸ºåµŒå…¥æ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬é€šè¿‡ `vector store.as_retriever `æ¥åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "308eab74",
      "metadata": {
        "id": "308eab74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E:\\LearningDisk\\Learning_Projects\\MyPythonProjects\\llm-cookbook\\.venv\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    openai_api_key=API_KEY,\n",
        "    openai_api_base=BASE_URL,\n",
        "    model=\"BAAI/bge-m3\"\n",
        ")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªDocArrayInMemorySearchå¯¹è±¡ï¼Œç”¨äºå­˜å‚¨å’Œæœç´¢æ–‡æ¡£å‘é‡\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"å“ˆé‡Œæ£®åœ¨è‚¯è‚–å·¥ä½œ\", \"ç†Šå–œæ¬¢åƒèœ‚èœœ\"],\n",
        "    embedding=embedding_model\n",
        ")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "768c1f68",
      "metadata": {
        "id": "768c1f68"
      },
      "source": [
        "é€šè¿‡ä¹‹å‰çš„å­¦ä¹ ï¼Œå¦‚æœæˆ‘ä»¬è°ƒç”¨`retriever.get_relevant_documents`ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ç›¸å…³çš„æ£€ç´¢æ–‡æ¡£ï¼Œé¦–å…ˆæˆ‘ä»¬é—®â€œå“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œï¼Ÿâ€ï¼Œæˆ‘ä»¬ä¼šå‘ç°è¿”å›äº†ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œä»–ä¼šæ ¹æ®ç›¸ä¼¼åº¦æ’åºè¿”å›æ–‡æ¡£åˆ—è¡¨ï¼Œæ‰€ä»¥å…¶ä¸­æœ€ç›¸å…³çš„æ”¾åœ¨äº†ç¬¬ä¸€ä¸ªã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f83e9118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83e9118",
        "outputId": "4b3e4b1f-c378-43ec-8a2e-4b6a6a0d88b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='å“ˆé‡Œæ£®åœ¨è‚¯è‚–å·¥ä½œ'),\n",
              " Document(metadata={}, page_content='ç†Šå–œæ¬¢åƒèœ‚èœœ')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# è·å–ä¸é—®é¢˜â€œå“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œï¼Ÿâ€ç›¸å…³çš„æ–‡æ¡£\n",
        "retriever.invoke(\"å“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œï¼Ÿ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b5eacb",
      "metadata": {
        "id": "a4b5eacb"
      },
      "source": [
        "å¦‚æœæˆ‘ä»¬æ¢ä¸€ä¸ªé—®é¢˜ï¼Œæ¯”å¦‚\"ç†Šå–œæ¬¢åƒä»€ä¹ˆ\"ï¼Œå¯ä»¥çœ‹åˆ°é—®é¢˜çš„é¡ºåºå°±å‘ç”Ÿäº†å˜åŒ–ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7d76aaf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d76aaf5",
        "outputId": "8e79e2d9-8572-44e0-edf7-70cd254e0252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='ç†Šå–œæ¬¢åƒèœ‚èœœ'),\n",
              " Document(metadata={}, page_content='å“ˆé‡Œæ£®åœ¨è‚¯è‚–å·¥ä½œ')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# è·å–ä¸é—®é¢˜â€œç†Šå–œæ¬¢åƒä»€ä¹ˆâ€ç›¸å…³çš„æ–‡æ¡£\n",
        "retriever.invoke(\"ç†Šå–œæ¬¢åƒä»€ä¹ˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb34293a",
      "metadata": {
        "id": "fb34293a"
      },
      "source": [
        "### 3.2 ä½¿ç”¨RunnableMap\n",
        "\n",
        "ä¸Šè¿°ä¾‹å­è¿”å›ä¸¤ä¸ªç»“æœæ˜¯å› ä¸ºåªæœ‰ä¸¤ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œè¿™å®Œå…¨é€‚ç”¨äºæ›´å¤šæ–‡æ¡£æƒ…å†µã€‚æ¥ä¸‹æ¥æˆ‘ä»¬ä¼šåŠ å…¥`RunnableMap`ï¼Œåœ¨è¿™ä¸ª`RunnableMap`ä¸­ï¼Œä¸ä»…ä»…æœ‰ç”¨æˆ·çš„é—®é¢˜ï¼Œä»¥åŠæœ‰å¯¹åº”çš„é—®é¢˜çš„æ–‡æ¡£åˆ—è¡¨ï¼Œç›¸å½“äºè¿™ä¹Ÿä¸ºå¤§æ¨¡å‹çš„æ–‡æ¡£å¢åŠ äº†ä¸Šä¸‹æ–‡ï¼Œè¿™æ ·å°±èƒ½å®Œæˆæ£€ç´¢å¢å¼ºçš„äº‹æƒ…ã€‚å¦‚æœæˆ‘ä»¬æ­£å¸¸é—®ä¸€ä¸ªé—®é¢˜ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå¤§æ¨¡å‹æ­£ç¡®çš„è¿”å›äº†æ–‡æ¡£é‡Œé¢çš„ç»“æœï¼Œå¾—åˆ°äº†æ­£ç¡®çš„è¾“å‡ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e8a9b652",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e8a9b652",
        "outputId": "d615b86a-a14b-4917-833f-e70c91730477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'å“ˆé‡Œæ£®åœ¨è‚¯è‚–å·¥ä½œã€‚'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.schema.runnable import RunnableMap\n",
        "\n",
        "# å®šä¹‰ä¸€ä¸ªæ¨¡æ¿å­—ç¬¦ä¸²template\n",
        "template = \"\"\"ä»…æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n",
        "{context}\n",
        "\n",
        "é—®é¢˜ï¼š{question}\n",
        "\"\"\"\n",
        "\n",
        "# ä½¿ç”¨ template ä½œä¸ºæ¨¡æ¿\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªå¤„ç†é“¾ chain ï¼ŒåŒ…å«äº† RunnableMapã€promptã€model å’Œ output_parser ç»„ä»¶\n",
        "chain = RunnableMap({\n",
        "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "}) | prompt | model | output_parser\n",
        "\n",
        "# è°ƒç”¨chainçš„invokeæ–¹æ³•\n",
        "chain.invoke({\"question\": \"å“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œ?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394af88e",
      "metadata": {
        "id": "394af88e"
      },
      "source": [
        "å¦‚æœæˆ‘ä»¬æƒ³æ›´æ·±å…¥æŒ–æ˜ä¸€ä¸‹èƒŒåçš„å·¥ä½œæœºç†ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹`RunnableMap`ï¼Œæˆ‘ä»¬æŠŠå…¶åˆ›å»ºä¸ºä¸€ä¸ªè¾“å…¥ï¼Œç”¨ä¸€æ ·çš„æ–¹å¼è¿›è¡Œæ“ä½œã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™ä¹‹ä¸­ï¼Œ`RunnableMap`æä¾›äº†`context`å’Œ`question`ä¸¤ä¸ªå˜é‡ï¼Œä¸€ä¸ªæ˜¯æŸ¥è¯¢çš„æ–‡æ¡£åˆ—è¡¨ï¼Œå¦ä¸€ä¸ªæ˜¯å¯¹åº”çš„é—®é¢˜ï¼Œè¿™ä¸ªå¤§æ¨¡å‹å°±å¯ä»¥æ ¹æ®æä¾›æ–‡æ¡£æ¥æ€»ç»“å›ç­”å¯¹åº”çš„é—®é¢˜äº†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "759d2af6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759d2af6",
        "outputId": "fa16fa6c-dcb0-46e9-e538-428e711db372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='å“ˆé‡Œæ£®åœ¨è‚¯è‚–å·¥ä½œ'),\n",
              "  Document(metadata={}, page_content='ç†Šå–œæ¬¢åƒèœ‚èœœ')],\n",
              " 'question': 'å“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œ?'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# åˆ›å»ºä¸€ä¸ªRunnableMapå¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªé”®å€¼å¯¹\n",
        "# é”® \"context\" å¯¹åº”ä¸€ä¸ªlambdaå‡½æ•°ï¼Œç”¨äºè·å–ç›¸å…³æ–‡æ¡£ï¼Œå‡½æ•°è¾“å…¥å‚æ•°ä¸ºxï¼Œå³è¾“å…¥çš„å­—å…¸ï¼Œå‡½æ•°è¿”å›å€¼ä¸ºretriever.get_relevant_documents(x[\"question\"])\n",
        "# é”® \"question\" å¯¹åº”ä¸€ä¸ªlambdaå‡½æ•°ï¼Œç”¨äºè·å–é—®é¢˜ï¼Œå‡½æ•°è¾“å…¥å‚æ•°ä¸ºxï¼Œå³è¾“å…¥çš„å­—å…¸ï¼Œå‡½æ•°è¿”å›å€¼ä¸ºx[\"question\"]\n",
        "inputs = RunnableMap({\n",
        "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "})\n",
        "\n",
        "# è°ƒç”¨ inputs çš„ invoke æ–¹æ³•ï¼Œå¹¶ä¼ é€’ä¸€ä¸ªå­—å…¸ä½œä¸ºå‚æ•°ï¼Œå­—å…¸ä¸­åŒ…å«ä¸€ä¸ªé”®å€¼å¯¹ï¼Œé”®ä¸º\"question\"ï¼Œå€¼ä¸º\"å“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œ?\"\n",
        "inputs.invoke({\"question\": \"å“ˆé‡Œæ£®åœ¨å“ªé‡Œå·¥ä½œ?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c01b704",
      "metadata": {
        "id": "2c01b704"
      },
      "source": [
        "## ä¸‰ã€ç»‘å®š Bind\n",
        "\n",
        "åœ¨ä¸Šä¸€ç« æˆ‘ä»¬ä»‹ç»äº†OpenAIå‡½æ•°çš„è°ƒç”¨ï¼Œæ–°çš„`function`å‚æ•°å¯ä»¥è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦è¦ä½¿ç”¨å·¥å…·å‡½æ•°ï¼Œå¦‚æœéœ€è¦å°±ä¼šè¿”å›éœ€è¦ä½¿ç”¨çš„å‚æ•°ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬ä¹Ÿä½¿ç”¨LangChainå®ç°OpenAIå‡½æ•°è°ƒç”¨çš„æ–°åŠŸèƒ½ï¼Œé¦–å…ˆéœ€è¦ä¸€ä¸ªå‡½æ•°çš„æè¿°ä¿¡æ¯ï¼Œä»¥åŠå®šä¹‰å‡½æ•°ï¼Œè¿™é‡Œçš„å‡½æ•°è¿˜æ˜¯ä½¿ç”¨ä¸Šä¸€ç« çš„`get_current_weather`å‡½æ•°ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1b00f651",
      "metadata": {
        "id": "1b00f651"
      },
      "outputs": [],
      "source": [
        "# å®šä¹‰ä¸€ä¸ªå‡½æ•°\n",
        "get_current_weather_fn = {\n",
        "    \"name\": \"get_current_weather\",\n",
        "    \"description\": \"è·å–æŒ‡å®šä½ç½®çš„å½“å‰å¤©æ°”æƒ…å†µ\",\n",
        "    \"parameters\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"location\": {\n",
        "          \"type\": \"string\",\n",
        "          \"description\": \"åŸå¸‚å’Œçœä»½ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ï¼ŒåŒ—äº¬å¸‚\",\n",
        "        },\n",
        "        \"unit\": {\"type\": \"string\", \"enum\": [\"æ‘„æ°åº¦\", \"åæ°åº¦\"]},\n",
        "      },\n",
        "      \"required\": [\"location\"],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2ff71d",
      "metadata": {
        "id": "5d2ff71d"
      },
      "source": [
        "### 3.1 å•å‡½æ•°ç»‘å®š\n",
        "\n",
        "æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨`bind`çš„æ–¹æ³•æŠŠå·¥å…·å‡½æ•°ç»‘å®šåˆ°å¤§æ¨¡å‹ä¸Šï¼Œå¹¶æ„å»ºä¸€ä¸ªç®€å•çš„é“¾ã€‚è¿›è¡Œè°ƒç”¨ä»¥åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿”å›äº†ä¸€ä¸ª`AIMessage`ï¼Œ\tå…¶ä¸­è¿”å›çš„`content`ä¸ºç©ºï¼Œä½†æ˜¯è¿”å›äº†æˆ‘ä»¬éœ€è¦è°ƒç”¨å·¥å…·å‡½æ•°çš„å‚æ•°ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2f693ff9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f693ff9",
        "outputId": "9ebdd754-906f-4178-a31a-899ed3c7d304"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '01975f1a44717c4182a160a787b51d6c', 'function': {'arguments': ' {\"location\": \"åŒ—äº¬\", \"unit\": \"æ‘„æ°åº¦\"}', 'name': 'get_current_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 197, 'total_tokens': 212, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '01975f1a438bc4e812dd7a110a207b82', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4a897e02-fdb5-4e0f-9b30-42577e3d0b6e-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'åŒ—äº¬', 'unit': 'æ‘„æ°åº¦'}, 'id': '01975f1a44717c4182a160a787b51d6c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 15, 'total_tokens': 212, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ä½¿ç”¨ChatPromptTemplate.from_messagesæ–¹æ³•åˆ›å»ºä¸€ä¸ªChatPromptTemplateå¯¹è±¡\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ä½¿ç”¨bindæ–¹æ³•ç»‘å®šfunctionså‚æ•°\n",
        "model = model.bind(tools=[\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": get_current_weather_fn\n",
        "    }\n",
        "])\n",
        "\n",
        "runnable = prompt | model\n",
        "\n",
        "# è°ƒç”¨invokeæ–¹æ³•\n",
        "runnable.invoke({\"input\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89a5fb09",
      "metadata": {
        "id": "89a5fb09"
      },
      "source": [
        "### 3.2 å¤šä¸ªå‡½æ•°ç»‘å®š\n",
        "\n",
        "åŒæ—¶æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰å¤šä¸ª`function`ï¼Œå¤§æ¨¡å‹åœ¨å¯¹è¯çš„æ—¶å€™å¯ä»¥è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨å“ªä¸€ä¸ªå‡½æ•°ã€‚è¿™é‡Œé¢æˆ‘ä»¬å®šä¹‰æœ‰ä¸¤ä¸ªå‡½æ•°ï¼Œç¬¬ä¸€ä¸ªå‡½æ•°æ˜¯ç±»ä¼¼äºå‰é¢çš„`weather_search`ï¼Œæœç´¢ç»™å®šæœºåœºçš„å¤©æ°”ï¼Œç„¶åæˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸€ä¸ªèµ›äº‹ä½“è‚²æ–°é—»æœç´¢çš„`sports_search`ï¼ŒæŸ¥è¯¢å¤©æ°”çš„å‡½æ•°`weather_search`æ¥å—çš„å‚æ•°ä¸ºairport_codeå³æœºåœºä»£ç ï¼Œä½“è‚²æ–°é—»æœç´¢å‡½æ•°`sports_search`æ¥å—çš„å‚æ•°ä¸ºteam_nameå³ä½“è‚²é˜Ÿåã€‚ç”±äºè¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦è¿è¡Œè¿™äº›å‡½æ•°ï¼Œå› ä¸ºå¤§æ¨¡å‹æ˜¯é€šè¿‡é—®çš„é—®é¢˜æ¥è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦è°ƒç”¨è¿™äº›å‡½æ•°ï¼Œå¹¶ä¸”è¿”å›å‚æ•°ï¼Œå¹¶ä¸ä¼šç›´æ¥å¸®æˆ‘ä»¬è°ƒç”¨ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b95f4029",
      "metadata": {
        "id": "b95f4029"
      },
      "outputs": [],
      "source": [
        "weather_search_fn = {\n",
        "    \"name\": \"weather_search\",\n",
        "    \"description\": \"æœç´¢ç»™å®šæœºåœºä»£ç çš„å¤©æ°”\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"airport_code\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"è¦è·å–å¤©æ°”çš„æœºåœºä»£ç \"\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "sports_search_fn = {\n",
        "    \"name\": \"sports_search\",\n",
        "        \"description\": \"æœç´¢æœ€è¿‘ä½“è‚²èµ›äº‹çš„æ–°é—»\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"team_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"è¦æœç´¢çš„ä½“è‚²é˜Ÿå\"\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"team_name\"]\n",
        "        }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a77d53",
      "metadata": {
        "id": "d4a77d53"
      },
      "source": [
        "æ¥ç€æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å‡½æ•°ç»‘å®šå¤§æ¨¡å‹ï¼Œå®šä¹‰ä¸€ä¸ªç®€å•çš„é“¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬é—®äº†ç›¸å…³çš„é—®é¢˜ä»¥åï¼Œå¤§æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨åˆ¤æ–­å¹¶ä¸”æ­£ç¡®è¿”å›å‚æ•°ï¼ŒçŸ¥é“éœ€è¦è°ƒç”¨å‡½æ•°äº†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "519e761d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "519e761d",
        "outputId": "7ad43d65-bd62-4339-c8f8-e5c74a414dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '01975f1b61c1160a4502c5183ac1a75d', 'function': {'arguments': ' {\"team_name\": \"çˆ±å›½è€…é˜Ÿ\"}', 'name': 'sports_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 251, 'total_tokens': 261, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '01975f1b60c0d9eb77dbdb940a2abd98', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e82fe1d3-4a66-42bd-ab02-15b900982007-0', tool_calls=[{'name': 'sports_search', 'args': {'team_name': 'çˆ±å›½è€…é˜Ÿ'}, 'id': '01975f1b61c1160a4502c5183ac1a75d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 251, 'output_tokens': 10, 'total_tokens': 261, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ç»‘å®šå¤§æ¨¡å‹\n",
        "model = model.bind(tools=[\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": weather_search_fn\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": sports_search_fn\n",
        "    }\n",
        "])\n",
        "\n",
        "runnable = prompt | model\n",
        "\n",
        "runnable.invoke({\"input\": \"çˆ±å›½è€…é˜Ÿæ˜¨å¤©è¡¨ç°çš„æ€ä¹ˆæ ·?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b988820",
      "metadata": {
        "id": "0b988820"
      },
      "source": [
        "## å››ã€åå¤‡æªæ–½ Fallbacks\n",
        "\n",
        "åœ¨ä½¿ç”¨æ—©æœŸçš„OpenAIæ¨¡å‹å¦‚\"text-davinci-001\"ï¼Œè¿™äº›æ¨¡å‹åœ¨å¯¹è¯è¿‡ç¨‹ä¸­ï¼Œä¸æ”¯æŒæ ¼å¼åŒ–è¾“å‡ºç»“æœå³å®ƒä»¬éƒ½æ˜¯ä»¥å­—ç¬¦ä¸²çš„å½¢å¼è¾“å‡ºç»“æœï¼Œè¿™å¯¹æˆ‘ä»¬æœ‰æ—¶å€™éœ€è¦è§£æ LLM çš„è¾“å‡ºå¸¦æ¥ä¸€äº›éº»çƒ¦ï¼Œæ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼Œå°±æ˜¯åˆ©ç”¨æ—©æœŸæ¨¡å‹\"text-davinci-001\"æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¸Œæœ› llm èƒ½ä»¥ json æ ¼å¼è¾“å‡ºç»“æœã€‚\n",
        "\n",
        "æˆ‘ä»¬å®šä¹‰äº† OpenAI çš„æ¨¡å‹ä»¥åŠåˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„é“¾ï¼Œä»¥æ­¤åŠ å…¥ json å¸Œæœ›èƒ½ä»¥ json æ ¼å¼è¾“å‡ºç»“æœï¼Œæˆ‘ä»¬è®© simple_model å†™ä¸‰é¦–è¯—ï¼Œå¹¶ä»¥ josn æ ¼å¼è¾“å‡ºï¼Œæ¯é¦–è¯—å¿…é¡»åŒ…å«:`æ ‡é¢˜ï¼Œä½œè€…å’Œè¯—çš„ç¬¬ä¸€å¥`ã€‚æˆ‘ä»¬ä¼šå‘ç°ç»“æœåªæœ‰å­—ç¬¦ä¸²ï¼Œæ— æ³•è¾“å‡ºæŒ‡å®šæ ¼å¼çš„å†…å®¹ï¼Œè™½ç„¶é‡Œé¢æœ‰ä¸€äº›`[`ï¼Œä½†æ˜¯æœ¬è´¨ä¸Šè¿˜æ˜¯ä¸€ä¸ªå¤§çš„å­—ç¬¦ä¸²ï¼Œè¿™å°±æ— æ³•è®©æˆ‘ä»¬è§£æè¾“å‡ºã€‚\n",
        "\n",
        "> ç”±äºOpenAIäº2024å¹´1æœˆ4æ—¥åœç”¨äº†æ¨¡å‹text-davinci-001ï¼Œä½ å°†ä½¿ç”¨OpenAIæ¨èçš„æ›¿ä»£æ¨¡å‹gpt-3.5-turbo-instructã€‚\n",
        "\n",
        "åœ¨ä½¿ç”¨è¯­è¨€æ¨¡å‹æ—¶ï¼Œä½ å¯èƒ½ç»å¸¸ä¼šé‡åˆ°æ¥è‡ªåº•å±‚ API çš„é—®é¢˜ï¼Œæ— è®ºè¿™äº›é—®é¢˜æ˜¯é€Ÿç‡é™åˆ¶è¿˜æ˜¯åœæœºæ—¶é—´ã€‚å› æ­¤ï¼Œå½“ä½ å°† LLM åº”ç”¨ç¨‹åºè½¬ç§»åˆ°å®é™…ç”Ÿäº§ç¯å¢ƒä¸­æ—¶ï¼Œé˜²èŒƒè¿™äº›é—®é¢˜å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å¼•å…¥äº†`å›é€€ï¼ˆFallbacksï¼‰`çš„æ¦‚å¿µã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "127d93a1",
      "metadata": {},
      "source": [
        "### 4.1 ä½¿ç”¨æ—©æœŸæ¨¡å‹æ ¼å¼åŒ–è¾“å‡º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "11e2b2e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "11e2b2e2",
        "outputId": "1294676f-7fbf-4185-ac16-49fa5d0512f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n{\\n  \"title\": \"æ˜¥é£\",\\n  \"author\": \"æç™½\",\\n  \"first_line\": \"æ˜¥é£åˆç»¿æ±Ÿå—å²¸\",\\n  \"content\": [\\n    \"æ˜¥é£åˆç»¿æ±Ÿå—å²¸\",\\n    \"èŠ±å¼€æ»¡æ ‘æŸ³å¦‚ä¸\",\\n    \"é¸Ÿå„¿æ¬¢å”±å¤©åœ°å®½\",\\n    \"äººé—´æ˜¥è‰²æœ€å®œäºº\"\\n  ]\\n}\\n\\n{\\n  \"title\": \"å¤œé›¨\",\\n  \"author\": \"æœç”«\",\\n  \"first_line\": \"å¤œé›¨æ½‡æ½‡\",\\n  \"content\": [\\n    \"å¤œé›¨æ½‡æ½‡\",\\n    \"å­¤ç¯ç…§æ—§\",\\n    \"æ€å¿µå¦‚æ½®\",\\n    \"æ³›æ»¥å¿ƒå¤´\"\\n  ]\\n}\\n\\n{\\n  \"title\": \"å±±è¡Œ\",\\n  \"author\": \"ç‹ç»´\",\\n  \"first_line\": \"è¿œä¸Šå¯’å±±çŸ³å¾„æ–œ\",\\n  \"content\": [\\n    \"è¿œä¸Šå¯’å±±çŸ³å¾„æ–œ\",\\n    \"ç™½äº‘ç”Ÿå¤„æœ‰äººå®¶\",\\n    \"åœè½¦åçˆ±æ«æ—æ™š\",\\n    \"éœœå¶çº¢äºäºŒæœˆèŠ±\"\\n  ]\\n}'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "import json\n",
        "\n",
        "# ä½¿ç”¨æ—©æœŸçš„OpenAIæ¨¡å‹\n",
        "simple_model = OpenAI(\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    model=\"gpt-3.5-turbo-instruct\"\n",
        ")\n",
        "simple_chain = simple_model | json.loads\n",
        "\n",
        "challenge = \"å†™ä¸‰é¦–è¯—ï¼Œå¹¶ä»¥josnæ ¼å¼è¾“å‡ºï¼Œæ¯é¦–è¯—å¿…é¡»åŒ…å«:æ ‡é¢˜ï¼Œä½œè€…å’Œè¯—çš„ç¬¬ä¸€å¥ã€‚\"\n",
        "\n",
        "simple_model.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a22ae8e",
      "metadata": {
        "id": "6a22ae8e"
      },
      "source": [
        "å¦‚æœæˆ‘ä»¬ä½¿ç”¨`simple_chain`æ¥è¿è¡Œï¼Œæˆ‘ä»¬å°±ä¼šå‘ç°å‡ºç°äº† json è§£ç é”™è¯¯çš„é—®é¢˜ï¼Œå› ä¸ºè¿”å›çš„ç»“æœå°±æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ— æ³•è§£æï¼Œæ‰€ä»¥ä¸‹é¢ä»£ç å°±ä¼šæŠ¥é”™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "08ee6ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "08ee6ba5",
        "outputId": "2ef7f71f-4398-47ed-a8d8-bcaa75bd91d8"
      },
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 15 column 1 (char 147)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7b2363c45b31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3505\u001b[0m         \u001b[0;34m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3507\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   3508\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             output = cast(\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3381\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   3384\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 15 column 1 (char 147)"
          ]
        }
      ],
      "source": [
        "simple_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c534366",
      "metadata": {
        "id": "1c534366"
      },
      "source": [
        "### 4.2 ä½¿ç”¨æ–°æ¨¡å‹æ ¼å¼åŒ–è¾“å‡º\n",
        "\n",
        "æ‰€ä»¥æˆ‘ä»¬ä¼šå‘ç°æ—©æœŸç‰ˆæœ¬çš„ OpenAI æ¨¡å‹ä¸æ”¯æŒæ ¼å¼åŒ–çš„è¾“å‡ºï¼Œæ‰€ä»¥å³ä½¿ä½¿ç”¨ LangChain å¹¶ä¸”åŠ ä¸Šäº†`json.load`ä½†æ˜¯è¿˜æ˜¯ä¼šå‡ºç°é”™è¯¯ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬ä½¿ç”¨æ–°çš„`gpt-3.5-turbo`æ¨¡å‹å°±ä¸ä¼šå‡ºç°è¿™ä¸ªé—®é¢˜ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f0e34ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e34ed7",
        "outputId": "f3ae66a2-b0c7-4557-8914-687ac20b2a08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'poems': [{'title': 'ç§‹æ€', 'author': 'æå•†éš', 'first_line': 'æ¯è—¤è€æ ‘æ˜é¸¦ï¼Œå°æ¡¥æµæ°´äººå®¶'},\n",
              "  {'title': 'é™å¤œæ€', 'author': 'æç™½', 'first_line': 'åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœ'},\n",
              "  {'title': 'ç™»é¹³é›€æ¥¼', 'author': 'ç‹ä¹‹æ¶£', 'first_line': 'ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµ'}]}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# é»˜è®¤ä½¿ç”¨æ–°çš„æ¨¡å‹\n",
        "model = ChatOpenAI(temperature=0, model_name=\"Qwen/Qwen3-8B\", max_tokens=4096,\n",
        "                   openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
        "                   seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
        "                   extra_body={\n",
        "                       \"enable_thinking\": False\n",
        "                   }\n",
        "                  )\n",
        "\n",
        "chain = model | StrOutputParser() | json.loads\n",
        "\n",
        "challenge = \"å†™ä¸‰é¦–è¯—ï¼Œå¹¶ä»¥josnæ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ï¼Œæ¯é¦–è¯—å¿…é¡»åŒ…å«:æ ‡é¢˜ï¼Œä½œè€…å’Œè¯—çš„ç¬¬ä¸€å¥ã€‚\"\n",
        "\n",
        "chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603a2605",
      "metadata": {
        "id": "603a2605"
      },
      "source": [
        "### 4.3 fallbacksæ–¹æ³•\n",
        "\n",
        "é‚£è¿™ä¸ªæ—¶å€™å¯èƒ½å°±ä¼šæ€è€ƒï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆæ–¹æ³•ï¼Œåœ¨ä¸ç”¨æ”¹å˜å¤ªå¤šä»£ç çš„æƒ…å†µä¸‹ï¼Œè®©æ—©æœŸçš„æ¨¡å‹ä¹Ÿèƒ½è¾¾åˆ°æ ¼å¼åŒ–è¾“å‡ºçš„æ•ˆæœï¼Œè€Œä¸æ˜¯å†™å¤æ‚çš„æ ¼å¼åŒ–è¾“å‡ºçš„ä»£ç å»å¯¹ç»“æœè¿›è¡Œæ“ä½œã€‚è¿™æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨`fallbacks`çš„æ–¹å¼èµ‹äºˆæ—©æœŸæ¨¡å‹è¿™æ ·æ ¼å¼åŒ–çš„èƒ½åŠ›ï¼Œä»ç»“æœæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬æˆåŠŸä½¿ç”¨`fallbacks`èµ‹äºˆäº†ç®€å•æ¨¡å‹æ ¼å¼åŒ–çš„èƒ½åŠ›ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7b1aede1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b1aede1",
        "outputId": "3823946c-a875-4807-9b0d-ba2910fe584d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'æ˜¥é£',\n",
              "  'author': 'æç™½',\n",
              "  'first_line': 'æ˜¥é£åˆç»¿æ±Ÿå—å²¸ã€‚',\n",
              "  'content': 'æ˜¥é£åˆç»¿æ±Ÿå—å²¸ï¼Œæ˜æœˆä½•æ—¶ç…§æˆ‘è¿˜ã€‚'},\n",
              " 'poem2': {'title': 'é™å¤œæ€',\n",
              "  'author': 'æœç”«',\n",
              "  'first_line': 'åºŠå‰æ˜æœˆå…‰ï¼Œ',\n",
              "  'content': 'åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚'},\n",
              " 'poem3': {'title': 'ç™»é¹³é›€æ¥¼',\n",
              "  'author': 'ç‹ä¹‹æ¶£',\n",
              "  'first_line': 'ç™½æ—¥ä¾å±±å°½ï¼Œ',\n",
              "  'content': 'ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµã€‚'}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ä½¿ç”¨with_fallbacksæœºåˆ¶\n",
        "final_chain = simple_chain.with_fallbacks([chain])\n",
        "\n",
        "# è°ƒç”¨final_chainçš„invokeæ–¹æ³•ï¼Œå¹¶ä¼ é€’challengeå‚æ•°\n",
        "final_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6f0aac",
      "metadata": {},
      "source": [
        "### 4.4 fallbacks æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ\n",
        "\n",
        "å½“æˆ‘ä»¬è°ƒç”¨ LLM æ—¶ï¼Œç»å¸¸ä¼šå‡ºç°ç”±äºåº•å±‚ API é—®é¢˜ã€é€Ÿç‡é—®é¢˜æˆ–è€…ç½‘ç»œé—®é¢˜ç­‰åŸå› ï¼Œå¯¼è‡´ä¸èƒ½æˆåŠŸè¿è¡Œ LLM ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å›é€€è¿™ç§æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå…·ä½“æ¥è¯´ï¼Œä»–æ˜¯é€šè¿‡ä½¿ç”¨å¦ä¸€ç§ LLM æ¥ä»£æ›¿åŸå…ˆçš„ä¸å¯è¿è¡Œçš„ LLM äº§ç”Ÿç»“æœï¼Œè¯·çœ‹ä¸‹é¢ä¾‹å­ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd3f251",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.chat_models.openai import ChatOpenAI\n",
        "from langchain_core.chat_models.anthropic import ChatAnthropic\n",
        "\n",
        "model = ChatAnthropic().with_fallbacks([ChatOpenAI()])\n",
        "model.invoke('hello')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8fb2aa",
      "metadata": {},
      "source": [
        "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šå¸¸ä¼šä¼˜å…ˆä½¿ç”¨ ChatAnthropic è¿›è¡Œå›ç­”ï¼Œä½†æ˜¯å¦‚æœè°ƒç”¨ ChatAnthropic å¤±è´¥äº†ï¼Œä¼šå›é€€åˆ°ä½¿ç”¨ ChatOpenAI æ¨¡å‹æ¥ç”Ÿæˆå“åº”ã€‚å¦‚æœä¸¤ç§ LLM éƒ½å¤±è´¥äº†ï¼Œå°†ä¼šå›é€€åˆ°ä¸€ç§ç¡¬ç¼–ç å“åº”ã€‚ç¡¬ç¼–ç çš„é»˜è®¤å“åº”ç”¨äºå¤„ç†å¼‚å¸¸æƒ…å†µæˆ–è€…åœ¨æ— æ³•ä»å¤–éƒ¨èµ„æºè·å–æ‰€éœ€ä¿¡æ¯æ—¶æä¾›ä¸€ä¸ªå¤‡ç”¨é€‰é¡¹ï¼Œä¾‹å¦‚ \"Looks like our LLM providers are down. Here's a nice ğŸ¦œï¸ emoji for you instead.\"ï¼ˆçœ‹èµ·æ¥æˆ‘ä»¬çš„ LLM æä¾›å•†å‡ºäº†é—®é¢˜ï¼Œé‚£ä¹ˆï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå¯çˆ±çš„ ğŸ¦œï¸ è¡¨æƒ…ç¬¦å·ç»™ä½ ã€‚ï¼‰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438e1841",
      "metadata": {},
      "source": [
        "å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº fallbacks çš„å†…å®¹ï¼Œè¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/guides/fallbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e3229d",
      "metadata": {
        "id": "96e3229d"
      },
      "source": [
        "## äº”ã€æ¥å£ Interface\n",
        "\n",
        "åœ¨ä½¿ç”¨LangChainä¸­ï¼Œå­˜åœ¨è®¸å¤šæ¥å£ï¼Œå…¶ä¸­å…¬å¼€çš„æ ‡å‡†æ¥å£åŒ…æ‹¬ï¼š\n",
        "\n",
        "- streamï¼šæµå¼è¿”å›è¾“å‡ºå†…å®¹\n",
        "- invokeï¼šè¾“å…¥è°ƒç”¨chain\n",
        "- batchï¼šåœ¨è¾“å…¥åˆ—è¡¨ä¸­å¹¶è¡Œè°ƒç”¨chain\n",
        "\n",
        "è¿™äº›ä¹Ÿæœ‰ç›¸åº”çš„å¼‚æ­¥æ–¹æ³•ï¼š\n",
        "\n",
        "- astreamï¼šå¼‚æ­¥æµå¼è¿”å›è¾“å‡ºå†…å®¹\n",
        "- ainvokeï¼šåœ¨è¾“å…¥ä¸Šå¼‚æ­¥è°ƒç”¨chain\n",
        "- abatchï¼šåœ¨è¾“å…¥åˆ—è¡¨ä¸­å¹¶è¡Œå¼‚æ­¥è°ƒç”¨chain\n",
        "\n",
        "é¦–å…ˆæˆ‘ä»¬å®šä¹‰ç»™ä¸€ä¸ªç®€å•æç¤ºæ¨¡æ¿ï¼Œä¹Ÿå°±æ˜¯\"ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{ä¸»é¢˜}çš„çŸ­ç¬‘è¯\"ï¼Œç„¶åå®šä¹‰äº†ä¸€ä¸ªç®€å•çš„é“¾`Chain = prompt | LLM | OutputParser`ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "72e228da",
      "metadata": {
        "id": "72e228da"
      },
      "outputs": [],
      "source": [
        "# åˆ›å»ºä¸€ä¸ªChatPromptTemplateå¯¹è±¡ï¼Œä½¿ç”¨æ¨¡æ¿\"ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„çŸ­ç¬‘è¯\"\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„çŸ­ç¬‘è¯\"\n",
        ")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªChatOpenAIæ¨¡å‹\n",
        "model = ChatOpenAI(temperature=0, model_name=\"Qwen/Qwen3-8B\", max_tokens=4096,\n",
        "                   openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
        "                   seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
        "                   extra_body={\n",
        "                       \"enable_thinking\": False\n",
        "                   }\n",
        "                  )\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªStrOutputParserå¯¹è±¡\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªchainï¼Œå°†promptã€modelå’Œoutput_parserè¿æ¥èµ·æ¥\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b02924",
      "metadata": {
        "id": "e8b02924"
      },
      "source": [
        "### 5.1 invokeæ¥å£\n",
        "\n",
        "æ¥ä¸‹æ¥æˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨å¯¹åº”çš„æ¥å£ï¼Œæ¯”å¦‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å¸¸è§„çš„`invoke`çš„è°ƒç”¨ï¼Œè¿™ä¸ªä¹Ÿæ˜¯å‰é¢å±•ç°çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å¯¹åº”ç»“æœã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e339d019",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "e339d019",
        "outputId": "6893312f-8473-411f-d175-c351532e5646"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºç†Šçš„çŸ­ç¬‘è¯ï¼š\\n\\næœ‰ä¸€å¤©ï¼Œä¸€åªç†Šèµ°è¿›äº†ä¸€å®¶é…’å§ï¼Œç‚¹äº†ä¸€æ¯å•¤é…’ï¼Œç„¶åè¯´ï¼šâ€œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿çœ‹äº†çœ‹å®ƒï¼Œè¯´ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘ä»¬è¿™é‡Œä¸æ¬¢è¿ç†Šã€‚â€\\n\\nç†Šè€¸è€¸è‚©ï¼Œè¯´ï¼šâ€œé‚£æˆ‘æ¢ä¸ªåœ°æ–¹ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿æ— å¥ˆåœ°è¯´ï¼šâ€œä½ æ€»æ˜¯è¿™æ ·ï¼Œç†Šã€‚â€\\n\\nç†Šå›ç­”ï¼šâ€œé‚£æˆ‘æ¢ä¸ªèº«ä»½ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ åˆ°åº•æ˜¯è°ï¼Ÿâ€\\n\\nç†Šï¼šâ€œæˆ‘æ˜¯â€˜æˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯â€™ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ çœŸæ˜¯ä¸ªå“²å­¦ç†Šã€‚â€ ğŸ˜„\\n\\nè¿™ä¸ªç¬‘è¯æœ‰ç‚¹æ–‡å­—æ¸¸æˆçš„æ„å‘³ï¼Œä½†å¸Œæœ›ä½ å–œæ¬¢ï¼å¦‚æœä½ æƒ³è¦æ›´æç¬‘æˆ–æ›´æ¸©é¦¨çš„ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ã€‚'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"ç†Š\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2520f449",
      "metadata": {
        "id": "2520f449"
      },
      "source": [
        "### 5.2 batchæ¥å£\n",
        "\n",
        "æˆ‘ä»¬å†å°è¯•ä½¿ç”¨`batch`çš„æ¥å£ï¼Œæˆ‘ä»¬ä¼šå‘ç°å¤§æ¨¡å‹å¯ä»¥è¿”å›ä¸¤ä¸ªé—®é¢˜çš„ç­”æ¡ˆï¼Œæˆ‘ä»¬ä¼šç»™chainä¸€ä¸ªè¾“å…¥çš„åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­å¯ä»¥åŒ…å«å¤šä¸ªé—®é¢˜ï¼Œæœ€åè¿”å›å¤šä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d549ac8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d549ac8a",
        "outputId": "fbd34c84-26b2-4576-d7ce-aa73be98d755"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºç†Šçš„çŸ­ç¬‘è¯ï¼š\\n\\næœ‰ä¸€å¤©ï¼Œä¸€åªç†Šèµ°è¿›äº†ä¸€å®¶é…’å§ï¼Œç‚¹äº†ä¸€æ¯å•¤é…’ï¼Œç„¶åè¯´ï¼šâ€œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿çœ‹äº†çœ‹å®ƒï¼Œè¯´ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘ä»¬è¿™é‡Œä¸æ¬¢è¿ç†Šã€‚â€\\n\\nç†Šè€¸è€¸è‚©ï¼Œè¯´ï¼šâ€œé‚£æˆ‘æ¢ä¸ªåœ°æ–¹ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿æ— å¥ˆåœ°è¯´ï¼šâ€œä½ æ€»æ˜¯è¿™æ ·ï¼Œç†Šã€‚â€\\n\\nç†Šå›ç­”ï¼šâ€œé‚£æˆ‘æ¢ä¸ªèº«ä»½ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ åˆ°åº•æ˜¯è°ï¼Ÿâ€\\n\\nç†Šï¼šâ€œæˆ‘æ˜¯â€˜æˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯â€™ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ çœŸæ˜¯ä¸ªå“²å­¦ç†Šã€‚â€ ğŸ˜„\\n\\nè¿™ä¸ªç¬‘è¯æœ‰ç‚¹æ–‡å­—æ¸¸æˆçš„æ„å‘³ï¼Œä½†å¸Œæœ›ä½ å–œæ¬¢ï¼å¦‚æœä½ æƒ³è¦æ›´æç¬‘æˆ–æ›´æ¸©é¦¨çš„ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ã€‚',\n",
              " 'å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºç‹ç‹¸çš„çŸ­ç¬‘è¯ï¼š\\n\\næœ‰ä¸€å¤©ï¼Œä¸€åªç‹ç‹¸èµ°è¿›äº†ç†å‘åº—ï¼Œå¯¹ç†å‘å¸ˆè¯´ï¼šâ€œæˆ‘æƒ³å‰ªä¸ªå‘å‹ã€‚â€\\n\\nç†å‘å¸ˆé—®ï¼šâ€œä½ æƒ³å‰ªæˆä»€ä¹ˆæ ·å­ï¼Ÿâ€\\n\\nç‹ç‹¸å›ç­”ï¼šâ€œæˆ‘æƒ³å‰ªæˆâ€˜ç‹ç‹¸â€™çš„æ ·å­ã€‚â€\\n\\nç†å‘å¸ˆæƒŠè®¶åœ°é—®ï¼šâ€œé‚£æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Ÿâ€\\n\\nç‹ç‹¸ç¬‘ç€è¯´ï¼šâ€œå°±æ˜¯â€¦â€¦åƒæˆ‘è¿™æ ·ï¼â€']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.batch([{\"topic\": \"ç†Š\"}, {\"topic\": \"ç‹ç‹¸\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307a41d2",
      "metadata": {
        "id": "307a41d2"
      },
      "source": [
        "### 5.3 streamæ¥å£\n",
        "\n",
        "æ¥ä¸‹æ¥æˆ‘ä»¬åœ¨çœ‹çœ‹`stream`æ¥å£ï¼Œä¹Ÿå°±æ˜¯æµå¼è¾“å‡ºå†…å®¹ï¼Œè¿™æ ·çš„åŠŸèƒ½å¾ˆæœ‰å¿…è¦ï¼Œæœ‰æ—¶å€™å¯ä»¥å…å»ç”¨æˆ·ç­‰å¾…çš„çƒ¦æ¼ï¼Œè®©ç”¨æˆ·çœ‹åˆ°ä¸€ä¸ªä¸€ä¸ªè¯è¹¦å‡ºæ¥è€Œä¸æ˜¯ä¸€ä¸ªç©ºçš„å±å¹•ï¼Œè¿™æ ·ä¼šå¸¦æ¥æ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f934e46d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f934e46d",
        "outputId": "872109e2-47cb-4da6-a439-eb010ed3530d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "å½“ç„¶\n",
            "å¯ä»¥\n",
            "ï¼\n",
            "è¿™é‡Œ\n",
            "æœ‰ä¸€ä¸ª\n",
            "å…³äº\n",
            "ç†Š\n",
            "çš„\n",
            "çŸ­\n",
            "ç¬‘è¯\n",
            "ï¼š\n",
            "\n",
            "\n",
            "æœ‰ä¸€å¤©\n",
            "ï¼Œ\n",
            "ä¸€åª\n",
            "ç†Š\n",
            "èµ°è¿›\n",
            "äº†ä¸€\n",
            "å®¶\n",
            "é…’å§\n",
            "ï¼Œ\n",
            "ç‚¹\n",
            "äº†ä¸€\n",
            "æ¯\n",
            "å•¤é…’\n",
            "ï¼Œ\n",
            "ç„¶å\n",
            "è¯´\n",
            "ï¼šâ€œ\n",
            "æˆ‘\n",
            "åªæƒ³\n",
            "å®‰é™\n",
            "åœ°\n",
            "å–\n",
            "ä¸€æ¯\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "é…’\n",
            "ä¿\n",
            "çœ‹äº†çœ‹\n",
            "å®ƒ\n",
            "ï¼Œ\n",
            "è¯´\n",
            "ï¼šâ€œ\n",
            "æŠ±æ­‰\n",
            "ï¼Œ\n",
            "æˆ‘ä»¬\n",
            "è¿™é‡Œ\n",
            "ä¸\n",
            "æ¬¢è¿\n",
            "ç†Š\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "ç†Š\n",
            "è€¸\n",
            "è€¸\n",
            "è‚©\n",
            "ï¼Œ\n",
            "è¯´\n",
            "ï¼šâ€œ\n",
            "é‚£\n",
            "æˆ‘\n",
            "æ¢ä¸ª\n",
            "åœ°æ–¹\n",
            "ï¼Œ\n",
            "æˆ‘\n",
            "åªæƒ³\n",
            "å®‰é™\n",
            "åœ°\n",
            "å–\n",
            "ä¸€æ¯\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "é…’\n",
            "ä¿\n",
            "æ— å¥ˆ\n",
            "åœ°è¯´\n",
            "ï¼šâ€œ\n",
            "ä½ \n",
            "æ€»æ˜¯\n",
            "è¿™æ ·\n",
            "ï¼Œ\n",
            "ç†Š\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "ç†Š\n",
            "å›ç­”\n",
            "ï¼šâ€œ\n",
            "é‚£\n",
            "æˆ‘\n",
            "æ¢ä¸ª\n",
            "èº«ä»½\n",
            "ï¼Œ\n",
            "æˆ‘\n",
            "åªæƒ³\n",
            "å®‰é™\n",
            "åœ°\n",
            "å–\n",
            "ä¸€æ¯\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "é…’\n",
            "ä¿\n",
            "ï¼šâ€œ\n",
            "â€¦â€¦\n",
            "ä½ \n",
            "åˆ°åº•\n",
            "æ˜¯è°\n",
            "ï¼Ÿ\n",
            "â€\n",
            "\n",
            "\n",
            "ç†Š\n",
            "ï¼šâ€œ\n",
            "æˆ‘æ˜¯\n",
            "â€˜\n",
            "æˆ‘\n",
            "åªæƒ³\n",
            "å®‰é™\n",
            "åœ°\n",
            "å–\n",
            "ä¸€æ¯\n",
            "â€™\n",
            "ã€‚â€\n",
            "\n",
            "\n",
            "é…’\n",
            "ä¿\n",
            "ï¼šâ€œ\n",
            "â€¦â€¦\n",
            "ä½ \n",
            "çœŸæ˜¯\n",
            "ä¸ª\n",
            "å“²å­¦\n",
            "ç†Š\n",
            "ã€‚â€\n",
            " ğŸ˜„\n",
            "\n",
            "\n",
            "\n",
            "è¿™ä¸ª\n",
            "ç¬‘è¯\n",
            "æœ‰ç‚¹\n",
            "æ–‡å­—\n",
            "æ¸¸æˆ\n",
            "çš„\n",
            "æ„å‘³\n",
            "ï¼Œ\n",
            "ä½†\n",
            "å¸Œæœ›\n",
            "ä½ å–œæ¬¢\n",
            "ï¼\n",
            "å¦‚æœä½ \n",
            "æƒ³è¦\n",
            "æ›´\n",
            "æç¬‘\n",
            "æˆ–\n",
            "æ›´\n",
            "æ¸©é¦¨\n",
            "çš„\n",
            "ç‰ˆæœ¬\n",
            "ï¼Œ\n",
            "ä¹Ÿå¯ä»¥\n",
            "å‘Šè¯‰æˆ‘\n",
            "ã€‚\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for t in chain.stream({\"topic\": \"ç†Š\"}):\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda98771",
      "metadata": {
        "id": "fda98771"
      },
      "source": [
        "### 5.4 å¼‚æ­¥æ¥å£\n",
        "\n",
        "æˆ‘ä»¬è¿˜å¯ä»¥å°è¯•å¼‚æ­¥æ¥è°ƒç”¨ï¼Œä½¿ç”¨`ainvoke`æ¥è°ƒç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "cd372fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "cd372fec",
        "outputId": "1232ac0b-7900-493c-aec6-7b99abb928d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºç†Šçš„çŸ­ç¬‘è¯ï¼š\\n\\næœ‰ä¸€å¤©ï¼Œä¸€åªç†Šèµ°è¿›äº†ä¸€å®¶é…’å§ï¼Œç‚¹äº†ä¸€æ¯å•¤é…’ï¼Œç„¶åè¯´ï¼šâ€œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿çœ‹äº†çœ‹å®ƒï¼Œè¯´ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘ä»¬è¿™é‡Œä¸æ¬¢è¿ç†Šã€‚â€\\n\\nç†Šè€¸è€¸è‚©ï¼Œè¯´ï¼šâ€œé‚£æˆ‘æ¢ä¸ªåœ°æ–¹ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿æ— å¥ˆåœ°è¯´ï¼šâ€œä½ æ€»æ˜¯è¿™æ ·ï¼Œç†Šã€‚â€\\n\\nç†Šå›ç­”ï¼šâ€œé‚£æˆ‘æ¢ä¸ªèº«ä»½ï¼Œæˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ åˆ°åº•æ˜¯è°ï¼Ÿâ€\\n\\nç†Šï¼šâ€œæˆ‘æ˜¯â€˜æˆ‘åªæƒ³å®‰é™åœ°å–ä¸€æ¯â€™ã€‚â€\\n\\né…’ä¿ï¼šâ€œâ€¦â€¦ä½ çœŸæ˜¯ä¸ªå“²å­¦ç†Šã€‚â€ ğŸ˜„\\n\\nè¿™ä¸ªç¬‘è¯æœ‰ç‚¹æ–‡å­—æ¸¸æˆçš„æ„å‘³ï¼Œä½†å¸Œæœ›ä½ å–œæ¬¢ï¼å¦‚æœä½ æƒ³è¦æ›´æç¬‘æˆ–æ›´æ¸©é¦¨çš„ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ã€‚'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = await chain.ainvoke({\"topic\": \"ç†Š\"})\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926c23d0",
      "metadata": {
        "id": "926c23d0"
      },
      "source": [
        "## å…­ã€è‹±æ–‡æç¤ºè¯"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nf-C5Y-9TR2d",
      "metadata": {
        "id": "nf-C5Y-9TR2d"
      },
      "source": [
        "**ä¸€ã€æ„å»ºç®€å•é“¾**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "urymAcXkTOQ2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "urymAcXkTOQ2",
        "outputId": "97d1aee3-86a0-44cb-c534-6db4ffb6a11b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Why don't bears ever get cold?  \\nBecause they always have *paws* in the snow! â„ï¸ğŸ»\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me a short joke about {topic}\"\n",
        ")\n",
        "model = ChatOpenAI(temperature=0, model_name=\"Qwen/Qwen3-8B\", max_tokens=4096,\n",
        "                   openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
        "                   seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
        "                   extra_body={\n",
        "                       \"enable_thinking\": False\n",
        "                   }\n",
        "                  )\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34b6bd6",
      "metadata": {},
      "source": [
        "**2.1 æ„å»ºç®€å•æ–‡æ¡£æ•°æ®åº“**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "J-IpScccTHtL",
      "metadata": {
        "id": "J-IpScccTHtL"
      },
      "outputs": [],
      "source": [
        "embedding_model = OpenAIEmbeddings(\n",
        "    openai_api_key=API_KEY,\n",
        "    openai_api_base=BASE_URL,\n",
        "    model=\"BAAI/bge-m3\"\n",
        ")\n",
        "\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
        "    embedding=embedding_model\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4nWE8nLjTJuT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nWE8nLjTJuT",
        "outputId": "65742853-5146-4a1c-fb0b-d1e456532b95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
              " Document(metadata={}, page_content='bears like to eat honey')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"where did harrison work?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "hygSW50bTXzV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hygSW50bTXzV",
        "outputId": "2f88f2d7-781d-41d0-c50e-fa18e0420c3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
              " Document(metadata={}, page_content='bears like to eat honey')]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"what do bears like to eat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "-6iG51i5TZGJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-6iG51i5TZGJ",
        "outputId": "29de378b-2151-43fc-d2fc-f6a1b8d16896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Harrison worked at Kensho.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = RunnableMap({\n",
        "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "}) | prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabda125",
      "metadata": {},
      "source": [
        "**3.2 ä½¿ç”¨RunnableMap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "JoLBmwfETg1L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoLBmwfETg1L",
        "outputId": "73127639-c19e-400c-e26e-8f68dfd93635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
              "  Document(metadata={}, page_content='bears like to eat honey')],\n",
              " 'question': 'where did harrison work?'}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = RunnableMap({\n",
        "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "})\n",
        "\n",
        "inputs.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HqjgfGT8Tj2Z",
      "metadata": {
        "id": "HqjgfGT8Tj2Z"
      },
      "source": [
        "**3.1 å•å‡½æ•°ç»‘å®š**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "_XZPKC1_Th6S",
      "metadata": {
        "id": "_XZPKC1_Th6S"
      },
      "outputs": [],
      "source": [
        "weather_search_fn {\n",
        "  \"name\": \"weather_search\",\n",
        "  \"description\": \"Search for weather given an airport code\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"airport_code\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The airport code to get the weather for\"\n",
        "      },\n",
        "    },\n",
        "    \"required\": [\"airport_code\"]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "0UPE0nWDTm3T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UPE0nWDTm3T",
        "outputId": "a4762623-c42f-4950-a21e-da73f7efe0c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '01975f257c4ff746c35bd2427ef2e53e', 'function': {'arguments': ' {\"airport_code\": \"sf\"}', 'name': 'weather_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 175, 'total_tokens': 183, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '01975f257b2320284d4fbb03b6fc47ae', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6245c15e-d178-41cf-80cc-2180bb04e54e-0', tool_calls=[{'name': 'weather_search', 'args': {'airport_code': 'sf'}, 'id': '01975f257c4ff746c35bd2427ef2e53e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 175, 'output_tokens': 8, 'total_tokens': 183, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "model = model.bind(tools=[\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": weather_search_fn\n",
        "    },\n",
        "])\n",
        "\n",
        "runnable = prompt | model\n",
        "\n",
        "runnable.invoke({\"input\": \"what is the weather in sf\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6a3fd8",
      "metadata": {},
      "source": [
        "**3.2 å¤šä¸ªå‡½æ•°ç»‘å®š**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "U2R9nKncTpy6",
      "metadata": {
        "id": "U2R9nKncTpy6"
      },
      "outputs": [],
      "source": [
        "weather_search = {\n",
        "  \"name\": \"weather_search\",\n",
        "  \"description\": \"Search for weather given an airport code\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"airport_code\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The airport code to get the weather for\"\n",
        "      },\n",
        "    },\n",
        "    \"required\": [\"airport_code\"]\n",
        "  }\n",
        "}\n",
        "sports_search_fn = {\n",
        "  \"name\": \"sports_search\",\n",
        "  \"description\": \"Search for news of recent sport events\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"team_name\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The sports team to search for\"\n",
        "      },\n",
        "    },\n",
        "    \"required\": [\"team_name\"]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "i9yES-wwTrYO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9yES-wwTrYO",
        "outputId": "c4e1ae94-d087-454b-a8c1-7fab9df2b790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '01975f268b31eb50420366c9eec21aab', 'function': {'arguments': ' {\"team_name\": \"Patriots\"}', 'name': 'sports_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 252, 'total_tokens': 262, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '01975f268a6fe8d58e92cedb8afa1587', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3b98e3a5-66b2-4c3e-8558-f60ee06b616a-0', tool_calls=[{'name': 'sports_search', 'args': {'team_name': 'Patriots'}, 'id': '01975f268b31eb50420366c9eec21aab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 252, 'output_tokens': 10, 'total_tokens': 262, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = model.bind(tools=[\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": weather_search_fn\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": sports_search_fn\n",
        "    }\n",
        "])\n",
        "\n",
        "runnable = prompt | model\n",
        "\n",
        "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300a9405",
      "metadata": {},
      "source": [
        "**4.1 ä½¿ç”¨æ—©æœŸæ¨¡å‹æ ¼å¼åŒ–è¾“å‡º**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4lECkukwT4ua",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "4lECkukwT4ua",
        "outputId": "88c67d19-6d26-406a-9d26-08827794dc4e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_model = OpenAI(\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    model=\"gpt-3.5-turbo-instruct\"\n",
        ")\n",
        "simple_chain = simple_model | json.loads\n",
        "\n",
        "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\"\n",
        "\n",
        "simple_model.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c60800",
      "metadata": {},
      "source": [
        "**æ—©æœŸæ¨¡å‹ä¸æ”¯æŒï¼Œä¼šå‡ºç°è§£ç é”™è¯¯**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "aX0oo-25T9hE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "aX0oo-25T9hE",
        "outputId": "8425f5f7-5891-4448-d67d-be89208e05a9"
      },
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 9 column 1 (char 125)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-7b2363c45b31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3505\u001b[0m         \u001b[0;34m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3507\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   3508\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             output = cast(\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3381\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   3384\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 9 column 1 (char 125)"
          ]
        }
      ],
      "source": [
        "simple_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935a60b7",
      "metadata": {},
      "source": [
        "**4.2 è¾ƒæ–°çš„æ¨¡å‹èƒ½å¤Ÿæ ¼å¼åŒ–è¾“å‡º**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "oLFppvMMT-w7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLFppvMMT-w7",
        "outputId": "3fa0a0c1-3e9b-44ca-acaa-4b5fe5915c43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'poems': [{'title': 'The Road Not Taken',\n",
              "   'author': 'Robert Frost',\n",
              "   'first_line': 'Two roads diverged in a yellow wood,'},\n",
              "  {'title': 'Still I Rise',\n",
              "   'author': 'Maya Angelou',\n",
              "   'first_line': 'You may write me down in history'},\n",
              "  {'title': 'Ode to a Nightingale',\n",
              "   'author': 'John Keats',\n",
              "   'first_line': 'My heart aches, and aches, and still I rise.'}]}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatOpenAI(temperature=0, model_name=\"Qwen/Qwen3-8B\", max_tokens=4096,\n",
        "                   openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
        "                   seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
        "                   extra_body={\n",
        "                       \"enable_thinking\": False\n",
        "                   }\n",
        "                  )\n",
        "\n",
        "chain = model | StrOutputParser() | json.loads\n",
        "\n",
        "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\"\n",
        "\n",
        "chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c76fe472",
      "metadata": {},
      "source": [
        "**4.3 fallbackæœºåˆ¶**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "mWQ6qEwSUA0y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWQ6qEwSUA0y",
        "outputId": "1ca395fa-976f-4f5d-c0f4-f2bcbd0ba325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'Whispers of the Wind',\n",
              "  'author': 'Emily Rivers',\n",
              "  'first_line': 'Softly it comes, the whisper of the wind'},\n",
              " 'poem2': {'title': 'Silent Serenade',\n",
              "  'author': 'Jacob Moore',\n",
              "  'first_line': 'In the stillness of night, a silent serenade'},\n",
              " 'poem3': {'title': 'Dancing Shadows',\n",
              "  'author': 'Sophia Anderson',\n",
              "  'first_line': 'Shadows dance upon the moonlit floor'}}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_chain = simple_chain.with_fallbacks([chain])\n",
        "\n",
        "final_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd87734",
      "metadata": {},
      "source": [
        "**äº”ã€æ¥å£**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "oenACTHsUFlm",
      "metadata": {
        "id": "oenACTHsUFlm"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a short joke about {topic}\"\n",
        ")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5feb063",
      "metadata": {},
      "source": [
        "**5.1 invokeæ¥å£**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "uhpMBbexUHK2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uhpMBbexUHK2",
        "outputId": "bd63b7f7-7d11-474e-bdd7-ad59a45323ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Why don't bears play hide and seek with their friends?  \\nBecause good luck finding themâ€”theyâ€™re always *bear* ing the fruit! ğŸ»ğŸ\""
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae6e2de",
      "metadata": {},
      "source": [
        "**5.2 batchæ¥å£**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ptSp8UhQUILV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptSp8UhQUILV",
        "outputId": "b3125d7e-c35b-4ea3-999f-75543f36ac34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Why don't bears play hide and seek with their cubs?  \\nBecause the cubs always find themâ€”*bear* is the best game ever! ğŸ»ğŸ˜„\",\n",
              " \"Why don't frogs ever get cold?  \\nBecause they always carry a *toad* (towel) with them! ğŸ¸ğŸ§º\"]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826b9ed7",
      "metadata": {},
      "source": [
        "**5.3 streamæ¥å£**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "Ehj9MzGPUI_I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehj9MzGPUI_I",
        "outputId": "239b158c-6283-4892-d6f5-bcbe69329cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Why\n",
            " don\n",
            "'t\n",
            " bears\n",
            " play\n",
            " hide\n",
            " and\n",
            " seek\n",
            " with\n",
            " their\n",
            " friends\n",
            "?\n",
            "  \n",
            "\n",
            "Because\n",
            " good\n",
            " luck\n",
            " finding\n",
            " them\n",
            "â€”they\n",
            "â€™re\n",
            " always\n",
            " *\n",
            "bear\n",
            "*\n",
            " ing\n",
            " the\n",
            " fruit\n",
            "!\n",
            " ğŸ»\n",
            "ğŸ\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for t in chain.stream({\"topic\": \"bears\"}):\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2858691",
      "metadata": {},
      "source": [
        "**5.4 å¼‚æ­¥æ¥å£**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "xucFn07uUJ7Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xucFn07uUJ7Z",
        "outputId": "54545335-949b-463d-b8e2-41bb7c1076c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Why don't bears play hide and seek with their friends?  \\nBecause good luck finding themâ€”theyâ€™re always *bear* ing the fruit! ğŸ»ğŸ\""
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
        "response"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
