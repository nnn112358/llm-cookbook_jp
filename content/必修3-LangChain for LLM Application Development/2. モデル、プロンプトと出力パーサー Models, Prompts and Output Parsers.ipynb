{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 第2章 モデル、プロンプト、出力パーサー\n\n - [1. OpenAI API キーの設定](#1-openai-api-キーの設定)\n - [2. OpenAIの直接使用](#2-openaiの直接使用)\n     - [2.1 1+1の計算](#21-11の計算)\n     - [2.2 海賊メールをアメリカ英語で表現](#22-海賊メールをアメリカ英語で表現)\n     - [2.3 日本語版](#23-日本語版)\n - [3. LangChain経由でのOpenAI使用](#3-langchain経由でのopenai使用)\n     - [3.1 モデル](#31-モデル)\n     - [3.2 プロンプトテンプレート](#32-プロンプトテンプレート)\n         - [3.2.1 LangChainプロンプトテンプレートの使用](#321-langchainプロンプトテンプレートの使用)\n         - [3.2.2 日本語版](#322-日本語版)\n         - [3.2.3 プロンプトテンプレートが必要な理由](#323-プロンプトテンプレートが必要な理由)\n     - [3.3 出力パーサー](#33-出力パーサー)\n         - [3.3.1 出力パーサーがない場合](#331-出力パーサーがない場合)\n         - [3.3.2 日本語版](#332-日本語版)\n         - [3.3.3 LangChain出力パーサー](#333-langchain出力パーサー)\n         - [3.3.4 日本語版](#334-日本語版)\n - [4. 補足資料](#4-補足資料)\n     - [4.1 思考の連鎖推論（ReAct）](#41-思考の連鎖推論react)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "## 1. OpenAI API キーの設定\n\n[OpenAI アカウント](https://platform.openai.com/account/api-keys)にログインしてAPI キーを取得し、環境変数として設定してください。\n\n- グローバル環境変数として設定したい場合は、[知乎文章](https://zhuanlan.zhihu.com/p/627665725)を参考にしてください。\n- ローカル/プロジェクト環境変数として設定したい場合は、このファイルのディレクトリに`.env`ファイルを作成し、ファイルを開いて以下の内容を入力してください。\n\n    <p style=\"font-family:verdana; font-size:12px;color:green\">\n    OPENAI_API_KEY=\"your_api_key\" \n    </p>\n  \n  \"your_api_key\"をあなた自身のAPI キーに置き換えてください"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# 读取本地/项目的环境变量。\n",
        "\n",
        "# find_dotenv()寻找并定位.env文件的路径\n",
        "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
        "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# 获取环境变量 OPENAI_API_KEY\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "## 2. OpenAIの直接使用\n\nまず、OpenAIのAPIを直接呼び出すことから始めましょう。\n\n`get_completion`関数は`openai`のラッパー関数で、与えられたプロンプト（prompt）に対して対応する回答を出力します。この関数は2つのパラメータを含みます\n   \n   - `prompt` 必須入力パラメータ。モデルに与える**プロンプトで、質問や、モデルに手伝ってもらいたいこと**（テキストの文体変更、翻訳、メッセージ返信など）が可能です。\n   - `model` 非必須入力パラメータ。デフォルトでgpt-3.5-turboを使用します。他のモデルも選択できます。\n   \nここでのプロンプトは、私たちがchatgptに与える質問に対応し、関数が出力する結果は、chatgptが私たちに与える回答に対応します。"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    \n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    client = OpenAI()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, \n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "### 2.1 1+1の計算\n\n簡単な例から始めましょう - 日本語と英語でモデルに質問してみます\n\n- 日本語プロンプト： `1+1は何ですか？`\n- 英語プロンプト： `What is 1+1?`"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 日本語\nget_completion(\"1+1は何ですか？\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1+1 equals 2.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 英文\n",
        "get_completion(\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "### 2.2 海賊メールをアメリカ英語で表現\n\n上記の簡単な例では、モデル`gpt-3.5-turbo`が1+1は何かという質問に回答しました。\n\n今度はもう少し複雑な例を見てみましょう：\n\n私たちがEコマース会社の従業員で、顧客が海賊Aだと仮定しましょう。彼は私たちのWebサイトでスムージーを作るためのブレンダーを購入しました。スムージーを作る過程で、スムージーの蓋が飛んでしまい、キッチンの壁が汚れてしまいました。そこで海賊Aは私たちのカスタマーサービスセンターに以下のメール`customer_email`を送りました："
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse,\\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "私たちのカスタマーサービススタッフは、海賊の言い回しが少し理解しにくいと感じています。今、2つの小さな目標を実現したいと思います：\n\n- モデルに海賊のメールをアメリカ英語の表現方法で翻訳してもらい、カスタマーサービススタッフがより理解しやすくする。*ここでの海賊の英語表現は英語の方言として理解でき、関西弁と標準語の関係のようなものです。\n- モデルが翻訳する際に穏やかで敬意のあるトーンで表現してもらい、カスタマーサービススタッフの気分も良くする。\n\nこの2つの小さな目標に基づいて、テキスト表現スタイル：`style`を定義します"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": "# アメリカ英語 + 穏やか、敬意のあるトーン\nstyle = \"\"\"American English \\\nin a calm and respectful tone\n\"\"\""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "次にやるべきことは、`customer_email`と`style`を組み合わせて私たちのプロンプト:`prompt`を構築することです"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": "# 指定されたトーンに従って変換するようモデルに要求\nprompt = f\"\"\"Translate the text \\\nthat is delimited by triple backticks \ninto a style that is {style}.\ntext: ```{customer_email}```\n\"\"\"\n\nprint(prompt)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "`prompt`が構築できたので、`get_completion`を呼び出して私たちが望む結果を得ることができます - 穏やかで敬意のあるトーンのアメリカ英語で表現された海賊言葉のメール"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Ah, I'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "言語スタイル変換の前後を比較すると、より正式な言葉遣いになり、極端な感情表現が置き換えられ、感謝の気持ちが表現されています。\n\n✨ プロンプトを修正して、どんな異なる結果が得られるか試してみてください😉"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "### 2.3 日本語版"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 標準日本語 + 穏やか、敬意のあるトーン\nstyle = \"\"\"正式な日本語 \\\n穏やかで敬意のあるトーンで\n\"\"\""
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 非正式な表現\ncustomer_email = \"\"\"   \nああ、腹が立つよ、\\\nミキサーの蓋が飛んで、\\\nスムージーがキッチンの壁に飛び散ったんだ！\\\nもっと悪いことに、保証はキッチンの掃除費用をカバーしていない。\\\n今すぐ君の助けが必要だ、仲間よ！\n\"\"\""
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 指定されたトーンに従って変換するようモデルに要求\nprompt = f\"\"\"三つのバッククォートで区切られたテキストを\\\n{style}スタイルに翻訳してください。\nテキスト: ```{customer_email}```\n\"\"\"\n\nprint(prompt)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'尊敬的先生/女士，\\n\\n我感到非常不安，因为我的搅拌机盖子掉了，导致奶昔溅到了厨房的墙上！更糟糕的是，保修不包括清洁厨房的费用。我现在需要您的帮助，朋友！感谢您的理解和支持。'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = get_completion(prompt)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "## 3. LangChain経由でのOpenAI使用\n\n前の部分では、ラッパー関数`get_completion`を通じてOpenAIを直接呼び出し、方言メールの翻訳を完了し、穏やかで敬意のあるトーン、正式な日本語で表現されたメールを得ました。\n\nLangChainを使用して同じ機能を実装してみましょう。"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "### 3.1 モデル\n\n`langchain_community.chat_models.openai`からOpenAIの対話モデル`ChatOpenAI`をインポートします。OpenAI以外にも、`langchain_community.chat_models`は他の対話モデルも統合しています。詳細は[Langchain公式ドキュメント](https://python.langchain.com/en/latest/modules/models/chat/integrations.html)をご確認ください。"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": "# ここではtemperatureパラメータを0.0に設定し、生成される回答のランダム性を減らします。\n# 毎回異なる新しいアイデアの回答を得たい場合は、このパラメータを調整してみてください。\nchat = ChatOpenAI(temperature=0)\nchat"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "上記の出力は、ChatOpenAIのデフォルトモデルが`gpt-3.5-turbo`であることを示しています"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.2 プロンプトテンプレート\n\n前の例では、[f文字列](https://docs.python.org/ja/3/tutorial/inputoutput.html#tut-f-strings)を通じてPython表現の値`style`と`customer_email`を`prompt`文字列内に追加しました。\n\n```python\nprompt = f\"\"\"Translate the text \\\nthat is delimited by triple backticks \ninto a style that is {style}.\ntext: ```{customer_email}```\n\"\"\"\n```\n`langchain`はプロンプトを便利かつ迅速に構築・使用するためのインターフェースを提供します。今度は`langchain`を使用してプロンプトを構築する方法を見てみましょう。"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "#### 3.2.1 LangChainプロンプトテンプレートの使用"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "##### 1️⃣ プロンプトテンプレート文字列の構築\nプロンプトテンプレート文字列：`template_string`を構築します"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "##### 2️⃣ LangChainプロンプトテンプレートの構築\n`ChatPromptTemplate.from_template()`関数を呼び出して、上記のプロンプトテンプレート文字`template_string`をプロンプトテンプレート`prompt_template`に変換します"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['style', 'text'] template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'\n"
          ]
        }
      ],
      "source": [
        "print(prompt_template.messages[0].prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "上記の出力から、`prompt_template`には2つの入力変数があることがわかります：`style`と`text`。"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['style', 'text']\n"
          ]
        }
      ],
      "source": [
        "print(prompt_template.messages[0].prompt.input_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 3️⃣ テンプレートを使用して顧客メッセージプロンプトを取得\n\nlangchainプロンプトテンプレート`prompt_template`には2つの入力変数が必要です：`style`と`text`。ここではそれぞれ以下に対応します\n- `customer_style`: 希望する顧客メールスタイル\n- `customer_email`: 顧客の元のメールテキスト。"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse, \\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "指定された`customer_style`と`customer_email`に対して、プロンプトテンプレート`prompt_template`の`format_messages`メソッドを使用して希望する顧客メッセージ`customer_messages`を生成できます。"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'langchain_core.messages.human.HumanMessage'>\n"
          ]
        }
      ],
      "source": [
        "print(type(customer_messages))\n",
        "print(type(customer_messages[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "`customer_messages`変数の型はリスト（`list`）で、リスト内の要素の変数型はlangchainカスタムメッセージ（`langchain.schema.HumanMessage`）であることがわかります。\n\n最初の要素を印刷すると以下が得られます："
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\"\n"
          ]
        }
      ],
      "source": [
        "print(customer_messages[0])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 日本語プロンプト\nfrom langchain.prompts import ChatPromptTemplate\n\ntemplate_string = \"\"\"三つのバッククォートで区切られたテキストを\\\n{style}スタイルに翻訳してください。\\\nテキスト: ```{text}```\n\"\"\"\nprompt_template = ChatPromptTemplate.from_template(template_string)\n\ncustomer_style = \"\"\"正式な日本語 \\\n穏やかで敬意のあるトーンで\n\"\"\"\n\ncustomer_email = \"\"\"\nああ、腹が立つよ、\\\nミキサーの蓋が飛んで、\\\nスムージーがキッチンの壁に飛び散ったんだ！\\\nもっと悪いことに、保証はキッチンの掃除費用をカバーしていない。\\\n今すぐ君の助けが必要だ、仲間よ！\n\"\"\"\n\ncustomer_messages = prompt_template.format_messages(\n                    style=customer_style,\n                    text=customer_email)\n\n\nprint(customer_messages[0])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 4️⃣ chatモデルを呼び出して顧客メッセージスタイルを変換\n\n今度は[モデル](#model)部分で定義したchatモデルを呼び出して、顧客メッセージスタイルの変換を実現できます。これまでで、前の部分でのタスクを実装しました。"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "customer_response = chat.invoke(customer_messages, temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "非常抱歉听到您的困扰。我理解您的不快，因为搅拌机盖掉了，导致奶昔溅到了厨房的墙上。更令人不安的是，保修不包括清洁厨房的费用。现在我需要您的帮助，朋友。让我们一起解决这个问题。感谢您的理解和支持。\n"
          ]
        }
      ],
      "source": [
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "非常抱歉听到您的困扰。我理解您的不快，因为搅拌机盖掉了，导致奶昔溅到了厨房的墙上。更令人不安的是，保修不包括清洁厨房的费用。现在我需要您的帮助，朋友。让我们一起解决这个问题。感谢您的理解和支持。\n"
          ]
        }
      ],
      "source": [
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 5️⃣ テンプレートを使用して返信メッセージプロンプトを取得\n\n次に、さらに進んで、カスタマーサービススタッフの返信メッセージを海賊の言語スタイルに変換し、メッセージが比較的丁寧であることを確認します。\n\nここでは、2️⃣ステップで構築したlangchainプロンプトテンプレートを引き続き使用して、返信メッセージプロンプトを取得できます。"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "service_reply = \"\"\"Hey there customer, \\\n",
        "the warranty does not cover \\\n",
        "cleaning expenses for your kitchen \\\n",
        "because it's your fault that \\\n",
        "you misused your blender \\\n",
        "by forgetting to put the lid on before \\\n",
        "starting the blender. \\\n",
        "Tough luck! See ya!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "service_style_pirate = \"\"\"\\\n",
        "a polite tone \\\n",
        "that speaks in English Pirate\\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "把由三个反引号分隔的文本翻译成一种a polite tone that speaks in English Pirate风格。文本: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "service_messages = prompt_template.format_messages(\n",
        "    style=service_style_pirate,\n",
        "    text=service_reply)\n",
        "\n",
        "print(service_messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 6️⃣ chatモデルを呼び出して返信メッセージスタイルを変換\n\n[モデル](#model)部分で定義したchatモデルを呼び出して返信メッセージスタイルを変換します"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lta/anaconda3/envs/cookbook/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ahoy there, me hearty customer! The warranty be not coverin' the cleanin' expenses for yer galley because 'tis yer own fault for misusin' yer blender by forgettin' to put the lid on afore startin' the blender. Tough luck, matey! Fare thee well!\n"
          ]
        }
      ],
      "source": [
        "service_response = chat(service_messages)\n",
        "print(service_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3.2.2 日本語版"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "service_reply = \"\"\"こんにちは、お客様、 \\\n保証は台所の清掃費用をカバーしません、 \\\nブレンダーを始動する前に \\\n蓋をつけるのを忘れてブレンダーを誤用したためです。 \\\nこれはあなたのミスです。 \\\n運が悪い！ さようなら！\n\"\"\"\n\nservice_style_pirate = \"\"\"\\\n丁寧な口調で \\\n正式な日本語を使って \\\n\"\"\"\nservice_messages = prompt_template.format_messages(\n    style=service_style_pirate,\n    text=service_reply)\n\nprint(service_messages[0].content)"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "尊敬的顾客，根据我们的保修政策，很遗憾告知您，厨房清洁费用不在保修范围内。这是因为在使用搅拌机之前，您忘记盖上盖子而导致搅拌机误用，这属于您的责任范围。非常抱歉给您带来不便。祝您好运，再见。\n"
          ]
        }
      ],
      "source": [
        "service_response = chat(service_messages)\n",
        "print(service_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": "#### 3.2.3 プロンプトテンプレートが必要な理由"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "比較的複雑なシナリオに適用する場合、プロンプトは非常に長く、多くの詳細を含む可能性があります。**プロンプトテンプレートを使用することで、設計されたプロンプトをより便利に再利用できます**。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "以下は比較的長いプロンプトテンプレートの例です。学生がオンライン学習を行い宿題を提出し、以下のプロンプトを通じて学生が提出した宿題の採点を実現します。"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 英語版\nprompt = \"\"\" Your task is to determine if the student's solution is correct or not\n\n    To solve the problem do the following:\n    - First, workout your own solution to the problem\n    - Then compare your solution to the student's solution \n    and evaluate if the student's solution is correct or not.\n    ...\n    Use the following format:\n    Question:\n    ```\n    question here\n    ```\n    Student's solution:\n    ```\n    student's solution here\n    ```\n    Actual solution:\n    ```\n    ...\n    steps to work out the solution and your solution here\n    ```\n    Is the student's solution the same as actual solution \\\n    just calculated:\n    ```\n    yes or no\n    ```\n    Student grade\n    ```\n    correct or incorrect\n    ```\n    \n    Question:\n    ```\n    {question}\n    ```\n    Student's solution:\n    ```\n    {student's solution}\n    ```\n    Actual solution:\n    \n    \"\"\""
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 日本語版\nprompt = \"\"\" あなたのタスクは、学生の解答が正しいかどうかを判断することです\n\nこの問題を解決するために、以下を実行してください：\n - まず、問題に対するあなた自身の解決策を作成してください\n - 次に、あなたの解決策と学生の解決策を比較し\n 学生の解決策が正しいかどうかを評価してください。\n...\n以下の形式を使用してください:\n\n問題:\n```\n問題文\n```\n学生の解答:\n```\n学生の解答文\n```\n実際の解答:\n```\n...\n解決策を作成する手順とあなたの解決策をここに参照してください\n```\n学生の解答と実際の解答が同じかどうか \\\n計算のみ：\n```\nはい または いいえ\n```\n学生の成績\n```\n正解 または 不正解\n```\n\n問題:\n```\n{question}\n```\n学生の解答:\n```\n{student's solution}\n```\n実際の解答:\n\n\"\"\""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": "この他に、LangChainは一般的なシナリオ用のプロンプトテンプレートも提供しています。例えば、自動要約、質問応答、SQLデータベースへの接続、異なるAPIへの接続などです。LangChain内蔵のプロンプトテンプレートを使用することで、プロンプトの設計と構築に時間をかけることなく、素早く自分の大型モデルアプリケーションを構築できます。\n\n最後に、大型モデルアプリケーションを構築する際、通常はモデルの出力が指定された形式になることを希望します。例えば、出力に特定のキーワードを使用して出力を構造化することです。以下は大型モデルを使用した思考の連鎖推論の例で、問題：*What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?*\n\nLangChainライブラリ関数を使用することで、「Thought」（思考）、「Action」（行動）、「Observation」（観察）を思考の連鎖推論のキーワードとして使用し、出力を構造化できます。\n\n```\nThought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\nAction: Search[Colorado orogeny]\nObservation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought: It does not mention the eastern sector. So I need to look up eastern sector.\nAction: Lookup[eastern sector]\nObservation: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\nAction: Search[High Plains]\nObservation: High Plains refers to one of two distinct land regions\n\nThought: I need to instead search High Plains (United States).\nAction: Search[High Plains (United States)]\nObservation: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\n\nThought: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\nAction: Finish[1,800 to 7,000 ft]\n```"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "補足資料では、LangChainとOpenAIを使用した思考の連鎖推論の別のコード例をご覧いただけます。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.3 出力パーサー"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3.3.1 出力パーサーがない場合\n\n指定された評価`customer_review`に対して、情報を抽出し、以下の形式で出力したいと思います：\n\n```python\n{\n  \"gift\": False,\n  \"delivery_days\": 5,\n  \"price_value\": \"pretty affordable!\"\n}\n```"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 1️⃣ プロンプトテンプレート文字列の構築"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 2️⃣ langchainプロンプトテンプレートの構築"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "print(prompt_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 3️⃣ テンプレートを使用してプロンプトメッセージを取得"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = prompt_template.format_messages(text=customer_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 4️⃣ chatモデルを呼び出して情報を抽出"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"gift\": true,\n",
            "    \"delivery_days\": 2,\n",
            "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(temperature=0.0)\n",
        "response = chat(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 📝 分析と総括\n`response.content`の型は文字列（`str`）であり、辞書（`dict`）ではないため、直接`get`メソッドを使用するとエラーが発生します。したがって、出力パーサーが必要です。"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'get'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
          ]
        }
      ],
      "source": [
        "response.content.get('gift')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3.3.2 日本語版"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "from langchain.prompts import ChatPromptTemplate\n\ncustomer_review = \"\"\"\\\nこの葉っぱブロワーは非常に素晴らしいです。4つの設定があります：\\\nろうそく消し、そよ風、風の街、竜巻。 \\\n2日で到着し、妻の\\\n記念日のプレゼントにちょうど間に合いました。 \\\n妻はとても気に入って言葉を失ったと思います。 \\\n今まで私だけが使用しており、\\\n一日おきの朝に芝生の葉っぱを掃除するのに使っています。 \\\n他の葉っぱブロワーより少し高価ですが、\\\n追加機能の価値があると思います。\n\"\"\"\n\nreview_template = \"\"\"\\\n以下のテキストから、以下の情報を抽出してください：\n\nプレゼント：この商品は他の人へのプレゼントとして購入されましたか？ \\\nはいの場合は はい、いいえまたは不明の場合は いいえ と答えてください。\n\n配送日数：商品が\\\n到着するまでに何日かかりましたか？ この情報が見つからない場合は-1を出力してください。\n\n価格：価値や価格に関する文章を抽出し、\\\nそれらをカンマ区切りのPythonリストとして出力してください。\n\n以下のキーでJSONとして出力をフォーマットしてください：\nプレゼント\n配送日数\n価格\n\nテキスト: {text}\n\"\"\"\n\nprompt_template = ChatPromptTemplate.from_template(review_template)\nprint(prompt_template)"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"礼物\": \"是的\",\n",
            "    \"交货天数\": 2,\n",
            "    \"价钱\": [\"它比其他吹叶机稍微贵一点\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = prompt_template.format_messages(text=customer_review)\n",
        "\n",
        "chat = ChatOpenAI(temperature=0.0)\n",
        "response = chat(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3.3.3 LangChain出力パーサー"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 1️⃣ プロンプトテンプレート文字列の構築"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "review_template_2 = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product\\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 2️⃣ langchainプロンプトテンプレートの構築"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 🔥 出力パーサーの構築"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "from langchain.output_parsers import ResponseSchema\nfrom langchain.output_parsers import StructuredOutputParser\n\ngift_schema = ResponseSchema(name=\"gift\",\n                             description=\"Was the item purchased\\\n                             as a gift for someone else? \\\n                             Answer True if yes,\\\n                             False if not or unknown.\")\n\ndelivery_days_schema = ResponseSchema(name=\"delivery_days\",\n                                      description=\"How many days\\\n                                      did it take for the product\\\n                                      to arrive? If this \\\n                                      information is not found,\\\n                                      output -1.\")\n\nprice_value_schema = ResponseSchema(name=\"price_value\",\n                                    description=\"Extract any\\\n                                    sentences about the value or \\\n                                    price, and output them as a \\\n                                    comma separated Python list.\")\n\n\nresponse_schemas = [gift_schema, \n                    delivery_days_schema,\n                    price_value_schema]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\nformat_instructions = output_parser.get_format_instructions()\nprint(format_instructions)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 3️⃣ テンプレートを使用してプロンプトメッセージを取得"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the following text, extract the following information:\n",
            "\n",
            "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\n",
            "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
            "\n",
            "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
            "\n",
            "text: 这款吹叶机非常神奇。 它有四个设置：吹蜡烛、微风、风城、龙卷风。 两天后就到了，正好赶上我妻子的周年纪念礼物。 我想我的妻子会喜欢它到说不出话来。 到目前为止，我是唯一一个使用它的人，而且我一直每隔一天早上用它来清理草坪上的叶子。 它比其他吹叶机稍微贵一点，但我认为它的额外功能是值得的。\n",
            "\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
            "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
            "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 4️⃣ chatモデルを呼び出して情報を抽出"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "\t\"gift\": true,\n",
            "\t\"delivery_days\": 2,\n",
            "\t\"price_value\": \"它比其他吹叶机稍微贵一点\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = chat(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 5️⃣ 出力パーサーを使用して出力を解析"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'gift': True, 'delivery_days': 2, 'price_value': '它比其他吹叶机稍微贵一点'}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "output_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "##### 📝 分析と総括\n`output_dict`の型は辞書（`dict`）で、直接`get`メソッドを使用できます。このような出力は下流タスクの処理により便利です。"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dict.get('delivery_days')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3.3.4 日本語版"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "# 日本語\nreview_template_2 = \"\"\"\\\n以下のテキストから、以下の情報を抽出してください：\n\nプレゼント：この商品は他の人へのプレゼントとして購入されましたか？\nはいの場合は はい、いいえまたは不明の場合は いいえ と答えてください。\n\n配送日数：商品が到着するまでに何日かかりましたか？ この情報が見つからない場合は-1を出力してください。\n\n価格：価値や価格に関する文章を抽出し、それらをカンマ区切りのPythonリストとして出力してください。\n\nテキスト: {text}\n\n{format_instructions}\n\"\"\"\n\nfrom langchain.output_parsers import ResponseSchema\nfrom langchain.output_parsers import StructuredOutputParser\n\ngift_schema = ResponseSchema(name=\"プレゼント\",\n                             description=\"この商品は他の人へのプレゼントとして購入されましたか？\\\n                            はいの場合は はい、\\\n                            いいえまたは不明の場合は いいえ と答えてください。\")\n\ndelivery_days_schema = ResponseSchema(name=\"配送日数\",\n                                      description=\"商品が到着するまでに何日かかりましたか？\\\n                                      この情報が見つからない場合は-1を出力してください。\")\n\nprice_value_schema = ResponseSchema(name=\"価格\",\n                                    description=\"価値や価格に関する文章を抽出し、\\\n                                    それらをカンマ区切りのPythonリストとして出力してください\")\n\n\nresponse_schemas = [gift_schema, \n                    delivery_days_schema,\n                    price_value_schema]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\nformat_instructions = output_parser.get_format_instructions()\nprint(format_instructions)"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the following text, extract the following information:\n",
            "\n",
            "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\n",
            "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
            "\n",
            "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
            "\n",
            "text: 这款吹叶机非常神奇。 它有四个设置：吹蜡烛、微风、风城、龙卷风。 两天后就到了，正好赶上我妻子的周年纪念礼物。 我想我的妻子会喜欢它到说不出话来。 到目前为止，我是唯一一个使用它的人，而且我一直每隔一天早上用它来清理草坪上的叶子。 它比其他吹叶机稍微贵一点，但我认为它的额外功能是值得的。\n",
            "\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"礼物\": string  // 这件物品是作为礼物送给别人的吗？                            如果是，则回答 是的，                            如果否或未知，则回答 不是。\n",
            "\t\"交货天数\": string  // 产品需要多少天才能到达？                                      如果没有找到该信息，则输出-1。\n",
            "\t\"价钱\": string  // 提取有关价值或价格的任何句子，                                    并将它们输出为逗号分隔的 Python 列表\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
        "print(messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "\t\"礼物\": \"是的\",\n",
            "\t\"交货天数\": \"两天\",\n",
            "\t\"价钱\": \"它比其他吹叶机稍微贵一点\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = chat(messages)\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'礼物': '是的', '交货天数': '两天', '价钱': '它比其他吹叶机稍微贵一点'}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "output_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. 補足資料"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.1 思考の連鎖推論（ReAct）\n参考資料：[ReAct (Reason+Act) prompting in OpenAI GPT and LangChain](https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": "from langchain.docstore.wikipedia import Wikipedia\nfrom langchain_community.chat_models import ChatOpenAI\nfrom langchain.agents import initialize_agent, Tool, AgentExecutor\nfrom langchain.agents.react.base import DocstoreExplorer\n\ndocstore=DocstoreExplorer(Wikipedia())\ntools = [\n  Tool(\n    name=\"Search\",\n    func=docstore.search,\n    description=\"Search for a term in the docstore.\",\n  ),\n  Tool(\n    name=\"Lookup\",\n    func=docstore.lookup,\n    description=\"Lookup a term in the docstore.\",\n  )\n]\n\n# 大規模言語モデルを使用\nllm = ChatOpenAI(\n  model_name=\"gpt-3.5-turbo\",\n  temperature=0,\n)\n\n# ReActエージェントを初期化\nreact = initialize_agent(tools, llm, agent=\"react-docstore\", verbose=True)\nagent_executor = AgentExecutor.from_agent_and_tools(\n  agent=react.agent,\n  tools=tools,\n  verbose=True,\n)\n\n\nquestion = \"Author David Chanoff has collaborated with a U.S. Navy admiral who served as the ambassador to the United Kingdom under which President?\"\nagent_executor.run(question)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.-1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
