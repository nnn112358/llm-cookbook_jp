{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {
    "tags": []
   },
   "source": "# 第3章 メモリ\n\n - [1. OpenAI API キーの設定](#1-openai-api-キーの設定)\n - [2. 対話バッファメモリ](#2-対話バッファメモリ)\n     - [2.1 英語版](#21-英語版)\n         - [2.1.1 対話モデルの初期化](#211-対話モデルの初期化)\n         - [2.1.2 第1回対話](#212-第1回対話)\n         - [2.1.3 第2回対話](#213-第2回対話)\n         - [2.1.4 第3回対話](#214-第3回対話)\n         - [2.1.5 メモリキャッシュの確認](#215-メモリキャッシュの確認)\n         - [2.1.6 メモリキャッシュへの直接コンテンツ追加](#216-メモリキャッシュへの直接コンテンツ追加)\n     - [2.2 日本語版](#22-日本語版)\n         - [2.1.1 対話モデルの初期化](#211-対話モデルの初期化)\n         - [2.1.2 第1回対話](#212-第1回対話)\n         - [2.1.3 第2回対話](#213-第2回対話)\n         - [2.1.4 第3回対話](#214-第3回対話)\n         - [2.1.5 メモリキャッシュの確認](#215-メモリキャッシュの確認)\n         - [2.1.6 メモリキャッシュへの直接コンテンツ追加](#216-メモリキャッシュへの直接コンテンツ追加)\n     - [2.3 まとめ](#23-まとめ)\n - [3. 対話バッファウィンドウメモリ](#3-対話バッファウィンドウメモリ)\n     - [3.1 英語版](#31-英語版)\n         - [3.1.1 ウィンドウメモリに2回の対話を追加](#311-ウィンドウメモリに2回の対話を追加)\n         - [3.1.2 対話チェーンでのウィンドウメモリの応用](#312-対話チェーンでのウィンドウメモリの応用)\n     - [3.2 日本語版](#32-日本語版)\n         - [3.1.1 ウィンドウメモリに2回の対話を追加](#311-ウィンドウメモリに2回の対話を追加)\n         - [3.1.2 対話チェーンでのウィンドウメモリの応用](#312-対話チェーンでのウィンドウメモリの応用)\n - [4. 対話トークンバッファメモリ](#4-対話トークンバッファメモリ)\n     - [4.1 英語版](#41-英語版)\n     - [4.2 日本語版](#42-日本語版)\n     - [4.3 補足](#43-補足)\n - [5. 対話要約バッファメモリ](#5-対話要約バッファメモリ)\n     - [5.1 英語版](#51-英語版)\n         - [5.1.1 対話要約バッファメモリの使用](#511-対話要約バッファメモリの使用)\n         - [5.1.2 対話要約バッファメモリに基づく対話チェーン](#512-対話要約バッファメモリに基づく対話チェーン)\n     - [5.2 日本語版](#52-日本語版)\n         - [5.2.1 対話要約バッファメモリの使用](#521-対話要約バッファメモリの使用)\n         - [5.1.2 対話要約バッファメモリに基づく対話チェーン](#512-対話要約バッファメモリに基づく対話チェーン)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7e10db6f",
   "metadata": {},
   "source": "言語モデルと対話する際、それらは以前にあなたと行った対話の内容を覚えていません。これは、チャットボットなどのアプリケーションを構築する際に大きな問題となります - 十分にインテリジェントに見えないのです！したがって、このセクションでは、LangChainのメモリモジュール、つまり以前の対話を言語モデルに埋め込み、連続的な対話能力を持たせる方法について紹介します。\n\nLangChainのメモリ（Memory）モジュールを使用すると、履歴チャットメッセージの保存と管理、特定のエンティティに関する知識の構築に役立ちます。これらのコンポーネントは複数回の対話にわたって情報を保存し、対話中に特定の情報とコンテキストを追跡することができます。\n\nLangChainは複数のメモリタイプを提供しています。その中で、バッファメモリは最近のチャットメッセージを保持し、要約メモリは対話全体の要約を提供します。エンティティメモリは複数回の対話において特定のエンティティに関する情報を保持することができます。これらのメモリコンポーネントはすべてモジュラーで、他のコンポーネントと組み合わせて使用でき、ボットの対話管理能力を向上させます。メモリモジュールは簡単なAPI呼び出しでアクセスと更新が可能で、開発者が対話履歴の管理と維持をより簡単に実装できます。\n\nこの課程では主に4つのメモリモジュールを紹介しますが、その他のモジュールについてはドキュメントを参照して学習してください。\n- 対話バッファメモリ（ConversationBufferMemory）\n- 対話バッファウィンドウメモリ（ConversationBufferWindowMemory）\n- 対話トークンバッファメモリ（ConversationTokenBufferMemory）\n- 対話要約バッファメモリ（ConversationSummaryBufferMemory）\n\nLangChainにおいて、メモリとは大規模言語モデル（LLM）の短期記憶を指します。なぜ短期記憶なのでしょうか？それは、LLMが訓練された後（一定の長期記憶を獲得した後）、そのパラメータはユーザーの入力によって変化することがないためです。ユーザーが訓練済みのLLMと対話する際、LLMは一時的にユーザーの入力と既に生成した出力を覚えて、以降の出力を予測しますが、モデルが出力を完了した後、以前のユーザーの入力と出力を「忘れて」しまいます。したがって、以前のこれらの情報はLLMの短期記憶としか呼べません。\n\nLLMの短期記憶の保持時間を延長するには、外部メモリ方式を借りて記憶する必要があります。これにより、ユーザーとLLMの対話において、LLMができるだけユーザーとの履歴対話情報を知ることができるようになります。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca56e6b-1e07-4405-a1ca-f4237f20fa75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": "## 1. OpenAI API キーの設定\n\n[OpenAI アカウント](https://platform.openai.com/account/api-keys)にログインしてAPI キーを取得し、環境変数として設定してください。\n\n- グローバル環境変数として設定したい場合は、[知乎文章](https://zhuanlan.zhihu.com/p/627665725)を参考にしてください。\n- ローカル/プロジェクト環境変数として設定したい場合は、このファイルのディレクトリに`.env`ファイルを作成し、ファイルを開いて以下の内容を入力してください。\n\n    <p style=\"font-family:verdana; font-size:12px;color:green\">\n    OPENAI_API_KEY=\"your_api_key\" \n    </p>\n  \n  \"your_api_key\"をあなた自身のAPI キーに置き換えてください",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10446712-9fa6-4d71-94ce-2ea4cf197e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中\n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 获取环境变量 OPENAI_API_KEY\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297dcd5",
   "metadata": {
    "tags": []
   },
   "source": "## 2. 対話バッファメモリ",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ffa8cd26-45c5-4bae-90b2-b07d23bf3bb2",
   "metadata": {},
   "source": "### 2.1 英語版",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e77a3d-7aaa-48c1-b219-19bd6f4eb674",
   "metadata": {
    "tags": []
   },
   "source": "#### 2.1.1 対話モデルの初期化",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ad6fe2",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "id": "88bdf13d",
   "metadata": {
    "height": 133
   },
   "outputs": [],
   "source": "# ここではtemperatureパラメータを0.0に設定し、生成される回答のランダム性を減らします。\n# 毎回異なる新しいアイデアの回答を得たい場合は、このパラメータを増やしてみてください。\nllm = ChatOpenAI(temperature=0.0) \n\nmemory = ConversationBufferMemory()\n\n# 新しいConversationChain Classインスタンスを作成\n# verboseパラメータをTrueに設定すると、プログラムはより詳細な情報を出力し、より多くのデバッグまたは実行時情報を提供します。\n# 反対に、verboseパラメータをFalseに設定すると、プログラムはより簡潔に実行され、重要な情報のみを出力します。\nconversation = ConversationChain(llm=llm, memory = memory, verbose=True )"
  },
  {
   "cell_type": "markdown",
   "id": "dea83837",
   "metadata": {
    "tags": []
   },
   "source": "#### 2.1.2 第1回対話",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3b4c42",
   "metadata": {},
   "source": "予測（<font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">predict</font>）を実行すると、いくつかのプロンプトが生成されます。以下で見られるように、「以下は人間とAIの間の友好的な対話で、AIは健談」などと言っています。これは実際にLangChainが生成したプロンプトで、システムが希望する友好的な対話を行い、対話を保存し、現在完了したモデルチェーンを促すためのものです。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db24677d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71564ad",
   "metadata": {},
   "source": "#### 2.1.3 第2回対話",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "54d006bd",
   "metadata": {},
   "source": "第2回対話を行うと、上記のプロンプトが保持されます",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3ef937",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb734b",
   "metadata": {},
   "source": "#### 2.1.4 第3回対話",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0393df3d",
   "metadata": {},
   "source": "以前の対話内容を記憶しているかを確認するため、前に言った内容（私の名前）を答えさせます。確かに正しい名前を出力しており、この対話チェーンは進行するにつれてどんどん長くなっていくことがわかります",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf3339a",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1 + 1 equals 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96a8d9",
   "metadata": {},
   "source": "#### 2.1.5 メモリキャッシュの確認\n\nメモリキャッシュ（<font style=\"font-family:verdana; font-size:13.5px\">memory.</font><font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">buffer</font>）には現在までのすべての対話情報が保存されています",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2529400d",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1 + 1 equals 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5de846",
   "metadata": {},
   "source": "<font style=\"font-family:verdana; font-size:13.5px\">memory.</font><font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">load_memory_variables</font><font style=\"font-family:verdana; font-size:13.5px\">({})</font>を使ってキャッシュ内の履歴メッセージを印刷することもできます。ここの`{}`は空の辞書で、より高度な機能がありユーザーがより複雑な入力を使用できますが、この短期コースでは説明しませんので、ここになぜ空の中括弧があるかは気にしないでください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5018cb0a",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1 + 1 equals 2. Is there anything else you would like to know?\\nHuman: What is my name?\\nAI: Your name is Andrew.\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2e892",
   "metadata": {},
   "source": "#### 2.1.6 メモリキャッシュへの直接コンテンツ追加",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "14219b70",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": "memory = ConversationBufferMemory()  # 新しい空の対話バッファメモリを作成"
  },
  {
   "cell_type": "code",
   "id": "a36e9905",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})  # バッファ領域に指定された対話の入出力を追加"
  },
  {
   "cell_type": "code",
   "id": "61631b1f",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": "print(memory.buffer)  # バッファ領域の結果を確認"
  },
  {
   "cell_type": "code",
   "id": "a2fdf9ec",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": "print(memory.load_memory_variables({}))# メモリ変数を再度読み込み"
  },
  {
   "cell_type": "markdown",
   "id": "2ac544f2",
   "metadata": {},
   "source": "新しいコンテンツを追加し続けると、対話履歴がすべて保存されます！",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca79256",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890a4497",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddd91a-bf1c-4b82-b99c-c585420e4ecb",
   "metadata": {},
   "source": "### 2.2 日本語版",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55b3e4e9-7a6a-4a09-9ac3-0096a67849c7",
   "metadata": {},
   "source": [
    "#### 2.1.1 初始化对话模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3577aaff-7edb-40b0-866a-e407e63d55e0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77d37ab-1f75-4ae8-8d7c-5066773ead81",
   "metadata": {
    "height": 133
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)  \n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747cb539-abc4-4e47-8cb9-1ee608ab07fc",
   "metadata": {},
   "source": [
    "#### 2.1.2 第一轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e48462-7a92-4842-bdaa-2a478ba2252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"你好, 我叫皮皮鲁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d320b-6b20-4722-99db-c48a43711d6c",
   "metadata": {},
   "source": [
    "#### 2.1.3 第二轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed6e97a-d7ea-4188-a6d7-f91d2a29d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\n",
      "Human: 1+1等于多少？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"1+1等于多少？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1fd531-216e-42d8-b226-839747ad7dd3",
   "metadata": {},
   "source": [
    "#### 2.1.4 第三轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5dfe488-2758-42c7-9c20-e483b4c22ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。\n",
      "Human: 我叫什么名字？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'抱歉，我不知道你的名字。你可以告诉我吗？我会记住的。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我叫什么名字？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9822e-943d-4905-a1f8-a0d28c215d60",
   "metadata": {},
   "source": [
    "#### 2.1.5 查看储存缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0795580f-b6b6-47e0-8882-26fe204560bd",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。\n",
      "Human: 我叫什么名字？\n",
      "AI: 抱歉，我不知道你的名字。你可以告诉我吗？我会记住的。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe7824f-bd6e-4b95-92e2-1c85c62a92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。\n",
      "Human: 我叫什么名字？\n",
      "AI: 抱歉，我不知道你的名字。你可以告诉我吗？我会记住的。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48942759-8afb-4aed-80c5-a48952a2b0c0",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好, 我叫皮皮鲁\\nAI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\\nHuman: 1+1等于多少？\\nAI: 1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。\\nHuman: 我叫什么名字？\\nAI: 抱歉，我不知道你的名字。你可以告诉我吗？我会记住的。'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d0c4625-e928-45dc-b8da-4ab865ac5f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好, 我叫皮皮鲁\\nAI:  你好皮皮鲁！我是一个人工智能助手，很高兴认识你。你有什么问题想问我吗？\\nHuman: 1+1等于多少？\\nAI: 1加1等于2。这是一个基本的数学问题，答案是2。你还有其他问题吗？我可以帮助你解答。\\nHuman: 我叫什么名字？\\nAI: 抱歉，我不知道你的名字。你可以告诉我吗？我会记住的。'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3778e-5fbf-43ed-9df1-d57d98ec6fb0",
   "metadata": {},
   "source": [
    "#### 2.1.6 直接添加内容到储存缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147b2c30-1662-4b49-aaf8-c228428e5cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b5e27f0-dad7-41b6-9326-bebf6299638f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa7c555-06ab-4906-b3dc-906f789e08f5",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西\\nHuman: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deb33de8-37ea-4180-a73e-0fc456b14eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10146f1a-0114-4902-8122-d19ae6f7c461",
   "metadata": {},
   "source": "### 2.3 まとめ",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2759b6bc-edb2-4cfe-b0f8-1bf6c4d796f9",
   "metadata": {},
   "source": "大規模言語モデルでチャット対話を行う際、**大規模言語モデル自体は実際にはステートレスです。言語モデル自体は現在までの履歴対話を覚えていません**。API エンドポイントへの各呼び出しは独立しています。メモリ（Memory）は現在までのすべての用語や対話を保存し、それをLLMに入力または付加コンテキストとして提供して出力を生成できます。このように、次の対話を行う際に以前に何を言ったかを覚えているように見えます。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {},
   "source": "## 3. 対話バッファウィンドウメモリ\n  \n対話が長くなるにつれて、必要なメモリ量も非常に大きくなります。大量のトークンをLLMに送信するコストも高くなり、これがAPI呼び出し料金が通常処理する必要があるトークン数に基づいて課金される理由です。\n  \n上記の問題に対して、LangChainは履歴対話を保存する便利なメモリ方式もいくつか提供しています。その中で、対話バッファウィンドウメモリはウィンドウサイズの対話のみを保持します。最近のn回のインタラクションのみを使用します。これは最近のインタラクションのスライディングウィンドウを保持するために使用でき、バッファが大きくなりすぎないようにできます",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b63c9061-9916-4524-b497-93a0aa2b7d06",
   "metadata": {},
   "source": [
    "### 3.1 英文版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641477a4",
   "metadata": {},
   "source": [
    "#### 3.1.1 添加两轮对话到窗口储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ea6233e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k 为窗口参数，k=1表明只保留一个对话记忆\n",
    "memory = ConversationBufferWindowMemory(k=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc4553fb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# 向memory添加两轮对话\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a788403",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 并查看记忆变量当前的记录\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bda148",
   "metadata": {},
   "source": [
    "#### 3.1.2 在对话链中应用窗口储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4087bc87",
   "metadata": {
    "height": 133
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d661e3",
   "metadata": {},
   "source": [
    "注意此处！由于这里用的是一个窗口的记忆，因此只能保存一轮的历史消息，因此AI并不能知道你第一轮对话中提到的名字，他最多只能记住上一轮（第二轮）的对话信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4faaa952",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb20ddaa",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "489b2194",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name. Is there anything else you would like to ask?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88837e7c-cf4b-469e-b820-bbfc49ba876c",
   "metadata": {},
   "source": [
    "### 3.2 中文版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ec3ad-6959-4a36-b1b5-4fcafe8088ad",
   "metadata": {},
   "source": [
    "#### 3.1.1 添加两轮对话到窗口储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68a2907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k=1表明只保留一个对话记忆\n",
    "memory = ConversationBufferWindowMemory(k=1)  \n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabf017-5bfd-4904-9f06-388f994eddc9",
   "metadata": {},
   "source": [
    "#### 3.1.2 在对话链中应用窗口储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ee854d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 你好，皮皮鲁！很高兴认识你。我是一个人工智能助手，可以回答你的问题或者和你聊天。有什么我可以帮助你的吗？\n",
      "1加1等于2。这是一个基本的数学问题，答案是2。如果你有任何其他数学问题，都可以问我哦！\n",
      "抱歉，我不知道你的名字。我只是一个AI程序，无法获取你的个人信息。如果你有其他问题，我会尽力回答的哦！\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )\n",
    "print(conversation.predict(input=\"你好, 我叫皮皮鲁\"))\n",
    "print(conversation.predict(input=\"1+1等于多少？\"))\n",
    "print(conversation.predict(input=\"我叫什么名字？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## 四、对话token缓存储存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5b4c7",
   "metadata": {},
   "source": [
    "使用对话token缓存记忆，内存将限制保存的token数量。如果token数量超出指定数目，它会切掉这个对话的早期部分\n",
    "以保留与最近的交流相对应的token数量，但不超过token限制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb9020ed",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84112",
   "metadata": {},
   "source": [
    "### 4.1 英文版\n",
    "添加对话到Token缓存储存,限制token数量，进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43582ee6",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"}, {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "284288e1",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62b2e1",
   "metadata": {},
   "source": [
    "可以看到前面超出的的token已经被舍弃了！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6be43",
   "metadata": {},
   "source": [
    "### 4.2 中文版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9191020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: 轻舟已过万重山。'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"朝辞白帝彩云间，\"}, {\"output\": \"千里江陵一日还。\"})\n",
    "memory.save_context({\"input\": \"两岸猿声啼不住，\"}, {\"output\": \"轻舟已过万重山。\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08ef4a-876f-422a-81f9-4805288e5955",
   "metadata": {},
   "source": [
    "### 4.3 补充"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d918b",
   "metadata": {},
   "source": [
    "ChatGPT使用一种基于字节对编码（Byte Pair Encoding，BPE）的方法来进行tokenization（将输入文本拆分为token）。BPE是一种常见的tokenization技术，它将输入文本分割成较小的子词单元。 \n",
    "\n",
    "OpenAI在其官方GitHub上公开了一个最新的开源Python库 [tiktoken](https://github.com/openai/tiktoken)，这个库主要是用来计算tokens数量的。相比较HuggingFace的tokenizer，其速度提升了好几倍。\n",
    "\n",
    "具体token计算方式,特别是汉字和英文单词的token区别，具体课参考[知乎文章](https://www.zhihu.com/question/594159910) 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## 五、对话摘要缓存储存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39b83a",
   "metadata": {},
   "source": [
    "对话摘要缓存储存，**使用LLM编写到目前为止历史对话的摘要**，并将其保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72dcf8b1",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b213e-ce17-46a0-8652-03658ca58dd8",
   "metadata": {},
   "source": [
    "### 5.1 英文版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572ef39",
   "metadata": {},
   "source": [
    "#### 5.1.1 使用对话摘要缓存储存\n",
    "\n",
    "创建一个长字符串，其中包含某人的日程安排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a5b238f",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "# 创建一个长字符串\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "# 使用对话摘要缓存记忆\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) \n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15226a41-ab36-43a0-93f7-c03c6b374936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI exchange greetings and discuss the day's schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the power of LangChain as a tool.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb97b6",
   "metadata": {},
   "source": [
    "#### 5.1.2 基于对话摘要缓存储存的对话链\n",
    "基于上面的对话摘要缓存储存，新建一个对话链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6728edba",
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a221b1d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings and discuss the day's schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the power of LangChain as a tool.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show would be a live demonstration of how LangChain can accurately translate complex technical documents from one language to another in real-time. This would showcase the speed, accuracy, and efficiency of the language processing capabilities of LangChain. Additionally, demonstrating how LangChain can seamlessly integrate with other AI tools and platforms would highlight its versatility and compatibility with existing systems.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb582617",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI exchange greetings and discuss the day's schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the power of LangChain as a tool.\n",
      "Human: What would be a good demo to show?\n",
      "AI: A good demo to show would be a live demonstration of how LangChain can accurately translate complex technical documents from one language to another in real-time. This would showcase the speed, accuracy, and efficiency of the language processing capabilities of LangChain. Additionally, demonstrating how LangChain can seamlessly integrate with other AI tools and platforms would highlight its versatility and compatibility with existing systems.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba827aa",
   "metadata": {
    "height": 31
   },
   "source": [
    "### 5.2 中文版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64898f33-c538-4e68-b008-7123870b692b",
   "metadata": {},
   "source": [
    "#### 5.2.1 使用对话摘要缓存储存\n",
    "\n",
    "创建一个长字符串，其中包含某人的日程安排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c07922b",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "# 创建一个长字符串\n",
    "schedule = \"在八点你和你的产品团队有一个会议。 \\\n",
    "你需要做一个PPT。 \\\n",
    "上午9点到12点你需要忙于LangChain。\\\n",
    "Langchain是一个有用的工具，因此你的项目进展的非常快。\\\n",
    "中午，在意大利餐厅与一位开车来的顾客共进午餐 \\\n",
    "走了一个多小时的路程与你见面，只为了解最新的 AI。 \\\n",
    "确保你带了笔记本电脑可以展示最新的 LLM 样例.\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.save_context({\"input\": \"今天的日程安排是什么？\"}, {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17424a12-430f-4529-9067-300978c6169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI introduce themselves in Chinese and become friends. They plan their schedule for the day, including a meeting with the product team, working on LangChain, and having lunch with a customer interested in AI. The AI emphasizes the importance of being prepared to showcase the latest LLM examples.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29a956-607a-4247-9eb5-01285a370991",
   "metadata": {},
   "source": [
    "#### 5.1.2 基于对话摘要缓存储存的对话链\n",
    "基于上面的对话摘要缓存储存，新建一个对话链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52696c8c",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48690d13",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI introduce themselves in Chinese and become friends. They plan their schedule for the day, including a meeting with the product team, working on LangChain, and having lunch with a customer interested in AI. The AI emphasizes the importance of being prepared to showcase the latest LLM examples.\n",
      "Human: 展示什么样的样例最好呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'最好展示一些具有创新性和实用性的语言模型样例，比如可以展示LangChain在不同语言之间的翻译效果，或者展示其在文本生成和对话系统方面的应用。这样可以让客户更直观地了解LangChain的潜力和优势。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"展示什么样的样例最好呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85bba1f8",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI introduce themselves in Chinese and become friends. They plan their schedule for the day, including a meeting with the product team, working on LangChain, and having lunch with a customer interested in AI. The AI emphasizes the importance of being prepared to showcase the latest LLM examples. The human asks what kind of examples would be best to showcase.\\nAI: 最好展示一些具有创新性和实用性的语言模型样例，比如可以展示LangChain在不同语言之间的翻译效果，或者展示其在文本生成和对话系统方面的应用。这样可以让客户更直观地了解LangChain的潜力和优势。'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # 摘要记录更新了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}