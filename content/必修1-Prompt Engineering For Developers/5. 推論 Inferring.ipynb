{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3630c235-f891-4874-bd0a-5277d4d6aa82",
   "metadata": {},
   "source": "# 第5章 推論\n\nこのレッスンでは、商品レビューやニュース記事から感情とトピックを推論します。\n",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb0eaf6",
   "metadata": {},
   "source": "<div class=\"toc\">\n <ul class=\"toc-item\">\n     <li><span><a href=\"#一序論\" data-toc-modified-id=\"一、序論\">一、序論</a></span></li>\n     <li>\n         <span><a href=\"#二感情推論と情報抽出\" data-toc-modified-id=\"二、感情推論と情報抽出\">二、感情推論と情報抽出</a></span>\n         <ul class=\"toc-item\">\n             <li><span><a href=\"#21-感情傾向分析\" data-toc-modified-id=\"2.1 感情傾向分析\">2.1 感情傾向分析</a></span></li> \n             <li><span><a href=\"#22-感情タイプの識別\" data-toc-modified-id=\"2.2 感情タイプの識別\">2.2 感情タイプの識別</a></span></li>\n             <li><span><a href=\"#23-怒りの識別\" data-toc-modified-id=\"2.3 怒りの識別\">2.3 怒りの識別</a></span></li>\n             <li><span><a href=\"#24-商品情報抽出\" data-toc-modified-id=\"2.4 商品情報抽出\">2.4 商品情報抽出</a></span></li>\n             <li><span><a href=\"#25-包括的なタスク完了\" data-toc-modified-id=\"2.5 包括的なタスク完了\">2.5 包括的なタスク完了</a></span></li>\n             </ul>\n         </li>\n     <li><span><a href=\"#三トピック推論\" data-toc-modified-id=\"三、トピック推論\">三、トピック推論</a></span></li>\n     <ul class=\"toc-item\">\n             <li><span><a href=\"#31-討論トピックの推論\" data-toc-modified-id=\"3.1 討論トピックの推論\">3.1 討論トピックの推論</a></span></li> \n             <li><span><a href=\"#32-特定トピックのニュースアラート作成\" data-toc-modified-id=\"3.2 特定トピックのニュースアラート作成\">3.2 特定トピックのニュースアラート作成</a></span></li>\n             </ul>\n     </ul>\n</div>",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5f3abbee",
   "metadata": {},
   "source": "## 一、序論\n\n推論タスクは、モデルがテキストを入力として受け取り、何らかの分析を実行するプロセスと考えることができます。これには、ラベルの抽出、エンティティの抽出、テキストの感情理解などが含まれます。テキストの一部から肯定的または否定的な感情を抽出したい場合、従来の機械学習ワークフローでは、ラベル付きデータセットの収集、モデルのトレーニング、クラウドでモデルをデプロイして推論を行う方法の決定が必要でした。これはうまくいく可能性がありますが、全体のワークフローを実行するには多くの作業が必要です。また、感情分析、エンティティ抽出など、各タスクについて、個別のモデルのトレーニングとデプロイが必要でした。\n\nLLMの非常に素晴らしい特徴は、これらのタスクの多くについて、プロンプトを書くだけで結果を生成し始めることができ、大量の作業を必要としないことです。これにより、アプリケーション開発の速度が大幅に向上します。また、多くの異なるモデルをトレーニングしてデプロイする方法を理解することなく、1つのモデルと1つのAPIを使用して多くの異なるタスクを実行することもできます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a821d943",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "# 导入第三方库\n",
    "\n",
    "openai.api_key = \"sk-...\"\n",
    "# 设置 API_KEY, 请替换成您自己的 API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82f5577",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2fdfa-c99f-4750-8574-dba7712cd7f0",
   "metadata": {},
   "source": "## 二、感情推論と情報抽出\n### 2.1 感情分類\n\nECプラットフォームのランプに関するレビューを例に、そこから伝わる感情を二分類（ポジティブ/ネガティブ）してみます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3b49b",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "id": "bc6260f0",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nlamp_review_ja = \"\"\"\n私は寝室用の素敵なランプが必要で、これには追加の収納機能があり、価格もそれほど高くありませんでした。\\\nすぐに受け取ることができました。配送中にランプの紐が壊れてしまいましたが、会社は喜んで新しいものを送ってくれました。\\\n数日後に届きました。組み立ても簡単でした。部品が足りなかったのでサポートに連絡したところ、とても迅速に不足部品を送ってくれました！\\\n私の見るところ、Luminaは顧客と製品を非常に大切にする素晴らしい会社です！\n\"\"\""
  },
  {
   "cell_type": "markdown",
   "id": "cc4ec4ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d6e4bd-3337-45a3-8c99-a734cdd06743",
   "metadata": {},
   "source": "それでは、このレビューの感情を分類するプロンプトを書いてみましょう。システムにこのレビューの感情が何かを教えてもらいたい場合は、「以下の商品レビューの感情は何ですか」というプロンプトを書き、通常の区切り文字とレビューテキストなどを追加するだけです。\n\n実行してみましょう。結果は、この商品レビューの感情が肯定的だということで、これは非常に正しいようです。このランプは完璧ではありませんでしたが、この顧客は非常に満足しているようです。これは顧客と製品を大切にする素晴らしい会社のようで、肯定的な感情が正しい答えのようです。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3157601",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is positive.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac5b0bb9",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nprompt = f\"\"\"\n以下の三重バッククォートで区切られた商品レビューの感情は何ですか？\n\nレビューテキスト: ```{lamp_review_ja}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "a562e656",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76be2320",
   "metadata": {},
   "source": "より簡潔な答えを得て、後処理を容易にしたい場合は、上記のプロンプトにもう一つの指示を追加できます：*一つの単語で答えてください：「ポジティブ」または「ネガティブ」*。これにより「ポジティブ」という単語のみが出力され、出力がより統一され、後続の処理に便利になります。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf9ca16",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "84a761b3",
   "metadata": {},
   "outputs": [],
   "source": "prompt = f\"\"\"\n以下の三重バッククォートで区切られた商品レビューの感情は何ですか？\n\n一つの単語で答えてください：「ポジティブ」または「ネガティブ」。\n\nレビューテキスト: ```{lamp_review_ja}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "81d2a973-1fa4-4a35-ae35-a2e746c0e91b",
   "metadata": {},
   "source": "### 2.2 感情タイプの識別\n\n引き続きランプのレビューを使用して、別のプロンプトを試してみましょう。今度は、モデルにレビュー作者が表現している感情を識別し、5項目以下のリストにまとめてもらいます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa7934b",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied, grateful, impressed, content, pleased\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e615c13a",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nprompt = f\"\"\"\n以下のレビューの作者が表現している感情を識別してください。5項目以下で答えを形式化し、カンマで区切られた単語のリストにしてください。\n\nレビューテキスト: ```{lamp_review_ja}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "c7743a53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc4444f7",
   "metadata": {},
   "source": "大型言語モデルは、テキストの一部から特定の要素を抽出することが非常に得意です。上記の例では、レビューで表現された感情が顧客が特定の製品をどのように見ているかを理解するのに役立ちます。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a428d093-51c9-461c-b41e-114e80876409",
   "metadata": {},
   "source": "### 2.3 怒りの識別\n\n多くの企業にとって、ある顧客が非常に怒っているかどうかを知ることは重要です。そこで次のような分類問題が生まれます：以下のレビューの作者は怒りの感情を表現していますか？もし誰かが本当に怒っているなら、カスタマーサポートやカスタマーサクセスチームが顧客に連絡して状況を理解し、顧客の問題を解決することが価値があるかもしれません。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba1a538",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bad324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "prompt = f\"\"\"\n",
    "以下评论的作者是否表达了愤怒？评论用三个反引号分隔。给出是或否的答案。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77905fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ca57a2",
   "metadata": {},
   "source": [
    "上面这个例子中，客户并没有生气。注意，如果使用常规的监督学习，如果想要建立所有这些分类器，不可能在几分钟内就做到这一点。我们鼓励大家尝试更改一些这样的 Prompt ，也许询问客户是否表达了喜悦，或者询问是否有任何遗漏的部分，并看看是否可以让 Prompt 对这个灯具评论做出不同的推论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a771e-ca78-4e55-8088-2da6f3820ddc",
   "metadata": {},
   "source": [
    "### 2.4 商品信息提取\n",
    "\n",
    "接下来，让我们从客户评论中提取更丰富的信息。信息提取是自然语言处理（NLP）的一部分，与从文本中提取你想要知道的某些事物相关。因此，在这个 Prompt 中，我要求它识别以下内容：购买物品和制造物品的公司名称。\n",
    "\n",
    "同样，如果你试图总结在线购物电子商务网站的许多评论，对于这些评论来说，弄清楚是什么物品、谁制造了该物品，弄清楚积极和消极的情感，有助于追踪特定物品或制造商收获的用户情感趋势。\n",
    "\n",
    "在下面这个示例中，我们要求它将响应格式化为一个 JSON 对象，其中物品和品牌作为键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a13bea1b",
   "metadata": {
    "height": 285
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ffe056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"物品\": \"卧室灯\",\n",
      "  \"品牌\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "prompt = f\"\"\"\n",
    "从评论文本中识别以下项目：\n",
    "- 评论者购买的物品\n",
    "- 制造该物品的公司\n",
    "\n",
    "评论文本用三个反引号分隔。将你的响应格式化为以 “物品” 和 “品牌” 为键的 JSON 对象。\n",
    "如果信息不存在，请使用 “未知” 作为值。\n",
    "让你的回应尽可能简短。\n",
    "  \n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342c732",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954d125d",
   "metadata": {},
   "source": [
    "如上所示，它会说这个物品是一个卧室灯，品牌是 Luminar，你可以轻松地将其加载到 Python 字典中，然后对此输出进行其他处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38880a5-088f-4609-9913-f8fa41fb7ba0",
   "metadata": {},
   "source": [
    "### 2.5 综合完成任务\n",
    "\n",
    "提取上述所有信息使用了 3 或 4 个 Prompt ，但实际上可以编写单个 Prompt 来同时提取所有这些信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7dda9e5",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939c2b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"正面\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"卧室灯\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "prompt = f\"\"\"\n",
    "从评论文本中识别以下项目：\n",
    "- 情绪（正面或负面）\n",
    "- 审稿人是否表达了愤怒？（是或否）\n",
    "- 评论者购买的物品\n",
    "- 制造该物品的公司\n",
    "\n",
    "评论用三个反引号分隔。将您的响应格式化为 JSON 对象，以 “Sentiment”、“Anger”、“Item” 和 “Brand” 作为键。\n",
    "如果信息不存在，请使用 “未知” 作为值。\n",
    "让你的回应尽可能简短。\n",
    "将 Anger 值格式化为布尔值。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09a673",
   "metadata": {},
   "source": [
    "这个例子中，我们告诉它将愤怒值格式化为布尔值，然后输出一个 JSON。您可以自己尝试不同的变化，或者甚至尝试完全不同的评论，看看是否仍然可以准确地提取这些内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fc223-2c89-49ec-ac2d-78a8e74a43ac",
   "metadata": {},
   "source": [
    "## 三、主题推断\n",
    "\n",
    "大型语言模型的另一个很酷的应用是推断主题。给定一段长文本，这段文本是关于什么的？有什么话题？以以下一段虚构的报纸报道为例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a74cc3e",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811ff13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "story_zh = \"\"\"\n",
    "在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。\n",
    "调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。\n",
    "\n",
    "一位 NASA 员工 John Smith 对这一发现发表了评论，他表示：\n",
    "“我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”\n",
    "\n",
    "NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示：\n",
    "“我们很高兴听到我们的员工对 NASA 的工作感到满意。\n",
    "我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”\n",
    "\n",
    "调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。\n",
    "政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea91d6-e841-4ee2-bed9-ca4a36df177f",
   "metadata": {},
   "source": [
    "### 3.1 推断讨论主题\n",
    "\n",
    "上面是一篇虚构的关于政府工作人员对他们工作机构感受的报纸文章。我们可以让它确定五个正在讨论的主题，用一两个字描述每个主题，并将输出格式化为逗号分隔的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c267cbe",
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government survey, public sector employees, job satisfaction, NASA, Social Security Administration\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: ```{story}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f92f90fe",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government survey',\n",
       " ' public sector employees',\n",
       " ' job satisfaction',\n",
       " ' NASA',\n",
       " ' Social Security Administration']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab27b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调查结果, NASA, 社会保障管理局, 员工满意度, 政府承诺\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "prompt = f\"\"\"\n",
    "确定以下给定文本中讨论的五个主题。\n",
    "\n",
    "每个主题用1-2个单词概括。\n",
    "\n",
    "输出时用逗号分割每个主题。\n",
    "\n",
    "给定文本: ```{story_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d1435",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34be1d2a-1309-4512-841a-b6f67338938b",
   "metadata": {},
   "source": [
    "### 3.2 为特定主题制作新闻提醒\n",
    "\n",
    "假设我们有一个新闻网站或类似的东西，这是我们感兴趣的主题：NASA、地方政府、工程、员工满意度、联邦政府等。假设我们想弄清楚，针对一篇新闻文章，其中涵盖了哪些主题。可以使用这样的prompt：确定以下主题列表中的每个项目是否是以下文本中的主题。以 0 或 1 的形式给出答案列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b8fa65",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626c5b8e",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa: 1\n",
      "local government: 0\n",
      "engineering: 0\n",
      "employee satisfaction: 1\n",
      "federal government: 1\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: ```{story}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902a7c74",
   "metadata": {
    "height": 79
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT: New NASA story!\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f53d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美国航空航天局：1\n",
      "当地政府：0\n",
      "工程：0\n",
      "员工满意度：1\n",
      "联邦政府：1\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "prompt = f\"\"\"\n",
    "判断主题列表中的每一项是否是给定文本中的一个话题，\n",
    "\n",
    "以列表的形式给出答案，每个主题用 0 或 1。\n",
    "\n",
    "主题列表：美国航空航天局、当地政府、工程、员工满意度、联邦政府\n",
    "\n",
    "给定文本: ```{story_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39f24a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08247dbf",
   "metadata": {},
   "source": [
    "有结果可见，这个故事是与关于 NASA 、员工满意度、联邦政府有关，而与当地政府的、工程学无关。这在机器学习中有时被称为 Zero-Shot （零样本）学习算法，因为我们没有给它任何标记的训练数据。仅凭 Prompt ，它就能确定哪些主题在新闻文章中有所涵盖。\n",
    "\n",
    "如果我们想生成一个新闻提醒，也可以使用这个处理新闻的过程。假设我非常喜欢 NASA 所做的工作，就可以构建一个这样的系统，每当 NASA 新闻出现时，输出提醒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53bf1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提醒: 关于美国航空航天局的新消息\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {i.split('：')[0]: int(i.split('：')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['美国航空航天局'] == 1:\n",
    "    print(\"提醒: 关于美国航空航天局的新消息\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2c643",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ccd189",
   "metadata": {},
   "source": [
    "这就是关于推断的全部内容了，仅用几分钟时间，我们就可以构建多个用于对文本进行推理的系统，而以前则需要熟练的机器学习开发人员数天甚至数周的时间。这非常令人兴奋，无论是对于熟练的机器学习开发人员，还是对于新手来说，都可以使用 Prompt 来非常快速地构建和开始相当复杂的自然语言处理任务。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}