# 第1章 序論

**著者 吴恩达教授**

本コースへようこそ。開発者向けのChatGPTプロンプトエンジニアリング（Prompt Engineering）をご紹介します。本コースはIsa Fulford教授と私が共同で担当します。IsaはOpenAIの技術チームメンバーで、人気のChatGPT検索プラグインを開発し、LLM（Large Language Model, 大規模言語モデル）技術の製品への応用を教えることに大きく貢献しました。彼女はまた、人々にPromptの使用を教えるOpenAI cookbookの編集にも参加しました。

インターネット上には、プロンプト（Prompt、本チュートリアルではこの用語を保持します）に関する多くの資料があり、例えば《30 prompts everyone has to know》のような記事があります。これらの記事は主にChatGPTのWebインターフェースに集中しており、多くの人が特定の、通常一回限りのタスクを実行するために使用しています。しかし、私は開発者にとって、LLMのより強力な機能はAPI呼び出しを通じてソフトウェアアプリケーションを迅速に構築できることだと考えています。この側面はまだ十分に重視されていないと思います。実際に、私たちはDeepLearning.AIの姉妹会社AI Fundのチームで多くのスタートアップ企業と協力し、これらの技術を多数のアプリケーションに応用してきました。LLM APIが開発者に非常に迅速にアプリケーションを構築させることができるのを見るのは非常に興奮します。

本コースでは、LLMの潜在能力を発掘するためのいくつかの技巧を共有し、応用上のベストプラクティスも提供します。過程では大量の資料が含まれます。まず、ソフトウェア開発用のPromptのベストプラクティスを学び、その後いくつかの一般的な使用例（要約、推論、変換、拡張を含む）を扱い、最後にLLMを利用してchatbot（チャットボット）を構築します。これがあなたの想像力を刺激し、新しいアプリケーションを開拓することを希望します。

LLMの発展に伴い、大まかに2つのタイプに分類できます。以降、基本LLMと指示微調（Instruction Tuned）LLMと呼びます。基本LLMはテキスト訓練データに基づいて、次の単語を予測する能力を持つモデルとして訓練されています。通常、インターネットやその他の情報源から大量のデータで訓練を行い、次に現れる最も可能性の高い単語を決定します。例えば、「昔々、一匹のユニコーンがいました」をPromptとした場合、基本LLMは「彼女はユニコーンの友達と一緒に魔法の森で暮らしていました」と続ける予測をするかもしれません。しかし、「フランスの首都は何ですか」をPromptとした場合、基本LLMはインターネット上の記事に基づいて、「フランス最大の都市は何ですか？フランスの人口は何人ですか？」という回答を予測する可能性があります。これは、インターネット上の記事がフランスという国に関する質問と回答のリストである可能性が高いためです。

一方、指示微調されたLLMについては、関連する研究と実践が盛んに行われており、指示に従うように訓練されています。そのため、「フランスの首都は何ですか？」と質問すると、「フランスの首都はパリです」と出力する可能性が非常に高くなります。指示微調されたLLMの訓練は通常、事前訓練されたLLMに基づいて行われます。つまり、モデルはすでに大量のテキストデータで訓練されています。その後、入力と理想的な出力を含むデータ（入力は指示、出力はこれらの指示に従う良い回答）を使用して、さらに訓練と微調整（finetune）が行われます。その後、通常はRLHF（reinforcement learning from human feedback、人間のフィードバックからの強化学習）と呼ばれる技術を使用してさらに改善され、システムがより有益に指示に従えるようになります。

指示微調されたLLMは有益で、誠実で、無害になるように訓練されているため、基本LLMと比較して、有害な出力など問題のあるテキストを出力する可能性が低くなります。多くの実際の使用シナリオは、すでに指示微調されたLLMに移行しています。インターネット上で見つけることができるベストプラクティスの中には、基本LLMにより適用できるものもありますが、今日のほとんどの実際のアプリケーションでは、指示微調されたLLMに注意を集中することをお勧めします。これらのLLMは使いやすく、OpenAIやその他のLLM企業の取り組みにより、より安全で協調的になっています。

そのため、本コースでは**指示微調されたLLMのベストプラクティス**に焦点を当て、ほとんどの使用シナリオでこれを使用することをお勧めします。続行する前に、Isaと私が提供した資料に対するOpenAIとDeepLearning.aiチームの貢献に感謝したいと思います。OpenAIのAndrew Main、Joe Palermo、Boris Power、Ted Sanders、Lillian Wengに深く感謝します。彼らは私たちのブレインストーミング資料の策定と審査に参加し、この短期コースのカリキュラムを編成してくれました。また、Deep Learning方面のGeoff Ladwig、Eddy Shyu、Tommy Nelsonの働きにも感謝します。

指示微調されたLLMを使用する際、他の人に指示を与えること（その人は賢いが、あなたのタスクの具体的な詳細を知らないと仮定）に例えることができます。そのため、LLMが正常に動作しない場合、指示が十分に明確でないことが原因である場合があります。例えば、「アラン・チューリング（Alan Turing）について何か書いてください」と質問したい場合、それに加えて、テキストが彼の科学的な仕事、個人的な生活、歴史的な役割、またはその他の側面に焦点を当てることを明確に示すことがより有益かもしれません。また、回答のトーンを指定することで、あなたのニーズをより満足させることができます。選択肢には*プロのジャーナリストの文章*、または*友人に書く随筆*などがあります。

LLMを新卒の大学生として捉え、彼にこのタスクを要求する場合、Alan Turingについて書くために読むべきテキストの断片を事前に指定することさえできます。これにより、この新卒の大学生がこのタスクをより良く完成させることができます。次の章では、プロンプト作成の2つの原則を見ることができます。一つは**明確で具体的**、もう一つは**LLMに考える時間を与える**ことです。