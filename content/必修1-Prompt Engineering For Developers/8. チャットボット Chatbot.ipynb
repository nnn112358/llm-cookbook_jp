{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9183228-0ba6-4af9-8430-649e28868253",
   "metadata": {
    "id": "JMXGlIvAwn30"
   },
   "source": "# 第8章 チャットボット",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4164d820",
   "metadata": {},
   "source": "<div class=\"toc\">\n    <ul class=\"toc-item\">\n        <li><span><a href=\"#一導入\" data-toc-modified-id=\"一、導入\">一、導入</a></span></li>\n        <li>\n        <span><a href=\"#二アイデンティティとコンテキストの構築\" data-toc-modified-id=\"二、アイデンティティとコンテキストの構築\">二、アイデンティティとコンテキストの構築</a></span></li><li>\n        <span><a href=\"#三注文ボット\" data-toc-modified-id=\"三、注文ボット\">三、注文ボット</a></span>\n        <ul class=\"toc-item\">\n            <li><span><a href=\"#31-json要約の作成\" data-toc-modified-id=\"3.1 json要約の作成\">3.1 JSON要約の作成</a></span></li>\n        </ul>\n        </li>\n    </ul>\n</div>",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0bdc2c9",
   "metadata": {},
   "source": "## 一、導入\n\n大規模言語モデルを使用する際の興奮すべきことの一つは、非常に少ない作業量でカスタマイズされたチャットボット（Chatbot）を構築できることです。本節では、チャット形式を利用して、個人化された（または特定のタスクや行動に特化した）チャットボットとの拡張対話を行う方法を探索します。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7fa0d9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "import openai\n# サードパーティライブラリのインポート\n\nopenai.api_key = \"sk-...\"\n# API_KEYの設定、ご自身のAPI_KEYに置き換えてください"
  },
  {
   "cell_type": "markdown",
   "id": "e6fae355",
   "metadata": {},
   "source": "ChatGPTのようなチャットモデルは実際には、一連のメッセージを入力として受け取り、モデルが生成したメッセージを出力として返すように組み立てられています。このチャット形式は元々複数ターンの対話を簡単にするために設計されましたが、これまでの学習を通じて分かるように、対話を伴わない**単一ターンタスク**にも同様に有用です。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "78344a7e",
   "metadata": {},
   "source": "## 二、アイデンティティとコンテキストの構築",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9b885b",
   "metadata": {},
   "source": "次に、2つの補助関数を定義します。\n\n最初のメソッドは、チュートリアル全体を通してあなたと共にあった```get_completion```で、単一ターン対話に適用されます。プロンプトを**ユーザーメッセージ**のような対話ボックスに配置します。もう一つは```get_completion_from_messages```と呼ばれ、メッセージリストを渡します。これらのメッセージは大量の異なる**役割**（roles）から来ることができ、これらの役割について説明します。\n\n最初のメッセージでは、システムアイデンティティでシステムメッセージ（system message）を送信し、これは全体的な指示を提供します。システムメッセージはアシスタントの行動と役割を設定し、対話の高レベル指示として機能します。アシスタントの耳元でささやき、その応答を導くものと想像できますが、ユーザーはシステムメッセージに気づきません。そのため、ユーザーとして、もしあなたがChatGPTを使用したことがあるなら、ChatGPTのシステムメッセージが何であるかを知らないかもしれませんが、これは意図的なものです。システムメッセージの利点は、開発者にリクエスト自体を対話の一部にすることなく、アシスタントを導き、その応答を指導する方法を提供することです。\n\nChatGPTのウェブインターフェースでは、あなたのメッセージはユーザーメッセージと呼ばれ、ChatGPTのメッセージはアシスタントメッセージと呼ばれます。しかし、チャットボットを構築する際、システムメッセージを送信した後、あなたの役割はユーザー（user）としてのみ機能することもできますし、ユーザーとアシスタント（assistant）の間で交互に役割を果たし、対話コンテキストを提供することもできます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f5308d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # モデル出力のランダム性を制御\n    )\n    return response.choices[0].message[\"content\"]\n\ndef get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature, # モデル出力のランダム性を制御\n    )\n#     print(str(response.choices[0].message))\n    return response.choices[0].message[\"content\"]"
  },
  {
   "cell_type": "markdown",
   "id": "46caaa5b",
   "metadata": {},
   "source": "今度は対話でこれらのメッセージを使ってみましょう。上記の関数を使用してこれらのメッセージから得られる回答を取得し、同時により高い温度（temperature）を使用します（高いほどより多様性が生成されます、詳細は第7章を参照）。\n\nシステムメッセージは、あなたはシェイクスピアのように話すアシスタントだと言っています。これは**どのように振る舞うべきか**をアシスタントに説明する方法です。その後、最初のユーザーメッセージは*ジョークを教えて*です。次にアシスタントの身分で回答を与えるのは、*なぜ鶏は道路を渡ったのか？*最後にユーザーメッセージとして*分からない*を送信します。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee681b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da45ea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get to the other side, fair sir.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "02b0e4d3",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nmessages =  [  \n{'role':'system', 'content':'あなたはシェイクスピアのように話すアシスタントです。'},    \n{'role':'user', 'content':'ジョークを教えて'},   \n{'role':'assistant', 'content':'なぜ鶏は道路を渡ったのか'},   \n{'role':'user', 'content':'分からない'}  ]"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f80283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因为它要去找“母鸡”。哈哈哈！（注：此为英文双关语，\"chicken\"是鸡的意思，也是胆小的意思；\"cross the road\"是过马路的意思，也是“破坏规则”的意思。）\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e5b83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f51a7e0",
   "metadata": {},
   "source": "（注：上記の例ではtemperature = 1を選択したため、モデルの回答は比較的ランダムで大きく異なります（創造性に富んだものも少なくありません）。ここに別の回答を付け加えます：\n\nシェイクスピア風の詩でお答えしましょう：\n\n鶏の心が前進を欲するとき、\n道路の際がその選択となりけり。\n車ゆっくりと進み天晴れて、\nクラクション響き交錯せり。\n\nなにゆえ何処へ行くやと問わん？\n大道の上に征なき故に、\n鶏は躍り進みて、\nその決断に迷いなし。\n\n鶏の智慧なにを語らん、\n道路孤独にして漆の如し。\nされども其の勇気人を嘆かせ、\n勇往邁進して退くことなし。\n\n故に鶏道路を渡る理由は？\n車流騒々の困厄に耐えんため。\nその鳴き声勇ましく一躍し、\n誇らしき絵巻を成就せり。\n\n故に笑話の妙処は、\n鶏の勇気溢るる伴いなり。\n人生の道を恐れず笑談し、\n智あり勇ありて妙を尽くす。\n\nこのシェイクスピア風の回答があなたに少しの楽しみをもたらすことを願います！）",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d70fd298",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f76bedb",
   "metadata": {},
   "source": "別の例を見てみましょう。アシスタントのメッセージは*あなたはフレンドリーなチャットボットです*、最初のユーザーメッセージは*こんにちは、私はIsaです*。最初のユーザーメッセージを取得したいと思います。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca733f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Isa! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca517ab0",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nmessages =  [  \n{'role':'system', 'content':'あなたはフレンドリーなチャットボットです。'},    \n{'role':'user', 'content':'こんにちは、私はIsaです。'}  ]\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "63c2010b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e9f96ba",
   "metadata": {},
   "source": "もう一つの例を試してみましょう。システムメッセージは、あなたはフレンドリーなチャットボットです、最初のユーザーメッセージは、はい、私の名前を思い出させてもらえますか？",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae595bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but since we don't have any personal information about you, I don't know your name. Can you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a606d422",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nmessages =  [  \n{'role':'system', 'content':'あなたはフレンドリーなチャットボットです。'},    \n{'role':'user', 'content':'はい、私の名前を思い出させてもらえますか？'}  ]\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "da1e4df5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c65d16",
   "metadata": {},
   "source": "上記で見るように、モデルは実際には私の名前を知りません。\n\nそのため、言語モデルとの各やり取りは相互に独立しており、これは現在の対話でモデルが参照できるように、すべての関連メッセージを提供する必要があることを意味します。モデルが対話の早期部分を参照または「記憶」してほしい場合は、モデルの入力に早期の交流を提供する必要があります。これをコンテキスト（context）と呼びます。以下の例を試してみてください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cbb817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Isa.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},\n",
    "{'role':'user', 'content':'Hi, my name is Isa'},\n",
    "{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
    "Is there anything I can help you with today?\"},\n",
    "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b40fb0",
   "metadata": {},
   "source": "別の回答を付け加えます：\n\n*あなたの名前はIsaです！どうして忘れることができるでしょうか？*",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6019b1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# 日本語\nmessages =  [  \n{'role':'system', 'content':'あなたはフレンドリーなチャットボットです。'},\n{'role':'user', 'content':'こんにちは、私はIsaです'},\n{'role':'assistant', 'content': \"こんにちはIsa！お会いできて嬉しいです。今日はお手伝いできることはありますか？\"},\n{'role':'user', 'content':'はい、私の名前を思い出させてもらえますか？'}  ]\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "c1ed90a6",
   "metadata": {},
   "source": "今度は、モデルに必要なコンテキスト、つまり以前の対話で言及された私の名前を提供しました。その後、同じ質問、つまり私の名前は何ですかと尋ねます。モデルは必要なすべてのコンテキストを持っているため、入力のメッセージリストで見るように応答できます。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dedba66a-58b0-40d4-b9ae-47e79ae22328",
   "metadata": {
    "id": "bBg_MpXeYnTq"
   },
   "source": "## 三、注文ボット\n\n今度は「注文ボット」を構築します。これがユーザー情報を自動的に収集し、ピザ店の注文を受け付ける必要があります。\n\n以下の関数は、手動入力を避けるためにユーザーメッセージを収集します。この関数は、以下で構築するユーザーインターフェースからプロンプトを収集し、コンテキスト（```context```）というリストに追加し、モデルを呼び出すたびにそのコンテキストを使用します。モデルの応答もコンテキストに追加されるため、ユーザーメッセージとモデルメッセージの両方がコンテキストに追加され、コンテキストは徐々に長くなります。このようにして、モデルは次にすべきことを決定するために必要な情報を持ちます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76749ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b003e",
   "metadata": {},
   "source": "今度は、このUIを設定して実行し、注文ボットを表示します。初期のコンテキストには、メニューを含むシステムメッセージが含まれており、各呼び出し時に使用されます。その後、対話が進むにつれて、コンテキストも継続的に成長します。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f97fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e746f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fff07d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327b15b7",
   "metadata": {},
   "source": "実行結果はインタラクティブです。以下の日本語版をご覧ください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "668ea96d",
   "metadata": {},
   "source": "### 3.1 JSON要約の作成",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2a2c9822",
   "metadata": {},
   "source": "ここで、モデルに注文システムに送信するためのJSON要約を作成してもらいます。\n\nそのため、コンテキストの基礎に別のシステムメッセージを追加する必要があり、これは別の指示（instruction）として機能します。*先ほどの注文のJSON要約を作成し、各項目の価格をリストアップしてください。フィールドは1）ピザ、サイズを含む、2）トッピングリスト、3）ドリンクリスト、サイズを含む、4）サイドディッシュリスト、サイズを含む、最後に総価格*と言います。ここではユーザーメッセージとして定義することもでき、必ずしもシステムメッセージである必要はありません。\n\nここでは、これらのタイプのタスクに対して比較的予測可能な出力を希望するため、より低い温度を使用していることに注意してください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c840ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a JSON summary of the previous food order:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"type\": \"cheese\",\n",
      "    \"size\": \"large\",\n",
      "    \"toppings\": [\n",
      "      \"mushrooms\"\n",
      "    ],\n",
      "    \"price\": 12.45\n",
      "  },\n",
      "  \"drinks\": [\n",
      "    {\n",
      "      \"type\": \"sprite\",\n",
      "      \"size\": \"medium\",\n",
      "      \"price\": 3.00\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"sprite\",\n",
      "      \"size\": \"medium\",\n",
      "      \"price\": 3.00\n",
      "    }\n",
      "  ],\n",
      "  \"sides\": [],\n",
      "  \"total_price\": 18.45\n",
      "}\n",
      "``` \n",
      "\n",
      "Note: I assumed that the price of the large cheese pizza with mushrooms is $12.45 instead of $12.95, since the customer only ordered one topping.\n"
     ]
    }
   ],
   "source": [
    "messages =  context.copy()\n",
    "messages.append(\n",
    "{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n",
    " The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    \n",
    ")\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ef90a6b",
   "metadata": {},
   "outputs": [],
   "source": "# 日本語\nimport panel as pn  # GUI\npn.extension()\n\npanels = [] # collect display \n\ncontext = [{'role':'system', 'content':\"\"\"\nあなたは注文ボットで、ピザレストランの注文情報を自動的に収集します。\nまず顧客に挨拶をします。その後、ユーザーの返答を待って注文情報を収集します。情報収集後、顧客が他に追加したいものがないか確認する必要があります。\n最後に、テイクアウトか配達かを尋ね、配達の場合は住所を尋ねてください。\n最後に顧客に注文の総額を伝え、祝福を送ってください。\n\nすべてのオプション、追加項目、サイズを明確にして、メニューから該当項目を一意に識別できるようにしてください。\nあなたの応答は短く、非常にカジュアルでフレンドリーなスタイルで表現してください。\n\nメニューは以下の通りです：\n\n料理：\nイタリア風ペパロニピザ（大、中、小） 12.95、10.00、7.00\nチーズピザ（大、中、小） 10.95、9.25、6.50\nナスピザ（大、中、小） 11.95、9.75、6.75\nフライドポテト（大、小） 4.50、3.50\nギリシャサラダ 7.25\n\nトッピング：\nチーズ 2.00\nマッシュルーム 1.50\nソーセージ 3.00\nカナディアンベーコン 3.50\nAIソース 1.50\nピーマン 1.00\n\nドリンク：\nコーラ（大、中、小） 3.00、2.00、1.00\nスプライト（大、中、小） 3.00、2.00、1.00\nボトル水 5.00\n\"\"\"} ]  # accumulate messages\n\n\ninp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\nbutton_conversation = pn.widgets.Button(name=\"Chat!\")\n\ninteractive_conversation = pn.bind(collect_messages, button_conversation)\n\ndashboard = pn.Column(\n    inp,\n    pn.Row(button_conversation),\n    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n)"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9a8ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1717'>\n",
       "  <div class=\"bk-root\" id=\"e321dfc5-ed71-4c7e-9054-ad25bb0996c1\" data-root-id=\"1717\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"ba214626-f150-41f7-88bd-59aed92ab8b3\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"GridStack1\",\"overrides\":[],\"properties\":[{\"default\":\"warn\",\"kind\":null,\"name\":\"mode\"},{\"default\":null,\"kind\":null,\"name\":\"ncols\"},{\"default\":null,\"kind\":null,\"name\":\"nrows\"},{\"default\":true,\"kind\":null,\"name\":\"allow_resize\"},{\"default\":true,\"kind\":null,\"name\":\"allow_drag\"},{\"default\":[],\"kind\":null,\"name\":\"state\"}]},{\"extends\":null,\"module\":null,\"name\":\"click1\",\"overrides\":[],\"properties\":[{\"default\":\"\",\"kind\":null,\"name\":\"terminal_output\"},{\"default\":\"\",\"kind\":null,\"name\":\"debug_name\"},{\"default\":0,\"kind\":null,\"name\":\"clears\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationAreaBase1\",\"overrides\":[],\"properties\":[{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationArea1\",\"overrides\":[],\"properties\":[{\"default\":[],\"kind\":null,\"name\":\"notifications\"},{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"},{\"default\":[{\"background\":\"#ffc107\",\"icon\":{\"className\":\"fas fa-exclamation-triangle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"warning\"},{\"background\":\"#007bff\",\"icon\":{\"className\":\"fas fa-info-circle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"info\"}],\"kind\":null,\"name\":\"types\"}]},{\"extends\":null,\"module\":null,\"name\":\"Notification\",\"overrides\":[],\"properties\":[{\"default\":null,\"kind\":null,\"name\":\"background\"},{\"default\":3000,\"kind\":null,\"name\":\"duration\"},{\"default\":null,\"kind\":null,\"name\":\"icon\"},{\"default\":\"\",\"kind\":null,\"name\":\"message\"},{\"default\":null,\"kind\":null,\"name\":\"notification_type\"},{\"default\":false,\"kind\":null,\"name\":\"_destroyed\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1720\"}],\"margin\":[0,0,0,0],\"name\":\"Row01094\"},\"id\":\"1719\",\"type\":\"Row\"},{\"attributes\":{\"args\":{\"bidirectional\":false,\"properties\":{\"event:button_click\":\"loading\"},\"source\":{\"id\":\"1720\"},\"target\":{\"id\":\"1721\"}},\"code\":\"\\n    if ('event:button_click'.startsWith('event:')) {\\n      var value = true\\n    } else {\\n      var value = source['event:button_click'];\\n      value = value;\\n    }\\n    if (typeof value !== 'boolean' || source.labels !== ['Loading']) {\\n      value = true\\n    }\\n    var css_classes = target.css_classes.slice()\\n    var loading_css = ['pn-loading', 'arc']\\n    if (value) {\\n      for (var css of loading_css) {\\n        if (!(css in css_classes)) {\\n          css_classes.push(css)\\n        }\\n      }\\n    } else {\\n     for (var css of loading_css) {\\n        var index = css_classes.indexOf(css)\\n        if (index > -1) {\\n          css_classes.splice(index, 1)\\n        }\\n      }\\n    }\\n    target['css_classes'] = css_classes\\n    \",\"tags\":[[5239341456,[null,\"event:button_click\"],[null,\"loading\"]]]},\"id\":\"1729\",\"type\":\"CustomJS\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01103\",\"text\":\"&lt;p&gt;User:&lt;/p&gt;\"},\"id\":\"1724\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"client_comm_id\":\"df72227b43a2413185c677536f738a1c\",\"comm_id\":\"bf7b0dfe31d54807a147c04852dfa441\",\"plot_id\":\"1717\"},\"id\":\"1730\",\"type\":\"panel.models.comm_manager.CommManager\"},{\"attributes\":{\"children\":[{\"id\":\"1722\"}],\"height\":300,\"margin\":[0,0,0,0],\"min_height\":300,\"name\":\"Row01099\"},\"id\":\"1721\",\"type\":\"Row\"},{\"attributes\":{\"icon\":null,\"js_event_callbacks\":{\"button_click\":[{\"id\":\"1729\"}]},\"label\":\"Chat!\",\"margin\":[5,10,5,10],\"subscribed_events\":[\"button_click\"]},\"id\":\"1720\",\"type\":\"Button\"},{\"attributes\":{\"children\":[{\"id\":\"1724\"},{\"id\":\"1725\"}],\"margin\":[0,0,0,0],\"name\":\"Row01105\"},\"id\":\"1723\",\"type\":\"Row\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01106\",\"style\":{\"background-color\":\"#F6F6F6\"},\"text\":\"&lt;p&gt;\\u4f60\\u597d\\uff01\\u6b22\\u8fce\\u6765\\u5230\\u62ab\\u8428\\u9910\\u5385\\uff01\\u8bf7\\u95ee\\u60a8\\u60f3\\u70b9\\u4ec0\\u4e48\\uff1f&lt;/p&gt;\",\"width\":600},\"id\":\"1728\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"children\":[{\"id\":\"1723\"},{\"id\":\"1726\"}],\"margin\":[0,0,0,0],\"name\":\"Column01111\"},\"id\":\"1722\",\"type\":\"Column\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01108\",\"text\":\"&lt;p&gt;Assistant:&lt;/p&gt;\"},\"id\":\"1727\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01101\",\"width\":600},\"id\":\"1725\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"margin\":[5,10,5,10],\"max_length\":5000,\"placeholder\":\"Enter text here\\u2026\"},\"id\":\"1718\",\"type\":\"TextInput\"},{\"attributes\":{\"children\":[{\"id\":\"1718\"},{\"id\":\"1719\"},{\"id\":\"1721\"}],\"margin\":[0,0,0,0],\"name\":\"Column01113\"},\"id\":\"1717\",\"type\":\"Column\"},{\"attributes\":{\"children\":[{\"id\":\"1727\"},{\"id\":\"1728\"}],\"margin\":[0,0,0,0],\"name\":\"Row01110\"},\"id\":\"1726\",\"type\":\"Row\"}],\"root_ids\":[\"1717\",\"1730\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "    var render_items = [{\"docid\":\"ba214626-f150-41f7-88bd-59aed92ab8b3\",\"root_ids\":[\"1717\"],\"roots\":{\"1717\":\"e321dfc5-ed71-4c7e-9054-ad25bb0996c1\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Column\n",
       "    [0] TextInput(placeholder='Enter text here…')\n",
       "    [1] Row\n",
       "        [0] Button(name='Chat!')\n",
       "    [2] ParamFunction(function, _pane=Column, height=300, loading_indicator=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1717"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "id": "96b2a2c7",
   "metadata": {},
   "outputs": [],
   "source": "messages =  context.copy()\nmessages.append(\n{'role':'system', 'content':'前回の食品注文のJSON要約を作成してください。\\\n各商品の価格を項目別にリストアップし、フィールドは 1) ピザ、サイズを含む 2) トッピングリスト 3) ドリンクリスト、サイズを含む 4) サイドディッシュリスト、サイズを含む 5) 総価格'},    \n)\n\nresponse = get_completion_from_messages(messages, temperature=0)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "018de2cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef17c2b2",
   "metadata": {},
   "source": "今度は、独自の注文チャットボットを構築しました。システムメッセージを自由にカスタマイズして修正し、チャットボットの動作を変更し、異なる役割を演じ、異なる知識を持つようにしてください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7f688397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f43e62",
   "metadata": {},
   "source": "付録：以下の図は注文ボットの完全な対話フローを示しています：\n![image.png](../../figures/Chatbot-pizza-cn.png)",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}