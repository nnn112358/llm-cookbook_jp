<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>5. 検索</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown-min.css" />
</head>
<body>
<h1 id="第5章-検索retrieval">第5章 検索(Retrieval)</h1>
<p>検索拡張生成（RAG）システムを構築する際、情報検索はコアな要素です。検索モジュールはユーザークエリの分析を担当し、知識ベースから関連する文書や段落を素早く特定し、後続の言語生成に情報サポートを提供します。<strong>検索とは、ユーザーの質問に基づいてベクターデータベースから質問に関連する文書内容を検索すること</strong>であり、ベクターデータベースにアクセスし、クエリを実行する際に使用される可能性のある技術には以下のようなものがあります：</p>
<ul>
<li>基本セマンティック類似度（Basic semantic similarity）</li>
<li>最大周辺関連性（Maximum marginal relevance、MMR）</li>
<li>メタデータフィルタリング</li>
<li>LLM支援検索</li>
</ul>
<p><img src="../figures/C4/Retrieval.png" /></p>
<div data-align="center">
図 4.5.1 検索技術
</div>
<p>基本的な類似性検索を使用することで、おそらく80%の関連検索作業を解決できますが、類似性検索が失敗するエッジケースにはどう対処すべきでしょうか？この章では、いくつかの検索手法と検索のエッジケースを解決するテクニックを紹介します。一緒に学習を始めましょう！</p>
<h2 id="一向量数据库检索">一、向量数据库检索</h2>
<p>本章节需要使用<code>lark</code>包，若环境中未安装过此包，请运行以下命令安装：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>Uq lark</span></code></pre></div>
<h3 id="相似性检索similarity-search">1.1 相似性检索（Similarity
Search）</h3>
<p>以我们的流程为例，前面课程已经存储了向量数据库(<code>VectorDB</code>)，包含各文档的语义向量表示。首先将上节课所保存的向量数据库(<code>VectorDB</code>)加载进来：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> Chroma</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.embeddings.openai <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>persist_directory_chinese <span class="op">=</span> <span class="st">&#39;docs/chroma/matplotlib/&#39;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> OpenAIEmbeddings()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>vectordb_chinese <span class="op">=</span> Chroma(</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    persist_directory<span class="op">=</span>persist_directory_chinese,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    embedding_function<span class="op">=</span>embedding</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vectordb_chinese._collection.count())</span></code></pre></div>
<pre><code>27</code></pre>
<p>下面我们来实现一下语义的相似度搜索，我们把三句话存入向量数据库Chroma中，然后我们提出问题让向量数据库根据问题来搜索相关答案：</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>texts_chinese <span class="op">=</span> [</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;毒鹅膏菌（Amanita phalloides）具有大型且引人注目的地上（epigeous）子实体（basidiocarp）&quot;&quot;&quot;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&quot;&quot;&quot;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&quot;&quot;&quot;</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>]</span></code></pre></div>
<p>我们可以看到前两句都是描述的是一种叫“鹅膏菌”的菌类，包括它们的特征：有较大的子实体，第三句描述的是“鬼笔甲”，一种已知的最毒的蘑菇，它的特征就是：含有剧毒。对于这个例子，我们将创建一个小数据库，我们可以作为一个示例来使用。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>smalldb_chinese <span class="op">=</span> Chroma.from_texts(texts_chinese, embedding<span class="op">=</span>embedding)</span></code></pre></div>
<pre><code>100%|██████████| 1/1 [00:00&lt;00:00,  1.51it/s]</code></pre>
<p>下面是我们对于这个示例所提出的问题：</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;告诉我关于具有大型子实体的全白色蘑菇的信息&quot;</span></span></code></pre></div>
<p>现在，让针对上面问题进行<strong>相似性搜索</strong>，设置 k=2
，只返回两个最相关的文档。</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>smalldb_chinese.similarity_search(question_chinese, k<span class="op">=</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}),
 Document(page_content=&#39;毒鹅膏菌（Amanita phalloides）具有大型且引人注目的地上（epigeous）子实体（basidiocarp）&#39;, metadata={})]</code></pre>
<p>我们现在可以看到，向量数据库返回了 2
个文档，就是我们存入向量数据库中的第一句和第二句。这里我们很明显的就可以看到
chroma 的 similarity_search（相似性搜索）
方法可以根据问题的语义去数据库中搜索与之相关性最高的文档，也就是搜索到了第一句和第二句的文本。但这似乎还存在一些问题，因为第一句和第二句的含义非常接近，他们都是描述“鹅膏菌”及其“子实体”的，所以假如只返回其中的一句就足以满足要求了，如果返回两句含义非常接近的文本感觉是一种资源的浪费。下面我们来看一下
max_marginal_relevance_search 的搜索结果。</p>
<h3 id="解决多样性最大边际相关性mmr">1.2
解决多样性：最大边际相关性(MMR)</h3>
<p>最大边际相关模型 (MMR，Maximal Marginal Relevance)
是实现多样性检索的常用算法。</p>
<p><img src="../figures/C4/MMR_algorithm.png" /></p>
<div data-align="center">
图 4.5.2 MMR
</div>
<p><strong>MMR
的基本思想是同时考量查询与文档的相关度，以及文档之间的相似度</strong>。相关度确保返回结果对查询高度相关，相似度则鼓励不同语义的文档被包含进结果集。具体来说，它计算每个候选文档与查询的相关度，并减去与已经选入结果集的文档的相似度。这样更不相似的文档会有更高的得分。</p>
<p>总之，MMR
是解决检索冗余问题、提供多样性结果的一种简单高效的算法。它平衡了相关性和多样性，适用于对多样信息需求较强的应用场景。</p>
<p>我们来看一个利用 MMR
从蘑菇知识库中检索信息的示例。首先加载有关蘑菇的文档，然后运行 MMR
算法，设置 fetch_k 参数，用来告诉向量数据库我们最终需要 k
个结果返回。fetch_k=3 ，也就是我们最初获取 3 个文档，k=2
表示返回最不同的 2 个文档。</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>smalldb_chinese.max_marginal_relevance_search(question_chinese,k<span class="op">=</span><span class="dv">2</span>, fetch_k<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}),
 Document(page_content=&#39;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&#39;, metadata={})]</code></pre>
<p>这里我们看到 max_marginal_relevance_search（最大边际相关搜索）
返回了第二和第三句的文本，尽管第三句与我们的问题的相关性不太高，但是这样的结果其实应该是更加的合理，因为第一句和第二句文本本来就有着相似的含义，所以只需要返回其中的一句就可以了，另外再返回一个与问题相关性弱一点的答案(第三句文本)，这样似乎增强了答案的多样性，相信用户也会更加偏爱</p>
<p>还记得在上一节中我们介绍了两种向量数据在查询时的失败场景吗？当向量数据库中存在相同的文档时，而用户的问题又与这些重复的文档高度相关时，向量数据库会出现返回重复文档的情况。现在我们就可以运用Langchain的
max_marginal_relevance_search 来解决这个问题：</p>
<p>我们首先看看前两个文档，只看前几个字符，可以看到它们是相同的。</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;Matplotlib是什么？&quot;</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>docs_ss_chinese <span class="op">=</span> vectordb_chinese.similarity_search(question_chinese,k<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;docs[0]: &quot;</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_ss_chinese[<span class="dv">0</span>].page_content[:<span class="dv">100</span>])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;docs[1]: &quot;</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_ss_chinese[<span class="dv">1</span>].page_content[:<span class="dv">100</span>])</span></code></pre></div>
<pre><code>docs[0]: 
第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种

docs[1]: 
第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种</code></pre>
<p>这里如果我们使用相似查询，会得到两个重复的结果，读者可以自己尝试一下，这里不再展示。我们可以使用
<code>MMR</code> 得到不一样的结果。</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>docs_mmr_chinese <span class="op">=</span> vectordb_chinese.max_marginal_relevance_search(question_chinese,k<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
<p>当我们运行 MMR
后得到结果时，我们可以看到第一个与之前的相同，因为那是最相似的。</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_mmr_chinese[<span class="dv">0</span>].page_content[:<span class="dv">100</span>])</span></code></pre></div>
<pre><code>第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种</code></pre>
<p>但是当我们进行到第二个时，我们可以看到它是不同的。</p>
<p>它在回应中获得了一些多样性。</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_mmr_chinese[<span class="dv">1</span>].page_content[:<span class="dv">100</span>])</span></code></pre></div>
<pre><code>By Datawhale 数据可视化开源⼩组
© Copyright © Copyright 2021.y轴分为左右两个，因此 tick1 对应左侧的轴； tick2 对应右侧的轴。
x轴分为上下两个</code></pre>
<p>从以上结果中可以看到，向量数据库返回了 2
篇完全不同的文档，这是因为我们使用的是 MMR
搜索，它把搜索结果中相似度很高的文档做了过滤，所以它保留了结果的相关性又同时兼顾了结果的多样性。</p>
<h3 id="解决特殊性使用元数据">1.3 解决特殊性：使用元数据</h3>
<p>在上一节课中，关于失败的应用场景我们还提出了一个问题，是询问了关于文档中某一讲的问题，但得到的结果中也包括了来自其他讲的结果。这是我们所不希望看到的结果，之所以产生这样的结果是因为当我们向向量数据库提出问题时，数据库并没有很好的理解问题的语义，所以返回的结果不如预期。要解决这个问题，我们可以通过过滤元数据的方式来实现精准搜索，当前很多向量数据库都支持对<code>元数据（metadata）</code>的操作：</p>
<p><code>metadata</code>为每个嵌入的块(embedded chunk)提供上下文。</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;他们在第二讲中对Figure说了些什么？&quot;</span>  </span></code></pre></div>
<p>现在，我们以手动的方式来解决这个问题，我们会指定一个元数据过滤器<code>filter</code></p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>docs_chinese <span class="op">=</span> vectordb_chinese.similarity_search(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    question_chinese,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">filter</span><span class="op">=</span>{<span class="st">&quot;source&quot;</span>:<span class="st">&quot;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&quot;</span>}</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>接下来，我们可以看到结果都来自对应的章节</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> docs_chinese:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(d.metadata)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<pre><code>{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 9}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 0}</code></pre>
<p>当然，我们不能每次都采用手动的方式来解决这个问题，这会显得不够智能。下一小节中，我们将展示通过LLM来解决这个问题。</p>
<h3 id="解决特殊性在元数据中使用自查询检索器llm辅助检索">1.4
解决特殊性：在元数据中使用自查询检索器（LLM辅助检索）</h3>
<p>在上例中，我们手动设置了过滤参数 filter
来过滤指定文档。但这种方式不够智能，需要人工指定过滤条件。如何自动从用户问题中提取过滤信息呢？</p>
<p>LangChain提供了SelfQueryRetriever模块，它可以通过语言模型从问题语句中分析出:</p>
<ol type="1">
<li><p>向量搜索的查询字符串(search term)</p></li>
<li><p>过滤文档的元数据条件(Filter)</p></li>
</ol>
<p>以“除了维基百科,还有哪些健康网站”为例,SelfQueryRetriever可以推断出“除了维基百科”表示需要过滤的条件,即排除维基百科的文档。</p>
<p>它使用语言模型自动解析语句语义,提取过滤信息,无需手动设置。这种基于理解的元数据过滤更加智能方便,可以自动处理更复杂的过滤逻辑。</p>
<p>掌握利用语言模型实现自动化过滤的技巧,可以大幅降低构建针对性问答系统的难度。这种自抽取查询的方法使检索更加智能和动态。</p>
<p>其原理如下图所示：</p>
<p><img src="../figures/C4/LLM%20Aided%20Retrieval.png" /></p>
<div data-align="center">
图 4.5.3 自抽取查询
</div>
<p>下面我们就来实现一下LLM辅助检索：</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.llms <span class="im">import</span> OpenAI</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers.self_query.base <span class="im">import</span> SelfQueryRetriever</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains.query_constructor.base <span class="im">import</span> AttributeInfo</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> OpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<p>这里我们首先定义了 metadata_field_info_chinese
，它包含了元数据的过滤条件 <code>source</code> 和 <code>page</code> ,
其中 source 的作用是告诉 LLM 我们想要的数据来自于哪里， page 告诉 LLM
我们需要提取相关的内容在原始文档的哪一页。有了
metadata_field_info_chinese
信息后，LLM会自动从用户的问题中提取出上图中的 Filter 和 Search term
两项，然后向量数据库基于这两项去搜索相关的内容。下面我们看一下查询结果：</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>metadata_field_info_chinese <span class="op">=</span> [</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    AttributeInfo(</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="st">&quot;source&quot;</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">&quot;The lecture the chunk is from, should be one of `docs/matplotlib/第一回：Matplotlib初相识.pdf`, `docs/matplotlib/第二回：艺术画笔见乾坤.pdf`, or `docs/matplotlib/第三回：布局格式定方圆.pdf`&quot;</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">type</span><span class="op">=</span><span class="st">&quot;string&quot;</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    AttributeInfo(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="st">&quot;page&quot;</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">&quot;The page from the lecture&quot;</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">type</span><span class="op">=</span><span class="st">&quot;integer&quot;</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>document_content_description_chinese <span class="op">=</span> <span class="st">&quot;Matplotlib 课堂讲义&quot;</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>retriever_chinese <span class="op">=</span> SelfQueryRetriever.from_llm(</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    llm,</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    vectordb_chinese,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    document_content_description_chinese,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    metadata_field_info_chinese,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;他们在第二讲中对Figure做了些什么？&quot;</span>  </span></code></pre></div>
<p>当你第一次执行下一行时，你会收到关于predict_and_parse已被弃用的<strong>警告</strong>。
这可以安全地忽略。</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>docs_chinese <span class="op">=</span> retriever_chinese.get_relevant_documents(question_chinese)</span></code></pre></div>
<pre><code>/root/autodl-tmp/env/gpt/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(


query=&#39;Figure&#39; filter=Comparison(comparator=&lt;Comparator.EQ: &#39;eq&#39;&gt;, attribute=&#39;source&#39;, value=&#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;) limit=None</code></pre>
<p>打印可以看到查询结果，基于子查询检索器，我们检索到的结果都是在第二回的文档中：</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> docs_chinese:</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(d.metadata)</span></code></pre></div>
<pre><code>{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 9}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 6}</code></pre>
<h3 id="其他技巧压缩">1.5 其他技巧：压缩</h3>
<p>在使用向量检索获取相关文档时，直接返回整个文档片段可能带来资源浪费，因为实际相关的只是文档的一小部分。为改进这一点，LangChain提供了一种“<code>压缩</code>”检索机制。其工作原理是，<strong>先使用标准向量检索获得候选文档，然后基于查询语句的语义，使用语言模型压缩这些文档,只保留与问题相关的部分</strong>。例如，对“蘑菇的营养价值”这个查询，检索可能返回整篇有关蘑菇的长文档。经压缩后，只提取文档中与“营养价值”相关的句子。</p>
<p><img src="../figures/C4/Compression.png" /></p>
<div data-align="center">
图 4.5.4 压缩
</div>
<p>从上图中我们看到，当向量数据库返回了所有与问题相关的所有文档块的全部内容后，会有一个Compression
LLM来负责对这些返回的文档块的内容进行压缩，所谓压缩是指仅从文档块中提取出和用户问题相关的内容，并舍弃掉那些不相关的内容。</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> ContextualCompressionRetriever</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers.document_compressors <span class="im">import</span> LLMChainExtractor</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pretty_print_docs(docs):</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="sc">{</span><span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">100</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>.join([<span class="ss">f&quot;Document </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:</span><span class="ch">\n\n</span><span class="ss">&quot;</span> <span class="op">+</span> d.page_content <span class="cf">for</span> i, d <span class="kw">in</span> <span class="bu">enumerate</span>(docs)]))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> OpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>compressor <span class="op">=</span> LLMChainExtractor.from_llm(llm)  <span class="co"># 压缩器</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>compression_retriever_chinese <span class="op">=</span> ContextualCompressionRetriever(</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    base_compressor<span class="op">=</span>compressor,</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    base_retriever<span class="op">=</span>vectordb_chinese.as_retriever()</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 对源文档进行压缩</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;Matplotlib是什么？&quot;</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>compressed_docs_chinese <span class="op">=</span> compression_retriever_chinese.get_relevant_documents(question_chinese)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>pretty_print_docs(compressed_docs_chinese)</span></code></pre></div>
<pre><code>Document 1:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。
----------------------------------------------------------------------------------------------------
Document 2:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。</code></pre>
<p>在上面的代码中我们定义了一个 LLMChainExtractor
，它是一个压缩器，它负责从向量数据库返回的文档块中提取相关信息，然后我们还定义了
ContextualCompressionRetriever ，它有两个参数：base_compressor 和
base_retriever，其中 base_compressor 是我们前面定义的 LLMChainExtractor
的实例，base_retriever是早前定义的 vectordb 产生的检索器。</p>
<p>现在当我们提出问题后，查看结果文档，我们可以看到两件事。</p>
<ol type="1">
<li>它们比正常文档短很多</li>
<li>仍然有一些重复的东西，这是因为在底层我们使用的是语义搜索算法。</li>
</ol>
<p>从上述例子中，我们可以发现这种压缩可以有效提升输出质量，同时节省通过长文档带来的计算资源浪费，降低成本。上下文相关的压缩检索技术，使得到的支持文档更严格匹配问题需求，是提升问答系统效率的重要手段。读者可以在实际应用中考虑这一技术。</p>
<h2 id="二结合各种技术">二、结合各种技术</h2>
<p>为了去掉结果中的重复文档，我们在从向量数据库创建检索器时，可以将搜索类型设置为
MMR
。然后我们可以重新运行这个过程，可以看到我们返回的是一个过滤过的结果集，其中不包含任何重复的信息。</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>compression_retriever_chinese <span class="op">=</span> ContextualCompressionRetriever(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    base_compressor<span class="op">=</span>compressor,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    base_retriever<span class="op">=</span>vectordb_chinese.as_retriever(search_type <span class="op">=</span> <span class="st">&quot;mmr&quot;</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;Matplotlib是什么？&quot;</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>compressed_docs_chinese <span class="op">=</span> compression_retriever_chinese.get_relevant_documents(question_chinese)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>pretty_print_docs(compressed_docs_chinese)</span></code></pre></div>
<pre><code>Document 1:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。</code></pre>
<h2 id="三其他类型的检索">三、其他类型的检索</h2>
<p>值得注意的是，vetordb
并不是唯一一种检索文档的工具。<code>LangChain</code>
还提供了其他检索文档的方式，例如：<code>TF-IDF</code> 或
<code>SVM</code>。</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> SVMRetriever</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> TFIDFRetriever</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.document_loaders <span class="im">import</span> PyPDFLoader</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> RecursiveCharacterTextSplitter</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载PDF</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>loader_chinese <span class="op">=</span> PyPDFLoader(<span class="st">&quot;docs/matplotlib/第一回：Matplotlib初相识.pdf&quot;</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>pages_chinese <span class="op">=</span> loader_chinese.load()</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>all_page_text_chinese <span class="op">=</span> [p.page_content <span class="cf">for</span> p <span class="kw">in</span> pages_chinese]</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>joined_page_text_chinese <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(all_page_text_chinese)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 分割文本</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>text_splitter_chinese <span class="op">=</span> RecursiveCharacterTextSplitter(chunk_size <span class="op">=</span> <span class="dv">1500</span>,chunk_overlap <span class="op">=</span> <span class="dv">150</span>)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>splits_chinese <span class="op">=</span> text_splitter_chinese.split_text(joined_page_text_chinese)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 检索</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>svm_retriever <span class="op">=</span> SVMRetriever.from_texts(splits_chinese, embedding)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>tfidf_retriever <span class="op">=</span> TFIDFRetriever.from_texts(splits_chinese)</span></code></pre></div>
<p>这里我们定义了 SVMRetriever ，和 TFIDFRetriever
两个检索器，接下来我们分别测试 TF-IDF 检索以及 SVM 检索的效果：</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;这门课的主要主题是什么？&quot;</span> </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>docs_svm_chinese <span class="op">=</span> svm_retriever.get_relevant_documents(question_chinese)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_svm_chinese[<span class="dv">0</span>])</span></code></pre></div>
<pre><code>page_content=&#39;fig, ax = plt.subplots()  \n# step4 绘制图像，  这⼀模块的扩展参考第⼆章进⼀步学习\nax.plot(x, y, label=\&#39;linear\&#39;)  \n# step5 添加标签，⽂字和图例，这⼀模块的扩展参考第四章进⼀步学习\nax.set_xlabel(\&#39;x label\&#39;) \nax.set_ylabel(\&#39;y label\&#39;) \nax.set_title(&quot;Simple Plot&quot;)  \nax.legend() ;\n思考题\n请思考两种绘图模式的优缺点和各⾃适合的使⽤场景\n在第五节绘图模板中我们是以 OO 模式作为例⼦展示的，请思考并写⼀个 pyplot 绘图模式的简单模板&#39; metadata={}</code></pre>
<p>可以看出，SVM 检索的效果要差于 VectorDB。</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>question_chinese <span class="op">=</span> <span class="st">&quot;Matplotlib是什么？&quot;</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>docs_tfidf_chinese <span class="op">=</span> tfidf_retriever.get_relevant_documents(question_chinese)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_tfidf_chinese[<span class="dv">0</span>])</span></code></pre></div>
<pre><code>page_content=&#39;fig, ax = plt.subplots()  \n# step4 绘制图像，  这⼀模块的扩展参考第⼆章进⼀步学习\nax.plot(x, y, label=\&#39;linear\&#39;)  \n# step5 添加标签，⽂字和图例，这⼀模块的扩展参考第四章进⼀步学习\nax.set_xlabel(\&#39;x label\&#39;) \nax.set_ylabel(\&#39;y label\&#39;) \nax.set_title(&quot;Simple Plot&quot;)  \nax.legend() ;\n思考题\n请思考两种绘图模式的优缺点和各⾃适合的使⽤场景\n在第五节绘图模板中我们是以 OO 模式作为例⼦展示的，请思考并写⼀个 pyplot 绘图模式的简单模板&#39; metadata={}</code></pre>
<p>同样，TF-IDF 检索的效果也不尽如人意。</p>
<h2 id="四总结">四、总结</h2>
<p>今天的课程涵盖了向量检索的多项新技术，让我们快速回顾关键要点：</p>
<ol type="1">
<li><p>MMR
算法可以实现兼具相关性与多样性的检索结果，避免信息冗余。</p></li>
<li><p>定义元数据字段可以进行针对性过滤，提升匹配准确率。</p></li>
<li><p>SelfQueryRetriever
模块通过语言模型自动分析语句，提取查询字符串与过滤条件，无需手动设置，使检索更智能。</p></li>
<li><p>ContextualCompressionRetriever
实现压缩检索，仅返回与问题相关的文档片段，可以大幅提升效率并节省计算资源。</p></li>
<li><p>除向量检索外，还简要介绍了基于 SVM 和 TF-IDF
的检索方法。</p></li>
</ol>
<p>这些技术为我们构建可交互的语义搜索模块提供了重要支持。熟练掌握各检索算法的适用场景，将大大增强问答系统的智能水平。希望本节的教程能够对大家有所帮助!</p>
<h2 id="五英文版">五、英文版</h2>
<p><strong>1.1 相似性检索</strong></p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> Chroma</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.embeddings.openai <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>persist_directory <span class="op">=</span> <span class="st">&#39;docs/chroma/cs229_lectures/&#39;</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> OpenAIEmbeddings()</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>vectordb <span class="op">=</span> Chroma(</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    persist_directory<span class="op">=</span>persist_directory,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    embedding_function<span class="op">=</span>embedding</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vectordb._collection.count())</span></code></pre></div>
<pre><code>209</code></pre>
<p>简单示例</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).&quot;&quot;&quot;</span>,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.&quot;&quot;&quot;</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&quot;&quot;A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.&quot;&quot;&quot;</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>smalldb <span class="op">=</span> Chroma.from_texts(texts, embedding<span class="op">=</span>embedding)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;Tell me about all-white mushrooms with large fruiting bodies&quot;</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;相似性检索：&quot;</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(smalldb.similarity_search(question, k<span class="op">=</span><span class="dv">2</span>))</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;MMR 检索：&quot;</span>)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(smalldb_chinese.max_marginal_relevance_search(question,k<span class="op">=</span><span class="dv">2</span>, fetch_k<span class="op">=</span><span class="dv">3</span>))</span></code></pre></div>
<pre><code>  0%|          | 0/1 [00:00&lt;?, ?it/s]100%|██████████| 1/1 [00:00&lt;00:00,  2.55it/s]


相似性检索：
[Document(page_content=&#39;A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.&#39;, metadata={}), Document(page_content=&#39;The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).&#39;, metadata={})]
MMR 检索：
[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}), Document(page_content=&#39;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&#39;, metadata={})]</code></pre>
<p><strong>1.2 最大边际相关性</strong></p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about matlab?&quot;</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>docs_ss <span class="op">=</span> vectordb.similarity_search(question,k<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;相似性检索：&quot;</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;docs[0]: &quot;</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_ss[<span class="dv">0</span>].page_content[:<span class="dv">100</span>])</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;docs[1]: &quot;</span>)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_ss[<span class="dv">1</span>].page_content[:<span class="dv">100</span>])</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>docs_mmr <span class="op">=</span> vectordb.max_marginal_relevance_search(question,k<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;MMR 检索：&quot;</span>)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;mmr[0]: &quot;</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_mmr[<span class="dv">0</span>].page_content[:<span class="dv">100</span>])</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;MMR 检索：&quot;</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;mmr[1]: &quot;</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_mmr[<span class="dv">1</span>].page_content[:<span class="dv">100</span>])</span></code></pre></div>
<pre><code>相似性检索：
docs[0]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people 

docs[1]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people 

MMR 检索：
mmr[0]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people 

MMR 检索：
mmr[1]: 
algorithm then? So what’s different? How come  I was making all that noise earlier about 
least squa</code></pre>
<p><strong>1.3 使用元数据</strong></p>
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about regression in the third lecture?&quot;</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> vectordb.similarity_search(</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    question,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">filter</span><span class="op">=</span>{<span class="st">&quot;source&quot;</span>:<span class="st">&quot;docs/cs229_lectures/MachineLearning-Lecture03.pdf&quot;</span>}</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> docs:</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(d.metadata)</span></code></pre></div>
<pre><code>{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 14}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 4}</code></pre>
<p><strong>1.4 使用自查询检索器</strong></p>
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.llms <span class="im">import</span> OpenAI</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers.self_query.base <span class="im">import</span> SelfQueryRetriever</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains.query_constructor.base <span class="im">import</span> AttributeInfo</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> OpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>metadata_field_info <span class="op">=</span> [</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    AttributeInfo(</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="st">&quot;source&quot;</span>,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">&quot;The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`&quot;</span>,</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">type</span><span class="op">=</span><span class="st">&quot;string&quot;</span>,</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>    AttributeInfo(</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="st">&quot;page&quot;</span>,</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">&quot;The page from the lecture&quot;</span>,</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">type</span><span class="op">=</span><span class="st">&quot;integer&quot;</span>,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>document_content_description <span class="op">=</span> <span class="st">&quot;Lecture notes&quot;</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>retriever <span class="op">=</span> SelfQueryRetriever.from_llm(</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    llm,</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    vectordb,</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>    document_content_description,</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>    metadata_field_info,</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about regression in the third lecture?&quot;</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> retriever.get_relevant_documents(question)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> docs:</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(d.metadata)</span></code></pre></div>
<pre><code>/root/autodl-tmp/env/gpt/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(


query=&#39;regression&#39; filter=Comparison(comparator=&lt;Comparator.EQ: &#39;eq&#39;&gt;, attribute=&#39;source&#39;, value=&#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;) limit=None
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 14}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 10}</code></pre>
<p><strong>1.5 压缩</strong></p>
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> ContextualCompressionRetriever</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers.document_compressors <span class="im">import</span> LLMChainExtractor</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pretty_print_docs(docs):</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="sc">{</span><span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">100</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>.join([<span class="ss">f&quot;Document </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:</span><span class="ch">\n\n</span><span class="ss">&quot;</span> <span class="op">+</span> d.page_content <span class="cf">for</span> i, d <span class="kw">in</span> <span class="bu">enumerate</span>(docs)]))</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> OpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>compressor <span class="op">=</span> LLMChainExtractor.from_llm(llm)  <span class="co"># 压缩器</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>compression_retriever <span class="op">=</span> ContextualCompressionRetriever(</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    base_compressor<span class="op">=</span>compressor,</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    base_retriever<span class="op">=</span>vectordb.as_retriever()</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about matlab?&quot;</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>compressed_docs <span class="op">=</span> compression_retriever.get_relevant_documents(question)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>pretty_print_docs(compressed_docs)</span></code></pre></div>
<pre><code>Document 1:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 2:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 3:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;
----------------------------------------------------------------------------------------------------
Document 4:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;</code></pre>
<p><strong>2.1 结合各种技术</strong></p>
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>compression_retriever <span class="op">=</span> ContextualCompressionRetriever(</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    base_compressor<span class="op">=</span>compressor,</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    base_retriever<span class="op">=</span>vectordb.as_retriever(search_type <span class="op">=</span> <span class="st">&quot;mmr&quot;</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about matlab?&quot;</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>compressed_docs <span class="op">=</span> compression_retriever.get_relevant_documents(question)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>pretty_print_docs(compressed_docs)</span></code></pre></div>
<pre><code>Document 1:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 2:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;</code></pre>
<p><strong>3.1 其他类型的检索</strong></p>
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> SVMRetriever</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> TFIDFRetriever</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.document_loaders <span class="im">import</span> PyPDFLoader</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> RecursiveCharacterTextSplitter</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载PDF</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>loader <span class="op">=</span> PyPDFLoader(<span class="st">&quot;docs/cs229_lectures/MachineLearning-Lecture01.pdf&quot;</span>)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>pages <span class="op">=</span> loader.load()</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>all_page_text <span class="op">=</span> [p.page_content <span class="cf">for</span> p <span class="kw">in</span> pages]</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>joined_page_text <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(all_page_text)</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 分割文本</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>text_splitter <span class="op">=</span> RecursiveCharacterTextSplitter(chunk_size <span class="op">=</span> <span class="dv">1500</span>,chunk_overlap <span class="op">=</span> <span class="dv">150</span>)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>splits <span class="op">=</span> text_splitter.split_text(joined_page_text)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 检索</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>svm_retriever <span class="op">=</span> SVMRetriever.from_texts(splits, embedding)</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>tfidf_retriever <span class="op">=</span> TFIDFRetriever.from_texts(splits)</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;What are major topics for this class?&quot;</span>  <span class="co"># 这门课的主要主题是什么？</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;SVM:&quot;</span>)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>docs_svm <span class="op">=</span> svm_retriever.get_relevant_documents(question)</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_svm[<span class="dv">0</span>])</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;what did they say about matlab?&quot;</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;TF-IDF:&quot;</span>)</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>docs_tfidf <span class="op">=</span> tfidf_retriever.get_relevant_documents(question)</span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(docs_tfidf[<span class="dv">0</span>])</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<pre><code>SVM:
page_content=&quot;let me just check what questions you have righ t now. So if there are no questions, I&#39;ll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? Form study groups, and try \nto find two other project partners.  \nSo thank you. I&#39;m looking forward to teaching this class, and I&#39;ll see you in a couple of \ndays.   [End of Audio]  \nDuration: 69 minutes&quot; metadata={}
TF-IDF:
page_content=&quot;Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. Let me actually blow that up so that you can see it more \nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? Although many people used to th ink it&#39;s not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. They were able to.  \nI&#39;ll just show you one more example. I like this  because it&#39;s a picture of Stanford with our \nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look&quot; metadata={}</code></pre>
</body>
</html>
