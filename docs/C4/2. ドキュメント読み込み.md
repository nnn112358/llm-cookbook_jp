# 第2章 文書読み込み



ユーザーの個人データは多様な形式で存在します：PDF文書、動画、ウェブページなど。LangChainがLLMにユーザー個人データへのアクセス能力を提供することに基づいて、まずユーザーの多様で非構造化された個人データを読み込み、処理する必要があります。本章では、まず文書（文書、動画、ウェブページなどを含む）の読み込み方法を紹介します。これは個人データアクセスの最初のステップです。

まずPDF文書から始めましょう。

## 一、PDF文書



まず、以下のリンクから[PDF文書](https://datawhalechina.github.io/fantastic-matplotlib/)を読み込みます。これはDataWhaleが提供するオープンソースチュートリアル『Fantastic Matplotlib』です。なお、英語版では、アンドリュー・ン教授が[2009年の機械学習講義の字幕ファイル](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf)を例として使用しています。中国語読者により適するため、上記の中国語チュートリアルを例として選択しました。ただし、英語版のコードでは、アンドリュー・ン教授の機械学習講義ファイルを参考として見つけることができます。後続のコード実践もこの調整に従います。

注意，要运行以下代码，你需要安装第三方库 pypdf：


```python
!pip install -q pypdf
```

### 1.1 PDF文書の読み込み

最初に、`PyPDFLoader`を使用してPDFファイルの読み取りと読み込みを行います。


```python
from langchain.document_loaders import PyPDFLoader

# 创建一个 PyPDFLoader Class 实例，输入为待加载的pdf文档路径
loader = PyPDFLoader("docs/matplotlib/第一回：Matplotlib初相识.pdf")

# 调用 PyPDFLoader Class 的函数 load对pdf文件进行加载
pages = loader.load()
```

### 1.2 読み込まれたデータの探索

文書が読み込まれると、`pages`という変数に格納されます。さらに、`pages`のデータ構造は`List`型です。その型を確認するために、Pythonの組み込み`type`関数を使用して`pages`の正確なデータ型を確認できます。


```python
print(type(pages))
```

    <class 'list'>


`pages`の長さを出力することで、そのPDFファイルに含まれる総ページ数を簡単に確認できます。


```python
print(len(pages))
```

    3


`page`変数では、各要素が一つの文書を表し、それらのデータ型は`langchain.schema.document.Document`です。


```python
page = pages[0]
print(type(page))
```

    <class 'langchain.schema.document.Document'>


`langchain.schema.document.Document`型には2つの属性があります：

1. `page_content`：その文書ページの内容を含みます。



```python
print(page.page_content[0:500])
```

    第⼀回：Matplotlib 初相识
    ⼀、认识matplotlib
    Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，
    交互式的图表。
    Matplotlib 可⽤于 Python 脚本， Python 和 IPython Shell 、 Jupyter notebook ， Web 应⽤程序服务器和各种图形⽤户界⾯⼯具包等。
    Matplotlib 是 Python 数据可视化库中的泰⽃，它已经成为 python 中公认的数据可视化⼯具，我们所熟知的 pandas 和 seaborn 的绘图接⼝
    其实也是基于 matplotlib 所作的⾼级封装。
    为了对matplotlib 有更好的理解，让我们从⼀些最基本的概念开始认识它，再逐渐过渡到⼀些⾼级技巧中。
    ⼆、⼀个最简单的绘图例⼦
    Matplotlib 的图像是画在 figure （如 windows ， jupyter 窗体）上的，每⼀个 figure ⼜包含了⼀个或多个 axes （⼀个可以指定坐标系的⼦区
    域）。最简单的创建 figure 


2. `meta_data`：文書ページに関連する記述的データです。


```python
print(page.metadata)
```

    {'source': 'docs/matplotlib/第一回：Matplotlib初相识.pdf', 'page': 0}


## 二、YouTube音声


第一部分ではPDF文書の読み込み方法を探索しました。この部分では、指定されたYouTube動画のリンクに対して詳しく説明します：
- `langchain`読み込みツールを使用し、指定されたYouTube動画リンクの対応する音声をローカルにダウンロード
- `OpenAIWhisperPaser`ツールを使用して、これらの音声ファイルを読みやすいテキスト内容に変換

注意，要运行以下代码，你需要安装如下两个第三方库：


```python
!pip -q install yt_dlp
!pip -q install pydub
```

### 2.1 YouTube音声文書の読み込み

最初に、`GenericLoader`インスタンスを構築してYouTube動画をローカルにダウンロードし、読み込みます。


```python
from langchain.document_loaders.generic import GenericLoader
from langchain.document_loaders.parsers import OpenAIWhisperParser
from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader

url="https://www.youtube.com/watch?v=_PHdzsQaDgw"
save_dir="docs/youtube-zh/"

# 创建一个 GenericLoader Class 实例
loader = GenericLoader(
    #将链接url中的Youtube视频的音频下载下来,存在本地路径save_dir
    YoutubeAudioLoader([url],save_dir), 
    
    #使用OpenAIWhisperPaser解析器将音频转化为文本
    OpenAIWhisperParser()
)

# 调用 GenericLoader Class 的函数 load对视频的音频文件进行加载
pages = loader.load()
```

    [youtube] Extracting URL: https://www.youtube.com/watch?v=_PHdzsQaDgw
    [youtube] _PHdzsQaDgw: Downloading webpage
    [youtube] _PHdzsQaDgw: Downloading ios player API JSON
    [youtube] _PHdzsQaDgw: Downloading android player API JSON
    [youtube] _PHdzsQaDgw: Downloading m3u8 information


    WARNING: [youtube] Failed to download m3u8 information: HTTP Error 429: Too Many Requests


    [info] _PHdzsQaDgw: Downloading 1 format(s): 140
    [download] docs/youtube-zh//【2023年7月最新】ChatGPT注册教程，国内详细注册流程，支持中文使用，chatgpt 中国怎么用？.m4a has already been downloaded
    [download] 100% of    7.72MiB
    [ExtractAudio] Not converting audio docs/youtube-zh//【2023年7月最新】ChatGPT注册教程，国内详细注册流程，支持中文使用，chatgpt 中国怎么用？.m4a; file is already in target format m4a
    Transcribing part 1!


### 2.2 読み込まれたデータの探索

YouTube音声ファイルを読み込んで得られた変数は上記と同様で、ここでは一つずつ説明しません。同様のコードで読み込みデータを表示できます：


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  1
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  大家好,欢迎来到我的频道 今天我们来介绍如何注册ChetGBT账号 之前我有介绍过一期如何注册ChetGBT账号 但是还是会有一些朋友在注册过程当中 遇到了一些问题 今天我们再来详细介绍最新的注册方法 我们先打开这个网站 这个网站的网址我会放到视频下方的评论区 大家可以直接点击打开 这个网站是需要翻墙才能打开 建议使用全局模式翻墙打开 可以选择台湾,新加坡,日本,美国节点 不要选择香港节点 我这里使用的是台湾节点 这个翻墙软件如果大家需要的话 我也会共享在视频的下方 另外浏览器需要开启无痕模式打开 这个就是打开新的无痕模式窗口 我们可以按快捷键,Ctrl键加Shift键加N 可以打开新的无痕模式窗口 然后用无痕模式窗口来打开这个网站 然后点击这里 然后会出现这个登录注册界面 如果没有显示这个界面 显示的是拒绝访问 那么就表示你使用的节点可能有问题 我们需要切换其他的节点 我们可以这样切换其他的节点 能够正常打开这个页面 表示节点是没问题的 我们可以点击注册 这里需要填一个邮箱 然后点击继续 然后需要输入密码 再点击继续 然后会出现这个提示 我们需要去收一封邮件 刷新一下 邮件已经收到了
    Meta Data:  {'source': 'docs/youtube-zh/【2023年7月最新】ChatGPT注册教程，国内详细注册流程，支持中文使用，chatgpt 中国怎么用？.m4a', 'chunk': 0}


## 三、ウェブページ文書



第二部分では、指定されたYouTube動画リンク（URL）に対して、LangChainローダーを使用して動画の音声をローカルにダウンロードし、その後OpenAIWhisperPaserパーサーを使用して音声をテキストに変換しました。

この部分では、ウェブページリンク（URLs）の処理方法を研究します。そのため、GitHub上のmarkdown形式の文書を例として、その読み込み方法を学習します。

### 3.1 ウェブページ文書の読み込み

最初に、`WebBaseLoader`インスタンスを構築してウェブページを読み込みます。


```python
from langchain.document_loaders import WebBaseLoader


# 创建一个 WebBaseLoader Class 实例
url = "https://github.com/datawhalechina/d2l-ai-solutions-manual/blob/master/docs/README.md"
header = {'User-Agent': 'python-requests/2.27.1', 
          'Accept-Encoding': 'gzip, deflate, br', 
          'Accept': '*/*',
          'Connection': 'keep-alive'}
loader = WebBaseLoader(web_path=url,header_template=header)

# 调用 WebBaseLoader Class 的函数 load对文件进行加载
pages = loader.load()
```

### 3.2 読み込まれたデータの探索

同様に、上記のコードで読み込みデータを表示できます：


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  1
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  {"payload":{"allShortcutsEnabled":false,"fileTree":{"docs":{"items":[{"name":"ch02","path":"docs/ch02","contentType":"directory"},{"name":"ch03","path":"docs/ch03","contentType":"directory"},{"name":"ch05","path":"docs/ch05","contentType":"directory"},{"name":"ch06","path":"docs/ch06","contentType":"directory"},{"name":"ch08","path":"docs/ch08","contentType":"directory"},{"name":"ch09","path":"docs/ch09","contentType":"directory"},{"name":"ch10","path":"docs/ch10","contentType":"directory"},{"na
    Meta Data:  {'source': 'https://github.com/datawhalechina/d2l-ai-solutions-manual/blob/master/docs/README.md'}


上記の文書内容には多くの余分な情報が含まれていることが分かります。通常、このようなデータに対してさらなる後処理（Post Processing）を行う必要があります。


```python
import json
convert_to_json = json.loads(page.page_content)
extracted_markdown = convert_to_json['payload']['blob']['richText']
print(extracted_markdown)
```

    动手学深度学习习题解答 {docsify-ignore-all}
      李沐老师的《动手学深度学习》是入门深度学习的经典书籍，这本书基于深度学习框架来介绍深度学习，书中代码可以做到“所学即所用”。对于一般的初学者来说想要把书中课后习题部分独立解答还是比较困难。本项目对《动手学深度学习》习题部分进行解答，作为该书的习题手册，帮助初学者快速理解书中内容。
    使用说明
      动手学深度学习习题解答，主要完成了该书的所有习题，并提供代码和运行之后的截图，里面的内容是以深度学习的内容为前置知识，该习题解答的最佳使用方法是以李沐老师的《动手学深度学习》为主线，并尝试完成课后习题，如果遇到不会的，再来查阅习题解答。
      如果觉得解答不详细，可以点击这里提交你希望补充推导或者习题编号，我们看到后会尽快进行补充。
    选用的《动手学深度学习》版本
    
    
    书名：动手学深度学习（PyTorch版）
    著者：阿斯顿·张、[美]扎卡里 C. 立顿、李沐、[德]亚历山大·J.斯莫拉
    译者：何孝霆、瑞潮儿·胡
    出版社：人民邮电出版社
    版次：2023年2月第1版
    
    项目结构
    codes----------------------------------------------习题代码
    docs-----------------------------------------------习题解答
    notebook-------------------------------------------习题解答JupyterNotebook格式
    requirements.txt-----------------------------------运行环境依赖包
    
    关注我们
    
    扫描下方二维码关注公众号：Datawhale
    
    
      Datawhale，一个专注于AI领域的学习圈子。初衷是for the learner，和学习者一起成长。目前加入学习社群的人数已经数千人，组织了机器学习，深度学习，数据分析，数据挖掘，爬虫，编程，统计学，Mysql，数据竞赛等多个领域的内容学习，微信搜索公众号Datawhale可以加入我们。
    LICENSE
    本作品采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议进行许可。
    


## 四、Notion文書

- [Notionサンプル文書](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f)(https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f)の右上のコピーボタン(Duplicate)をクリックし、文書をあなたのNotionスペースにコピー
- 右上の`⋯`ボタンをクリックし、Markdown&CSVとしてエクスポートを選択。エクスポートされたファイルはzipフォルダとなります
- 解凍してmarkdown文書をローカルパス`docs/Notion_DB/`に保存

### 4.1 Notion Markdown文書の読み込み

最初に、`NotionDirectoryLoader`を使用してNotion Markdown文書を読み込みます。


```python
from langchain.document_loaders import NotionDirectoryLoader
loader = NotionDirectoryLoader("docs/Notion_DB")
pages = loader.load()
```

### 4.2 読み込まれたデータの探索

同様に、上記のコードを使用します：


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  51
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  # #letstalkaboutstress
    
    Let’s talk about stress. Too much stress. 
    
    We know this can be a topic.
    
    So let’s get this conversation going. 
    
    [Intro: two things you should know](#letstalkaboutstress%2064040a0733074994976118bbe0acc7fb/Intro%20two%20things%20you%20should%20know%20b5fd0c5393a9498b93396e79fe71e8bf.md)
    
    [What is stress](#letstalkaboutstress%2064040a0733074994976118bbe0acc7fb/What%20is%20stress%20b198b685ed6a474ab14f6fafff7004b6.md)
    
    [When is there too much stress?](#letstalkaboutstress%2
    Meta Data:  {'source': 'docs/Notion_DB/#letstalkaboutstress 64040a0733074994976118bbe0acc7fb.md'}


## 五、英語版

**1.1 PDF文書の読み込み**


```python
from langchain.document_loaders import PyPDFLoader

# 创建一个 PyPDFLoader Class 实例，输入为待加载的pdf文档路径
loader = PyPDFLoader("docs/cs229_lectures/MachineLearning-Lecture01.pdf")

# 调用 PyPDFLoader Class 的函数 load对pdf文件进行加载
pages = loader.load()
```

**1.2 読み込まれたデータの探索**


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  22
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  MachineLearning-Lecture01  
    Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine 
    learning class. So what I wanna do today is ju st spend a little time going over the logistics 
    of the class, and then we'll start to  talk a bit about machine learning.  
    By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so 
    I personally work in machine learning, and I' ve worked on it for about 15 years now, and 
    I actually think that machine learning i
    Meta Data:  {'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}


**2.1 YouTube音声の読み込み**


```python
# 注：由于该视频较长，容易出现网络问题，此处没有运行，读者可自行运行探索

from langchain.document_loaders.generic import GenericLoader
from langchain.document_loaders.parsers import OpenAIWhisperParser
from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader

url="https://www.youtube.com/watch?v=jGwO_UgTS7I"
save_dir="docs/youtube/"

# 创建一个 GenericLoader Class 实例
loader = GenericLoader(
    #将链接url中的Youtube视频的音频下载下来,存在本地路径save_dir
    YoutubeAudioLoader([url],save_dir), 
    
    #使用OpenAIWhisperPaser解析器将音频转化为文本
    OpenAIWhisperParser()
)

# 调用 GenericLoader Class 的函数 load对视频的音频文件进行加载
docs = loader.load()
```

**2.2 読み込まれたデータの探索**


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

**3.1 ウェブページ文書の読み込み**


```python
from langchain.document_loaders import WebBaseLoader


# 创建一个 WebBaseLoader Class 实例
url = "https://github.com/basecamp/handbook/blob/master/37signals-is-you.md"
header = {'User-Agent': 'python-requests/2.27.1', 
          'Accept-Encoding': 'gzip, deflate, br', 
          'Accept': '*/*',
          'Connection': 'keep-alive'}
loader = WebBaseLoader(web_path=url,header_template=header)

# 调用 WebBaseLoader Class 的函数 load对文件进行加载
pages = loader.load()
```

**3.2 読み込まれたデータの探索**


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  1
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  {"payload":{"allShortcutsEnabled":false,"fileTree":{"":{"items":[{"name":"37signals-is-you.md","path":"37signals-is-you.md","contentType":"file"},{"name":"LICENSE.md","path":"LICENSE.md","contentType":"file"},{"name":"README.md","path":"README.md","contentType":"file"},{"name":"benefits-and-perks.md","path":"benefits-and-perks.md","contentType":"file"},{"name":"code-of-conduct.md","path":"code-of-conduct.md","contentType":"file"},{"name":"faq.md","path":"faq.md","contentType":"file"},{"name":"ge
    Meta Data:  {'source': 'https://github.com/basecamp/handbook/blob/master/37signals-is-you.md'}


さらなる処理を行う


```python
import json
convert_to_json = json.loads(page.page_content)
extracted_markdown = convert_to_json['payload']['blob']['richText']
print(extracted_markdown)
```

    37signals Is You
    Everyone working at 37signals represents 37signals. When a customer gets a response from Merissa on support, Merissa is 37signals. When a customer reads a tweet by Eron that our systems are down, Eron is 37signals. In those situations, all the other stuff we do to cultivate our best image is secondary. What’s right in front of someone in a time of need is what they’ll remember.
    That’s what we mean when we say marketing is everyone’s responsibility, and that it pays to spend the time to recognize that. This means avoiding the bullshit of outage language and bending our policies, not just lending your ears. It means taking the time to get the writing right and consider how you’d feel if you were on the other side of the interaction.
    The vast majority of our customers come from word of mouth and much of that word comes from people in our audience. This is an audience we’ve been educating and entertaining for 20 years and counting, and your voice is part of us now, whether you like it or not! Tell us and our audience what you have to say!
    This goes for tools and techniques as much as it goes for prose. 37signals not only tries to out-teach the competition, but also out-share and out-collaborate. We’re prolific open source contributors through Ruby on Rails, Trix, Turbolinks, Stimulus, and many other projects. Extracting the common infrastructure that others could use as well is satisfying, important work, and we should continue to do that.
    It’s also worth mentioning that joining 37signals can be all-consuming. We’ve seen it happen. You dig 37signals, so you feel pressure to contribute, maybe overwhelmingly so. The people who work here are some of the best and brightest in our industry, so the self-imposed burden to be exceptional is real. But here’s the thing: stop it. Settle in. We’re glad you love this job because we all do too, but at the end of the day it’s a job. Do your best work, collaborate with your team, write, read, learn, and then turn off your computer and play with your dog. We’ll all be better for it.
    


**4.1 Notion文書の読み込み**


```python
from langchain.document_loaders import NotionDirectoryLoader
loader = NotionDirectoryLoader("docs/Notion_DB")
pages = loader.load()
```

**4.2 読み込まれたデータの探索**


```python
print("Type of pages: ", type(pages))
print("Length of pages: ", len(pages))

page = pages[0]
print("Type of page: ", type(page))
print("Page_content: ", page.page_content[:500])
print("Meta Data: ", page.metadata)
```

    Type of pages:  <class 'list'>
    Length of pages:  51
    Type of page:  <class 'langchain.schema.document.Document'>
    Page_content:  # #letstalkaboutstress
    
    Let’s talk about stress. Too much stress. 
    
    We know this can be a topic.
    
    So let’s get this conversation going. 
    
    [Intro: two things you should know](#letstalkaboutstress%2064040a0733074994976118bbe0acc7fb/Intro%20two%20things%20you%20should%20know%20b5fd0c5393a9498b93396e79fe71e8bf.md)
    
    [What is stress](#letstalkaboutstress%2064040a0733074994976118bbe0acc7fb/What%20is%20stress%20b198b685ed6a474ab14f6fafff7004b6.md)
    
    [When is there too much stress?](#letstalkaboutstress%2
    Meta Data:  {'source': 'docs/Notion_DB/#letstalkaboutstress 64040a0733074994976118bbe0acc7fb.md'}

