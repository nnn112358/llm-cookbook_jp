# 第5章 推論

この章では、ストーリーを通じて、製品評価やニュース記事から感情やトピックを推論する方法について説明します。

まず想像してみてください。あなたはスタートアップのデータアナリストで、様々な製品レビューやニュース記事から重要な感情やトピックを抽出する任務があります。これらのタスクには、ラベル抽出、エンティティ抽出、テキストの感情理解などが含まれます。従来の機械学習フローでは、ラベル付きデータセットを収集し、モデルを訓練し、クラウドでモデルをデプロイして推論を実行する方法を決める必要があります。この方式は良い効果を生むかもしれませんが、全プロセスを完了するには大量の時間と労力が必要です。さらに、感情分析、エンティティ抽出などの各タスクごとに、個別のモデルを訓練・デプロイする必要があります。

しかし、重労働に投入する準備をしていた時、あなたは大規模言語モデル（LLM）を発見しました。LLMの明らかな利点は、このような多くのタスクに対して、Promptを書くだけで結果の生成を開始でき、作業負担を大幅に軽減することです。この発見は魔法の鍵を見つけたようで、アプリケーション開発の速度を大幅に向上させました。最も興奮することは、一つのモデルと一つのAPIを使用するだけで多くの異なるタスクを実行でき、多くの異なるモデルを訓練・デプロイする方法に悩む必要がないことです。

この章の学習を始めて、LLMを利用して作業プロセスを加速し、作業効率を向上させる方法を一緒に探求しましょう。

## 一、感情推論

### 1.1 感情傾向分析

ECプラットフォームの台灯レビューを例に、このレビューの感情二分類（ポジティブ/ネガティブ）を行う方法を学習します。


```python
lamp_review = """
私は美しい寝室用ライトが必要で、このライトには追加の収納機能があり、価格もそれほど高くありませんでした。\
すぐに受け取りました。配送過程で、私たちのライトのコードが断線しましたが、会社は喜んで新しいものを送ってくれました。\
数日後に受け取りました。このライトは組み立てが簡単です。部品が一つ足りないことがわかったので、彼らのカスタマーサービスに連絡したところ、すぐに不足部品を送ってくれました！\
私から見ると、Luminaは顧客と製品を非常に大切にする優秀な会社です！
"""
```

次に、この商品レビューの感情を分類するPromptを書いてみます。システムにこのレビューの感情傾向を解析させたい場合、「以下の商品レビューの感情傾向は何ですか？」のようなPromptを書き、標準的な区切り文字とレビューテキストなどを加えるだけです。

そして、このプログラムを一度実行してみます。結果は、この商品レビューの感情傾向はポジティブだと示しており、これは非常に正確なようです。この台灯は完璧ではありませんが、この顧客はかなり満足しているようです。この会社は顧客体験と製品品質を非常に重視しているようで、レビューの感情傾向をポジティブと判定するのは正しい判断のようです。


```python
from tool import get_completion

prompt = f"""
三つのバッククォートで区切られた以下の製品レビューの感情は何ですか？

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    感情はポジティブです。


より簡潔な答えを得て、後処理しやすくしたい場合は、上記のPromptに別の指示を追加できます：*一つの単語で答えてください：「ポジティブ」または「ネガティブ」*。これにより「ポジティブ」という単語のみが印刷され、出力がより統一され、後続処理に便利になります。


```python
prompt = f"""
三つのバッククォートで区切られた以下の製品レビューの感情は何ですか？

一つの単語で答えてください：「ポジティブ」または「ネガティブ」。

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    ポジティブ


### 1.2 感情タイプの識別

続いて、前の台灯レビューを使用しますが、今回は新しいPromptを試してみます。モデルにレビュー作者が表現した感情を識別させ、これらの感情を5項目以下のリストにまとめてもらいます。


```python
# 日本語
prompt = f"""
以下のレビューの作者が表現した感情を識別してください。5項目以下で答えをカンマ区切りの単語リストとして整形してください。

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    満足,感謝,賞賛,信頼,満足


大規模言語モデルは、テキストから特定のものを抽出することに非常に長けています。上記の例では、レビューが表現した感情が顧客が特定の製品をどう見ているかを理解するのに役立ちます。

### 1.3 怒りの識別

多くの企業にとって、顧客の怒りの感情を洞察することは極めて重要です。これは分類問題を提起します：以下のレビューの作者が怒りを表現しているでしょうか？もし誰かが本当に感情的になっている場合、追加の注意が必要かもしれません。なぜなら、怒っている顧客は皆、サービスを改善し、会社の評判を向上させる機会だからです。この時、カスタマーサポートやカスタマーサービスチームが介入し、顧客と接触して具体的状況を理解し、問題を解決すべきです。


```python
# 日本語
prompt = f"""
以下のレビューの作者が怒りを表現していますか？レビューは三つのバッククォートで区切られています。はいまたはいいえで答えてください。

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    いいえ


上記の例では、顧客は怒っていません。注意すべきは、通常の監督学習を使用する場合、すべてのこれらの分類器を構築するのに数分で済むはずがないということです。これらのようなPromptを変更してみることをお勧めします。おそらく顧客が喜びを表現しているか、または何か欠けている部分があるかを尋ね、このライトレビューに対してPromptが異なる推論を行えるかどうかを確認してください。

## 二、情報抽出

### 2.1 商品情報抽出  

情報抽出は自然言語処理（NLP）の重要な構成部分で、テキストから特定の、私たちが関心を持つ情報を抽出するのに役立ちます。顧客レビューの豊富な情報を深く掘り下げます。次の例では、モデルに2つの重要な要素を識別するよう要求します：購入した商品と商品の製造者。

オンラインECウェブサイトの多くのレビューを分析しようとしていると想像してください。レビューで言及されている商品が何か、誰が製造したか、および関連するポジティブまたはネガティブな感情を理解することで、特定の商品や製造者のユーザー心理の感情傾向を追跡するのに大いに役立ちます。

次の例では、モデルに回答をJSONオブジェクトの形式で提示するよう要求し、そのkeyは商品とブランドです。


```python
# 日本語
prompt = f"""
レビューテキストから以下の項目を識別してください：
- レビュー者が購入した商品
- その商品を製造した会社

レビューテキストは三つのバッククォートで区切られています。回答を「商品」と「ブランド」をキーとするJSONオブジェクトとして整形してください。
情報が存在しない場合は、値として「不明」を使用してください。
回答はできるだけ簡潔にしてください。

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    {
      "商品": "寝室用ライト",
      "ブランド": "Lumina"
    }


上記のように、商品は寝室用ライト、ブランドはLuminaと表示され、これを簡単にPython辞書に読み込んで、この出力に対して他の処理を行うことができます。

### 2.2 感情推論と情報抽出の統合

上記の小節では、「感情傾向」、「怒っているかどうか」、「商品タイプ」、「ブランド」などの情報を抽出するために3〜4つのPromptを使用しました。しかし、実際には、これらすべての情報を同時に抽出する単一のPromptを設計することができます。


```python
# 日本語
prompt = f"""
レビューテキストから以下の項目を識別してください：
- 感情（ポジティブまたはネガティブ）
- レビュー者が怒りを表現しているか？（はいまたはいいえ）
- レビュー者が購入した商品
- その商品を製造した会社

レビューは三つのバッククォートで区切られています。回答を「感情傾向」、「怒っているか」、「商品タイプ」、「ブランド」をキーとするJSONオブジェクトとして整形してください。
情報が存在しない場合は、値として「不明」を使用してください。
回答はできるだけ簡潔にしてください。
「怒っているか」の値をブール値として整形してください。

レビューテキスト: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    {
      "感情傾向": "ポジティブ",
      "怒っているか": false,
      "商品タイプ": "寝室用ライト",
      "ブランド": "Lumina"
    }


この例では、LLMに「怒っているか」の状況をブール値として整形するよう指示し、JSON形式で出力しました。フォーマットモードに対して様々な変化を試したり、まったく異なるレビューを使用して、LLMがこれらの内容を正確に抽出できるかどうかを実験することができます。

## 三、トピック推論

大規模言語モデルのもう一つのクールな応用はトピック推論です。長いテキストがある場合、このテキストの要旨は何か？どのようなトピックが含まれているかをどう判断するでしょうか？以下の架空の新聞記事を通じて具体的に理解してみましょう。


```python
# 日本語
story = """
政府が最近実施した調査で、公共部門の従業員に所属部門への満足度を評価するよう求めました。
調査結果により、NASAが満足度95％で最も人気のある部門であることが明らかになりました。

NASA職員のJohn Smithはこの発見についてコメントし、次のように述べました：
「NASAが1位になったことに驚きはありません。ここは素晴らしい人々と信じられない機会と一緒に働ける素晴らしい場所です。私はこのような革新的な組織の一員であることを誇りに思います。」

NASAの管理チームもこの結果を歓迎し、管理者のTom Johnsonは次のように述べました：
「我々の従業員がNASAでの仕事に満足していることを聞いて非常に嬉しく思います。
我々には才能豊かで忠実な献身的なチームがあり、彼らは目標達成のために絶え間なく努力しており、彼らの努力が報われているのを見るのは素晴らしいことです。」

調査ではまた、社会保障庁の満足度が最も低く、従業員の45％のみが仕事に満足していると表明したことも明らかになりました。
政府は調査で従業員が提起した問題に対処し、すべての部門の仕事満足度を向上させるよう努力することを約束しました。
"""
```

### 3.1 議論トピックの推論

以上は政府職員が所属する職場に対する感想についての架空の新聞記事です。大規模言語モデルにその中で議論されている5つのトピックを確定させ、各トピックを1〜2語で概括してもらうことができます。出力結果はカンマ区切りのPythonリスト形式で提示されます。


```python
# 日本語
prompt = f"""
以下の与えられたテキストで議論されている5つのトピックを確定してください。

各トピックを1〜2語で概括してください。

解析可能なPythonリストとして出力し、各要素は一つのトピックを示す文字列にしてください。

与えられたテキスト: ```{story}```
"""
response = get_completion(prompt)
print(response)
```

    ['NASA', '満足度', 'コメント', '管理チーム', '社会保障庁']


### 3.2 特定トピックのニュースアラート作成

ニュースウェブサイトや類似のプラットフォームがあり、これらが私たちの関心のあるトピックだと仮定しましょう：アメリカ航空宇宙局、地方政府、エンジニアリング、従業員満足度、連邦政府など。ニュース記事を分析し、どのトピックが含まれているかを理解したいと思います。このようなPromptを使用できます：以下のトピックリストの各項目が以下のテキストのトピックであるかどうかを確定し、0または1の形式で答えのリストを提供してください。


```python
# 日本語
prompt = f"""
トピックリストの各項目が与えられたテキストのトピックであるかどうかを判断し、

リスト形式で答えを提供し、各要素は対応するトピックをキー、対応する0または1を値とするJsonオブジェクトにしてください。

トピックリスト：アメリカ航空宇宙局、地方政府、エンジニアリング、従業員満足度、連邦政府

与えられたテキスト: ```{story}```
"""
response = get_completion(prompt)
print(response)
```

    [
      {"アメリカ航空宇宙局": 1},
      {"地方政府": 1},
      {"エンジニアリング": 0},
      {"従業員満足度": 1},
      {"連邦政府": 1}
    ]


出力結果から、この`story`は「アメリカ航空宇宙局」、「従業員満足度」、「連邦政府」、「地方政府」に関連しており、「エンジニアリング」とは関係がないことがわかります。この能力は機械学習分野でゼロショット（Zero-Shot）学習と呼ばれています。これは、ラベル付きの訓練データを提供していないにもかかわらず、Promptだけでどのトピックがニュース記事に含まれているかを判定できるからです。

ニュースアラートを制定したい場合も、同様にニュースを処理するフローを運用できます。「アメリカ航空宇宙局」の仕事に深く関心があると仮定すれば、このようなシステムを構築できます：'アメリカ宇宙局'に関連するニュースが出現するたびに、システムがアラートを出力します。


```python
result_lst = eval(response)
topic_dict = {list(i.keys())[0] : list(i.values())[0] for i in result_lst}
print(topic_dict)
if topic_dict['アメリカ航空宇宙局'] == 1:
    print("アラート: アメリカ航空宇宙局に関する新しいニュース")
```

    {'アメリカ航空宇宙局': 1, '地方政府': 1, 'エンジニアリング': 0, '従業員満足度': 1, '連邦政府': 1}
    アラート: アメリカ航空宇宙局に関する新しいニュース


これが推論に関する包括的な紹介です。短時間で、テキスト推論のための複数のシステムを構築することができました。これは以前、機械学習専門家が数日から数週間かけて完成させていたタスクです。この変化は間違いなく興奮を呼び起こします。経験豊富な機械学習開発者であっても、入門したばかりの新人であっても、Promptを入力することで複雑な自然言語処理タスクを迅速に開始できるからです。

## 英語版

**1.1 感情傾向分析**


```python
lamp_review = """
Needed a nice lamp for my bedroom, and this one had \
additional storage and not too high of a price point. \
Got it fast.  The string to our lamp broke during the \
transit and the company happily sent over a new one. \
Came within a few days as well. It was easy to put \
together.  I had a missing part, so I contacted their \
support and they very quickly got me the missing piece! \
Lumina seems to me to be a great company that cares \
about their customers and products!!
"""
```


```python
prompt = f"""
What is the sentiment of the following product review, 
which is delimited with triple backticks?

Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    The sentiment of the product review is positive.



```python
prompt = f"""
What is the sentiment of the following product review, 
which is delimited with triple backticks?

Give your answer as a single word, either "positive" \
or "negative".

Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    positive


**1.2感情タイプの識別**


```python
prompt = f"""
Identify a list of emotions that the writer of the \
following review is expressing. Include no more than \
five items in the list. Format your answer as a list of \
lower-case words separated by commas.

Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    satisfied, pleased, grateful, impressed, happy


**1.3 怒りの識別**


```python
prompt = f"""
Is the writer of the following review expressing anger?\
The review is delimited with triple backticks. \
Give your answer as either yes or no.

Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    No


**2.1 商品情報抽出**


```python
prompt = f"""
Identify the following items from the review text: 
- Item purchased by reviewer
- Company that made the item

The review is delimited with triple backticks. \
Format your response as a JSON object with \
"Item" and "Brand" as the keys. 
If the information isn't present, use "unknown" \
as the value.
Make your response as short as possible.
  
Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    {
      "Item": "lamp",
      "Brand": "Lumina"
    }


**2.2 感情推論と情報抽出の統合**


```python
prompt = f"""
Identify the following items from the review text: 
- Sentiment (positive or negative)
- Is the reviewer expressing anger? (true or false)
- Item purchased by reviewer
- Company that made the item

The review is delimited with triple backticks. \
Format your response as a JSON object with \
"Sentiment", "Anger", "Item" and "Brand" as the keys.
If the information isn't present, use "unknown" \
as the value.
Make your response as short as possible.
Format the Anger value as a boolean.

Review text: ```{lamp_review}```
"""
response = get_completion(prompt)
print(response)
```

    {
      "Sentiment": "positive",
      "Anger": false,
      "Item": "lamp",
      "Brand": "Lumina"
    }


**3.1 議論トピックの推論**


```python
story = """
In a recent survey conducted by the government, 
public sector employees were asked to rate their level 
of satisfaction with the department they work at. 
The results revealed that NASA was the most popular 
department with a satisfaction rating of 95%.

One NASA employee, John Smith, commented on the findings, 
stating, "I'm not surprised that NASA came out on top. 
It's a great place to work with amazing people and 
incredible opportunities. I'm proud to be a part of 
such an innovative organization."

The results were also welcomed by NASA's management team, 
with Director Tom Johnson stating, "We are thrilled to 
hear that our employees are satisfied with their work at NASA. 
We have a talented and dedicated team who work tirelessly 
to achieve our goals, and it's fantastic to see that their 
hard work is paying off."

The survey also revealed that the 
Social Security Administration had the lowest satisfaction 
rating, with only 45% of employees indicating they were 
satisfied with their job. The government has pledged to 
address the concerns raised by employees in the survey and 
work towards improving job satisfaction across all departments.
"""
```


```python
prompt = f"""
Determine five topics that are being discussed in the \
following text, which is delimited by triple backticks.

Make each item one or two words long. 

Format your response as a list of items separated by commas.
Give me a list which can be read in Python.

Text sample: ```{story}```
"""
response = get_completion(prompt)
print(response)
```

    survey, satisfaction rating, NASA, Social Security Administration, job satisfaction



```python
response.split(sep=',')
```




    ['survey',
     ' satisfaction rating',
     ' NASA',
     ' Social Security Administration',
     ' job satisfaction']



**3.2 特定トピックのニュースアラート作成**


```python
topic_list = [
    "nasa", "local government", "engineering", 
    "employee satisfaction", "federal government"
]
```


```python
prompt = f"""
Determine whether each item in the following list of \
topics is a topic in the text below, which
is delimited with triple backticks.

Give your answer as list with 0 or 1 for each topic.\

List of topics: {", ".join(topic_list)}

Text sample: ```{story}```
"""
response = get_completion(prompt)
print(response)
```

    [1, 0, 0, 1, 1]



```python
topic_dict = {topic_list[i] : eval(response)[i] for i in range(len(eval(response)))}
print(topic_dict)
if topic_dict['nasa'] == 1:
    print("ALERT: New NASA story!")
```

    {'nasa': 1, 'local government': 0, 'engineering': 0, 'employee satisfaction': 1, 'federal government': 1}
    ALERT: New NASA story!