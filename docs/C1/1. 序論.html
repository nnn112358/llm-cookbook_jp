<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>1. 序論</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown-min.css" />
</head>
<body>
<h1 id="第一章-はじめに">第一章 はじめに</h1>
<p><strong>開発者向けプロンプトエンジニアリング</strong>部分へようこそ。この部分の内容は<strong>Andrew
Ng先生の《Prompt Engineering for
Developer》講座</strong>に基づいて編集されています。《Prompt Engineering
for Developer》講座は<strong>Andrew
Ng先生</strong>とOpenAI技術チームメンバー<strong>Isa
Fulford</strong>先生が共同で担当しており、Isa先生は人気のChatGPT検索プラグインを開発し、LLM（Large
Language
Model、大規模言語モデル）技術の製品応用の指導において大きな貢献をしています。彼女はまた、人々にPromptの使用方法を教えるOpenAI
cookbookの編集にも参加しています。本モジュールの学習を通じて、プロンプトを使用したLLMアプリケーション開発のベストプラクティスと技術を皆さんと共有したいと思います。</p>
<p>ネット上にはプロンプト（Prompt、本チュートリアルではこの用語を保持します）設計に関する多くの資料があります。例えば《30
prompts everyone has to
know》のような記事で、これらの記事は主に<strong>ChatGPTのWebインターフェース</strong>に焦点を当てており、多くの人が特定の、通常は一回限りのタスクを実行するために使用しています。しかし、我々は開発者にとって、<strong>大規模言語モデル（LLM）のより強力な機能はAPIインターフェースを通じて呼び出すことで、迅速にソフトウェアアプリケーションを構築できること</strong>だと考えています。実際、DeepLearning.AIの姉妹会社AI
Fundのチームは多くのスタートアップ企業と協力し、これらの技術を多数のアプリケーションに応用していることが分かっています。LLM
APIが開発者に非常に迅速なアプリケーション構築を可能にすることを見て、とても興奮しています。</p>
<p>本モジュールでは、読者と大規模言語モデルアプリケーション効果を向上させる様々な技術とベストプラクティスを共有します。書籍の内容は幅広く、ソフトウェア開発プロンプト設計、テキスト要約、推論、変換、拡張、チャットボット構築など言語モデルの典型的な応用シーンを含みます。この講座が読者の想像力を刺激し、より優秀な言語モデルアプリケーションを開発することを心から願っています。</p>
<p>LLMの発展に伴い、大まかに2つのタイプに分けることができ、以下<strong>基礎LLM</strong>と<strong>指示微調整（Instruction
Tuned）LLM</strong>と呼びます。<strong>基礎LLM</strong>はテキスト訓練データに基づいて、次の単語を予測する能力を訓練したモデルです。通常、インターネットやその他の情報源の大量のデータで訓練を行い、次に現れる最も可能性の高い単語を確定します。例えば、「昔々、一匹のユニコーンが」をPromptとすると、基礎LLMは「彼女はユニコーンの友達と共に魔法の森で生活していました」と続けて予測するかもしれません。しかし、「フランスの首都は何ですか」をPromptとすると、基礎LLMはインターネット上の記事に基づいて、「フランス最大の都市は何ですか？フランスの人口はどのくらいですか？」と回答を予測するかもしれません。なぜなら、インターネット上の記事はフランス国家に関する質問回答リストである可能性が高いからです。</p>
<p>基礎言語モデルとは異なり、<strong>指示微調整LLM</strong>は専門的な訓練を通じて、指示をより良く理解し従うことができます。例えば、「フランスの首都は何ですか？」と質問した時、このタイプのモデルは「フランスの首都はパリです」と直接回答する可能性が高いです。指示微調整LLMの訓練は通常、事前訓練言語モデルに基づいて行われ、まず大規模テキストデータで<strong>事前訓練</strong>を行い、言語の基本法則を習得します。この基礎の上でさらなる訓練と<strong>微調整（finetune）</strong>を行い、入力は指示、出力はこれらの指示に対する正しい回答となります。時には<strong>RLHF（reinforcement
learning from human
feedback、人間フィードバック強化学習）</strong>技術も採用され、人間のモデル出力に対するフィードバックに基づいてモデルの指示遵従能力をさらに強化します。この制御された訓練過程を通じて、指示微調整LLMは指示に高度に敏感で、より安全で信頼性の高い出力を生成でき、無関係で有害なコンテンツを削減します。そのため、多くの実際の応用がこのタイプの大規模言語モデルの使用に転向しています。</p>
<p>したがって、本講座は指示微調整LLMに対するベストプラクティスを重点的に紹介し、ほとんどの使用シーンでこれを使用することを推奨します。指示微調整LLMを使用する際は、別の人に指示を提供すること（彼が非常に賢いが、あなたのタスクの具体的な詳細を知らないと仮定）に類比できます。そのため、LLMが正常に動作しない時、時には指示が十分明確でないことが原因です。例えば、「アラン・チューリング（Alan
Turing）について何かを書いてください」と質問したい場合、この基礎の上で、あなたがテキストを彼の科学的研究、個人生活、歴史的役割、またはその他の側面に焦点を当てることを明確に表明すると、より有用かもしれません。また、あなたのニーズをより満たすために回答のトーンを指定することもでき、選択肢には<em>専門記者の文体</em>や<em>友人に向けた随筆</em>などが含まれます。</p>
<p>LLMを新卒の大学生と見なして、彼にこのタスクを完成させる場合、アラン・チューリングについてのテキストを書くために彼らが読むべきテキスト片段を事前に指定することもでき、これにより新卒の大学生がこの任務をより良く完成させることができます。本書の次の章では、プロンプト設計の2つの重要な原則：<strong>明確性</strong>と<strong>十分な思考時間の提供</strong>について詳しく説明します。</p>
</body>
</html>
