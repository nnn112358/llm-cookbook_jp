<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>7. エージェント</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown-min.css" />
</head>
<body>
<h1 id="第七章-エージェント">第七章 エージェント</h1>
<p>大型语言模型（LLMs）非常强大，但它们缺乏“最笨”的计算机程序可以轻松处理的特定能力。LLM
对逻辑推理、计算和检索外部信息的能力较弱，这与最简单的计算机程序形成对比。例如，语言模型无法准确回答简单的计算问题，还有当询问最近发生的事件时，其回答也可能过时或错误，因为无法主动获取最新信息。这是由于当前语言模型仅依赖预训练数据，与外界“断开”。要克服这一缺陷，<code>LangChain</code>框架提出了<code>“代理”(Agent)</code>的解决方案。</p>
<p><strong>代理作为语言模型的外部模块，可提供计算、逻辑、检索等功能的支持，使语言模型获得异常强大的推理和获取信息的超能力</strong>。</p>
<p>在本章中，我们将详细介绍代理的工作机制、种类、以及如何在<code>LangChain</code>中将其与语言模型配合，构建功能更全面、智能程度更高的应用程序。代理机制极大扩展了语言模型的边界，是当前提升其智能的重要途径之一。让我们开始学习如何通过代理释放语言模型的最大潜力。</p>
<h2
id="一使用langchain内置工具llm-math和wikipedia">一、使用LangChain内置工具llm-math和wikipedia</h2>
<p>要使用代理 (Agents) ，我们需要三样东西：</p>
<ul>
<li>一个基本的 LLM</li>
<li>我们将要进行交互的工具 Tools</li>
<li>一个控制交互的代理 (Agents) 。</li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> load_tools, initialize_agent</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> AgentType</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.python <span class="im">import</span> PythonREPL</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span></code></pre></div>
<p>首先，让我们新建一个基本的 LLM</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 参数temperature设置为0.0，从而减少生成答案的随机性。</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<p>接下来，初始化<code>工具 Tool</code> ，我们可以创建自定义工具 Tool
或加载预构建工具 Tool。无论哪种情况，工具 Tool 都是一个给定工具
<code>名称 name</code> 和 <code>描述 description</code> 的 实用链。</p>
<ul>
<li><code>llm-math</code> 工具结合语言模型和计算器用以进行数学计算</li>
<li><code>wikipedia</code>工具通过API连接到wikipedia进行搜索查询。</li>
</ul>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>tools <span class="op">=</span> load_tools(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&quot;llm-math&quot;</span>,<span class="st">&quot;wikipedia&quot;</span>], </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    llm<span class="op">=</span>llm <span class="co">#第一步初始化的模型</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>现在我们有了 LLM 和工具，最后让我们初始化一个简单的代理 (Agents)
：</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 初始化代理</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>agent<span class="op">=</span> initialize_agent(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    tools, <span class="co">#第二步加载的工具</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    llm, <span class="co">#第一步初始化的模型</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    agent<span class="op">=</span>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  <span class="co">#代理类型</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    handle_parsing_errors<span class="op">=</span><span class="va">True</span>, <span class="co">#处理解析错误</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">True</span> <span class="co">#输出中间步骤</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<ul>
<li><code>agent</code>:
代理类型。这里使用的是<code>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION</code>。其中<code>CHAT</code>代表代理模型为针对对话优化的模型；<code>Zero-shot</code>
意味着代理 (Agents)
仅在当前操作上起作用，即它没有记忆；<code>REACT</code>代表针对REACT设计的提示模版。<code>DESCRIPTION</code>根据工具的描述
description 来决定使用哪个工具。(我们不会在本章中讨论 * REACT 框架
，但您可以将其视为 LLM 可以循环进行 Reasoning 和 Action
步骤的过程。它启用了一个多步骤的过程来识别答案。)</li>
<li><code>handle_parsing_errors</code>:
是否处理解析错误。当发生解析错误时，将错误信息返回给大模型，让其进行纠正。</li>
<li><code>verbose</code>: 是否输出中间步骤结果。</li>
</ul>
<p>使用代理回答数学问题</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>agent(<span class="st">&quot;计算300的25%&quot;</span>) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
Question: 计算300的25%
Thought: I can use the calculator tool to calculate 25% of 300.
Action:
```json
{
  &quot;action&quot;: &quot;Calculator&quot;,
  &quot;action_input&quot;: &quot;300 * 0.25&quot;
}
```

Observation: Answer: 75.0
Thought:The calculator tool returned the answer 75.0, which is 25% of 300.
Final Answer: 25% of 300 is 75.0.

&gt; Finished chain.





{&#39;input&#39;: &#39;计算300的25%&#39;, &#39;output&#39;: &#39;25% of 300 is 75.0.&#39;}</code></pre>
<p><strong>上面的过程可以总结为下</strong></p>
<ol type="1">
<li><p>模型对于接下来需要做什么，给出思考</p>
<p style="font-family:verdana; font-size:12px;color:green">
<p><strong>思考</strong>：我可以使用计算工具来计算300的25%</p>
</p></li>
<li><p>模型基于思考采取行动</p>
<p style="font-family:verdana; font-size:12px;color:green">
<p><strong>行动</strong>:
使用计算器（calculator），输入（action_input）300*0.25</p>
</p></li>
<li><p>模型得到观察</p>
<p style="font-family:verdana; font-size:12px;color:green">
<p><strong>观察</strong>：答案: 75.0</p>
</p></li>
<li><p>基于观察，模型对于接下来需要做什么，给出思考</p>
<p style="font-family:verdana; font-size:12px;color:green">
<p><strong>思考</strong>: 计算工具返回了300的25%，答案为75</p>
</p></li>
<li><p>给出最终答案（Final Answer）</p>
<p style="font-family:verdana; font-size:12px;color:green">
<p><strong>最终答案</strong>: 300的25%等于75。</p>
</p></li>
<li><p>以字典的形式给出最终答案。</p></li>
</ol>
<p>Tom M. Mitchell的书</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;Tom M. Mitchell是一位美国计算机科学家，</span><span class="ch">\</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="st">也是卡内基梅隆大学（CMU）的创始人大学教授。</span><span class="ch">\</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="st">他写了哪本书呢？&quot;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>agent(question) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
Thought: I can use Wikipedia to find information about Tom M. Mitchell and his books.
Action:
```json
{
  &quot;action&quot;: &quot;Wikipedia&quot;,
  &quot;action_input&quot;: &quot;Tom M. Mitchell&quot;
}
```
Observation: Page: Tom M. Mitchell
Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.

Page: Tom Mitchell (Australian footballer)
Summary: Thomas Mitchell (born 31 May 1993) is a professional Australian rules footballer playing for the Collingwood Football Club in the Australian Football League (AFL). He previously played for the Adelaide Crows, Sydney Swans from 2012 to 2016, and the Hawthorn Football Club between 2017 and 2022. Mitchell won the Brownlow Medal as the league&#39;s best and fairest player in 2018 and set the record for the most disposals in a VFL/AFL match, accruing 54 in a game against Collingwood during that season.
Thought:The book written by Tom M. Mitchell is &quot;Machine Learning&quot;.
Thought: I have found the answer.
Final Answer: The book written by Tom M. Mitchell is &quot;Machine Learning&quot;.

&gt; Finished chain.





{&#39;input&#39;: &#39;Tom M. Mitchell是一位美国计算机科学家，也是卡内基梅隆大学（CMU）的创始人大学教授。他写了哪本书呢？&#39;,
 &#39;output&#39;: &#39;The book written by Tom M. Mitchell is &quot;Machine Learning&quot;.&#39;}</code></pre>
<p>✅ <strong>总结</strong></p>
<ol type="1">
<li>模型对于接下来需要做什么，给出思考（Thought）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>思考</strong>：我应该使用维基百科去搜索。
</p></li>
<li>模型基于思考采取行动（Action）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>行动</strong>: 使用维基百科，输入Tom M. Mitchell
</p></li>
<li>模型得到观察（Observation）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>观测</strong>: 页面: Tom M. Mitchell，页面: Tom Mitchell
(澳大利亚足球运动员)
</p></li>
<li>基于观察，模型对于接下来需要做什么，给出思考（Thought）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>思考</strong>: Tom M. Mitchell写的书是Machine Learning
</p></li>
<li>给出最终答案（Final Answer）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>最终答案</strong>: Machine Learning
</p></li>
<li>以字典的形式给出最终答案。</li>
</ol>
<p>值得注意的是，模型每次运行推理的过程可能存在差异，但最终的结果一致。</p>
<h2 id="二-使用langchain内置工具pythonrepltool">二、
使用LangChain内置工具PythonREPLTool</h2>
<p>我们创建一个能将顾客名字转换为拼音的 python
代理，步骤与上一部分的一样：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents.agent_toolkits <span class="im">import</span> create_python_agent</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.tools.python.tool <span class="im">import</span> PythonREPLTool</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> create_python_agent(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    llm,  <span class="co">#使用前面一节已经加载的大语言模型</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    tool<span class="op">=</span>PythonREPLTool(), <span class="co">#使用Python交互式环境工具 REPLTool</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span> <span class="co">#输出中间步骤</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>customer_list <span class="op">=</span> [<span class="st">&quot;小明&quot;</span>,<span class="st">&quot;小黄&quot;</span>,<span class="st">&quot;小红&quot;</span>,<span class="st">&quot;小蓝&quot;</span>,<span class="st">&quot;小橘&quot;</span>,<span class="st">&quot;小绿&quot;</span>,]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>agent.run(<span class="ss">f&quot;将使用pinyin拼音库这些客户名字转换为拼音，并打印输出列表: </span><span class="sc">{</span>customer_list<span class="sc">}</span><span class="ss">。&quot;</span>) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...


Python REPL can execute arbitrary code. Use with caution.


I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.
Action: Python_REPL
Action Input: import pinyin
Observation: 
Thought:I have imported the pinyin library. Now I can use it to convert the names to pinyin.
Action: Python_REPL
Action Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]
pinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]
print(pinyin_names)
Observation: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]

Thought:I have successfully converted the names to pinyin and printed out the list of converted names.
Final Answer: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]

&gt; Finished chain.





&quot;[&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;</code></pre>
在调试（debug）模式下再次运行，我们可以把上面的6步分别对应到下面的具体流程
1. 模型对于接下来需要做什么，给出思考（Thought） -
<p style="font-family:verdana; font-size:12px;color:green">
[chain/start] [1:chain:AgentExecutor] Entering Chain run with input
</p>
<pre><code>- &lt;p style=&quot;font-family:verdana; font-size:12px;color:green&quot;&gt; [chain/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] Entering Chain run with input&lt;/p&gt;
- &lt;p style=&quot;font-family:verdana; font-size:12px;color:green&quot;&gt; [llm/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] Entering LLM run with input&lt;/p&gt;
- &lt;p style=&quot;font-family:verdana; font-size:12px;color:green&quot;&gt; [llm/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] [1.91s] Exiting LLM run with output&lt;/p&gt;
- &lt;p style=&quot;font-family:verdana; font-size:12px;color:green&quot;&gt;[chain/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] [1.91s] Exiting Chain run with output&lt;/p&gt;</code></pre>
<ol start="2" type="1">
<li>模型基于思考采取行动（Action),
因为使用的工具不同，Action的输出也和之前有所不同，这里输出的为python代码
<code>import pinyin</code>
<ul>
<li><p style="font-family:verdana; font-size:12px;color:green">
[tool/start] [1:chain:AgentExecutor &gt; 4:tool:Python REPL] Entering
Tool run with input
</p></li>
<li><p style="font-family:verdana; font-size:12px;color:green">
[tool/end] [1:chain:AgentExecutor &gt; 4:tool:Python_REPL] [1.28ms]
Exiting Tool run with output
</p></li>
</ul></li>
<li>模型得到观察（Observation）
<ul>
<li><p style="font-family:verdana; font-size:12px;color:green">
[chain/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] Entering
Chain run with input
</p></li>
</ul></li>
<li>基于观察，模型对于接下来需要做什么，给出思考（Thought）
<ul>
<li><p style="font-family:verdana; font-size:12px;color:green">
[llm/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt;
6:llm:ChatOpenAI] Entering LLM run with input
</p></li>
<li><p style="font-family:verdana; font-size:12px;color:green">
[llm/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt;
6:llm:ChatOpenAI] [3.48s] Exiting LLM run with output
</p></li>
</ul></li>
<li>给出最终答案（Final Answer）
<ul>
<li><p style="font-family:verdana; font-size:12px;color:green">
[chain/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] [3.48s]
Exiting Chain run with output
</p></li>
</ul></li>
<li>返回最终答案。
<ul>
<li><p style="font-family:verdana; font-size:12px;color:green">
[chain/end] [1:chain:AgentExecutor] [19.20s] Exiting Chain run with
output
</p></li>
</ul></li>
</ol>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> langchain</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>langchain.debug<span class="op">=</span><span class="va">True</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>agent.run(<span class="ss">f&quot;使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: </span><span class="sc">{</span>customer_list<span class="sc">}</span><span class="ss">&quot;</span>) </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>langchain.debug<span class="op">=</span><span class="va">False</span></span></code></pre></div>
<pre><code>[chain/start] [1:chain:AgentExecutor] Entering Chain run with input:
{
  &quot;input&quot;: &quot;使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]&quot;
}
[chain/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] Entering Chain run with input:
{
  &quot;input&quot;: &quot;使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]&quot;,
  &quot;agent_scratchpad&quot;: &quot;&quot;,
  &quot;stop&quot;: [
    &quot;\nObservation:&quot;,
    &quot;\n\tObservation:&quot;
  ]
}
[llm/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] Entering LLM run with input:
{
  &quot;prompts&quot;: [
    &quot;Human: You are an agent designed to write and execute python code to answer questions.\nYou have access to a python REPL, which you can use to execute python code.\nIf you get an error, debug your code and try again.\nOnly use the output of your code to answer the question. \nYou might know the answer without running any code, but you should still run the code to get the answer.\nIf it does not seem like you can write code to answer the question, just return \&quot;I don&#39;t know\&quot; as the answer.\n\n\nPython_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Python_REPL]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\nThought:&quot;
  ]
}
[llm/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] [2.32s] Exiting LLM run with output:
{
  &quot;generations&quot;: [
    [
      {
        &quot;text&quot;: &quot;I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin&quot;,
        &quot;generation_info&quot;: {
          &quot;finish_reason&quot;: &quot;stop&quot;
        },
        &quot;message&quot;: {
          &quot;lc&quot;: 1,
          &quot;type&quot;: &quot;constructor&quot;,
          &quot;id&quot;: [
            &quot;langchain&quot;,
            &quot;schema&quot;,
            &quot;messages&quot;,
            &quot;AIMessage&quot;
          ],
          &quot;kwargs&quot;: {
            &quot;content&quot;: &quot;I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin&quot;,
            &quot;additional_kwargs&quot;: {}
          }
        }
      }
    ]
  ],
  &quot;llm_output&quot;: {
    &quot;token_usage&quot;: {
      &quot;prompt_tokens&quot;: 320,
      &quot;completion_tokens&quot;: 39,
      &quot;total_tokens&quot;: 359
    },
    &quot;model_name&quot;: &quot;gpt-3.5-turbo&quot;
  },
  &quot;run&quot;: null
}
[chain/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] [2.33s] Exiting Chain run with output:
{
  &quot;text&quot;: &quot;I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin&quot;
}
[tool/start] [1:chain:AgentExecutor &gt; 4:tool:Python_REPL] Entering Tool run with input:
&quot;import pinyin&quot;
[tool/end] [1:chain:AgentExecutor &gt; 4:tool:Python_REPL] [1.5659999999999998ms] Exiting Tool run with output:
&quot;&quot;
[chain/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] Entering Chain run with input:
{
  &quot;input&quot;: &quot;使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]&quot;,
  &quot;agent_scratchpad&quot;: &quot;I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin\nObservation: \nThought:&quot;,
  &quot;stop&quot;: [
    &quot;\nObservation:&quot;,
    &quot;\n\tObservation:&quot;
  ]
}
[llm/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt; 6:llm:ChatOpenAI] Entering LLM run with input:
{
  &quot;prompts&quot;: [
    &quot;Human: You are an agent designed to write and execute python code to answer questions.\nYou have access to a python REPL, which you can use to execute python code.\nIf you get an error, debug your code and try again.\nOnly use the output of your code to answer the question. \nYou might know the answer without running any code, but you should still run the code to get the answer.\nIf it does not seem like you can write code to answer the question, just return \&quot;I don&#39;t know\&quot; as the answer.\n\n\nPython_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Python_REPL]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\nThought:I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin\nObservation: \nThought:&quot;
  ]
}
[llm/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt; 6:llm:ChatOpenAI] [4.09s] Exiting LLM run with output:
{
  &quot;generations&quot;: [
    [
      {
        &quot;text&quot;: &quot;I have imported the pinyin library. Now I can use it to convert the names to pinyin.\nAction: Python_REPL\nAction Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\npinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]\nprint(pinyin_names)&quot;,
        &quot;generation_info&quot;: {
          &quot;finish_reason&quot;: &quot;stop&quot;
        },
        &quot;message&quot;: {
          &quot;lc&quot;: 1,
          &quot;type&quot;: &quot;constructor&quot;,
          &quot;id&quot;: [
            &quot;langchain&quot;,
            &quot;schema&quot;,
            &quot;messages&quot;,
            &quot;AIMessage&quot;
          ],
          &quot;kwargs&quot;: {
            &quot;content&quot;: &quot;I have imported the pinyin library. Now I can use it to convert the names to pinyin.\nAction: Python_REPL\nAction Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\npinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]\nprint(pinyin_names)&quot;,
            &quot;additional_kwargs&quot;: {}
          }
        }
      }
    ]
  ],
  &quot;llm_output&quot;: {
    &quot;token_usage&quot;: {
      &quot;prompt_tokens&quot;: 365,
      &quot;completion_tokens&quot;: 87,
      &quot;total_tokens&quot;: 452
    },
    &quot;model_name&quot;: &quot;gpt-3.5-turbo&quot;
  },
  &quot;run&quot;: null
}
[chain/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] [4.09s] Exiting Chain run with output:
{
  &quot;text&quot;: &quot;I have imported the pinyin library. Now I can use it to convert the names to pinyin.\nAction: Python_REPL\nAction Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\npinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]\nprint(pinyin_names)&quot;
}
[tool/start] [1:chain:AgentExecutor &gt; 7:tool:Python_REPL] Entering Tool run with input:
&quot;names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]
pinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]
print(pinyin_names)&quot;
[tool/end] [1:chain:AgentExecutor &gt; 7:tool:Python_REPL] [0.8809999999999999ms] Exiting Tool run with output:
&quot;[&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;
[chain/start] [1:chain:AgentExecutor &gt; 8:chain:LLMChain] Entering Chain run with input:
{
  &quot;input&quot;: &quot;使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]&quot;,
  &quot;agent_scratchpad&quot;: &quot;I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin\nObservation: \nThought:I have imported the pinyin library. Now I can use it to convert the names to pinyin.\nAction: Python_REPL\nAction Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\npinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]\nprint(pinyin_names)\nObservation: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]\n\nThought:&quot;,
  &quot;stop&quot;: [
    &quot;\nObservation:&quot;,
    &quot;\n\tObservation:&quot;
  ]
}
[llm/start] [1:chain:AgentExecutor &gt; 8:chain:LLMChain &gt; 9:llm:ChatOpenAI] Entering LLM run with input:
{
  &quot;prompts&quot;: [
    &quot;Human: You are an agent designed to write and execute python code to answer questions.\nYou have access to a python REPL, which you can use to execute python code.\nIf you get an error, debug your code and try again.\nOnly use the output of your code to answer the question. \nYou might know the answer without running any code, but you should still run the code to get the answer.\nIf it does not seem like you can write code to answer the question, just return \&quot;I don&#39;t know\&quot; as the answer.\n\n\nPython_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Python_REPL]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 使用pinyin拼音库将这些客户名字转换为拼音，并打印输出列表: [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\nThought:I need to use the pinyin library to convert the names to pinyin. I can then print out the list of converted names.\nAction: Python_REPL\nAction Input: import pinyin\nObservation: \nThought:I have imported the pinyin library. Now I can use it to convert the names to pinyin.\nAction: Python_REPL\nAction Input: names = [&#39;小明&#39;, &#39;小黄&#39;, &#39;小红&#39;, &#39;小蓝&#39;, &#39;小橘&#39;, &#39;小绿&#39;]\npinyin_names = [pinyin.get(i, format=&#39;strip&#39;) for i in names]\nprint(pinyin_names)\nObservation: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]\n\nThought:&quot;
  ]
}
[llm/end] [1:chain:AgentExecutor &gt; 8:chain:LLMChain &gt; 9:llm:ChatOpenAI] [2.05s] Exiting LLM run with output:
{
  &quot;generations&quot;: [
    [
      {
        &quot;text&quot;: &quot;I have successfully converted the names to pinyin and printed out the list of converted names.\nFinal Answer: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;,
        &quot;generation_info&quot;: {
          &quot;finish_reason&quot;: &quot;stop&quot;
        },
        &quot;message&quot;: {
          &quot;lc&quot;: 1,
          &quot;type&quot;: &quot;constructor&quot;,
          &quot;id&quot;: [
            &quot;langchain&quot;,
            &quot;schema&quot;,
            &quot;messages&quot;,
            &quot;AIMessage&quot;
          ],
          &quot;kwargs&quot;: {
            &quot;content&quot;: &quot;I have successfully converted the names to pinyin and printed out the list of converted names.\nFinal Answer: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;,
            &quot;additional_kwargs&quot;: {}
          }
        }
      }
    ]
  ],
  &quot;llm_output&quot;: {
    &quot;token_usage&quot;: {
      &quot;prompt_tokens&quot;: 483,
      &quot;completion_tokens&quot;: 48,
      &quot;total_tokens&quot;: 531
    },
    &quot;model_name&quot;: &quot;gpt-3.5-turbo&quot;
  },
  &quot;run&quot;: null
}
[chain/end] [1:chain:AgentExecutor &gt; 8:chain:LLMChain] [2.05s] Exiting Chain run with output:
{
  &quot;text&quot;: &quot;I have successfully converted the names to pinyin and printed out the list of converted names.\nFinal Answer: [&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;
}
[chain/end] [1:chain:AgentExecutor] [8.47s] Exiting Chain run with output:
{
  &quot;output&quot;: &quot;[&#39;xiaoming&#39;, &#39;xiaohuang&#39;, &#39;xiaohong&#39;, &#39;xiaolan&#39;, &#39;xiaoju&#39;, &#39;xiaolv&#39;]&quot;
}</code></pre>
<h2 id="三-定义自己的工具并在代理中使用">三、
定义自己的工具并在代理中使用</h2>
<p>在本节，我们将<strong>创建和使用自定义时间工具</strong>。<strong>LangChian
tool 函数装饰器可以应用用于任何函数，将函数转化为LangChain
工具，使其成为代理可调用的工具</strong>。我们需要给函数加上非常详细的文档字符串,
使得代理知道在什么情况下、如何使用该函数/工具。比如下面的函数<code>time</code>,我们加上了详细的文档字符串。</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 导入tool函数装饰器</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> tool</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> date</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="at">@tool</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> time(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">    返回今天的日期，用于任何需要知道今天日期的问题。</span><span class="ch">\</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">    输入应该总是一个空字符串，</span><span class="ch">\</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">    这个函数将总是返回今天的日期，任何日期计算应该在这个函数之外进行。</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">str</span>(date.today())</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 初始化代理</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>agent<span class="op">=</span> initialize_agent(</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    tools<span class="op">=</span>[time], <span class="co">#将刚刚创建的时间工具加入代理</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    llm<span class="op">=</span>llm, <span class="co">#初始化的模型</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    agent<span class="op">=</span>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  <span class="co">#代理类型</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    handle_parsing_errors<span class="op">=</span><span class="va">True</span>, <span class="co">#处理解析错误</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">True</span> <span class="co">#输出中间步骤</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用代理询问今天的日期. </span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 注: 代理有时候可能会出错（该功能正在开发中）。如果出现错误，请尝试再次运行它。</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>agent(<span class="st">&quot;今天的日期是？&quot;</span>) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
根据提供的工具，我们可以使用`time`函数来获取今天的日期。

Thought: 使用`time`函数来获取今天的日期。

Action:
```
{
  &quot;action&quot;: &quot;time&quot;,
  &quot;action_input&quot;: &quot;&quot;
}
```


Observation: 2023-08-09
Thought:我现在知道了最终答案。
Final Answer: 今天的日期是2023-08-09。

&gt; Finished chain.





{&#39;input&#39;: &#39;今天的日期是？&#39;, &#39;output&#39;: &#39;今天的日期是2023-08-09。&#39;}</code></pre>
<p><strong>上面的过程可以总结为下</strong></p>
<ol type="1">
<li>模型对于接下来需要做什么，给出思考（Thought）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>思考</strong>：我需要使用 time 工具来获取今天的日期
</p></li>
<li>模型基于思考采取行动（Action),
因为使用的工具不同，Action的输出也和之前有所不同，这里输出的为python代码
<p style="font-family:verdana; font-size:12px;color:green">
<strong>行动</strong>: 使用time工具，输入为空字符串
</p></li>
<li>模型得到观察（Observation）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>观测</strong>: 2023-07-04
</p></li>
<li>基于观察，模型对于接下来需要做什么，给出思考（Thought）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>思考</strong>: 我已成功使用 time 工具检索到了今天的日期
</p></li>
<li>给出最终答案（Final Answer）
<p style="font-family:verdana; font-size:12px;color:green">
<strong>最终答案</strong>: 今天的日期是2023-08-09.
</p></li>
<li>返回最终答案。</li>
</ol>
<h2 id="四英文版">四、英文版</h2>
<p><strong>1. 使用LangChain内置工具llm-math和wikipedia</strong></p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> load_tools, initialize_agent</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> AgentType</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.python <span class="im">import</span> PythonREPL</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>tools <span class="op">=</span> load_tools(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&quot;llm-math&quot;</span>,<span class="st">&quot;wikipedia&quot;</span>], </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    llm<span class="op">=</span>llm </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>agent<span class="op">=</span> initialize_agent(</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    tools,  </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    llm,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    agent<span class="op">=</span>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    handle_parsing_errors<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">True</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>agent(<span class="st">&quot;What is the 25</span><span class="sc">% o</span><span class="st">f 300?&quot;</span>)</span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
I can use the calculator tool to find the answer to this question.

Action:
```json
{
  &quot;action&quot;: &quot;Calculator&quot;,
  &quot;action_input&quot;: &quot;25% of 300&quot;
}
```
Observation: Answer: 75.0
Thought:The answer is 75.0.
Final Answer: 75.0

&gt; Finished chain.





{&#39;input&#39;: &#39;What is the 25% of 300?&#39;, &#39;output&#39;: &#39;75.0&#39;}</code></pre>
<p><strong>Tom M. Mitchell的书</strong></p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> load_tools, initialize_agent</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> AgentType</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.python <span class="im">import</span> PythonREPL</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>tools <span class="op">=</span> load_tools(</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&quot;llm-math&quot;</span>,<span class="st">&quot;wikipedia&quot;</span>], </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    llm<span class="op">=</span>llm </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>agent<span class="op">=</span> initialize_agent(</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    tools,  </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    llm,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    agent<span class="op">=</span>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    handle_parsing_errors<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">True</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">&quot;Tom M. Mitchell is an American computer scientist </span><span class="ch">\</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="st">and the Founders University Professor at Carnegie Mellon University (CMU)</span><span class="ch">\</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="st">what book did he write?&quot;</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>agent(question) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
Thought: I can use Wikipedia to find out what book Tom M. Mitchell wrote.
Action:
```json
{
  &quot;action&quot;: &quot;Wikipedia&quot;,
  &quot;action_input&quot;: &quot;Tom M. Mitchell&quot;
}
```
Observation: Page: Tom M. Mitchell
Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.

Page: Tom Mitchell (Australian footballer)
Summary: Thomas Mitchell (born 31 May 1993) is a professional Australian rules footballer playing for the Collingwood Football Club in the Australian Football League (AFL). He previously played for the Adelaide Crows, Sydney Swans from 2012 to 2016, and the Hawthorn Football Club between 2017 and 2022. Mitchell won the Brownlow Medal as the league&#39;s best and fairest player in 2018 and set the record for the most disposals in a VFL/AFL match, accruing 54 in a game against Collingwood during that season.
Thought:The book that Tom M. Mitchell wrote is &quot;Machine Learning&quot;.
Final Answer: Machine Learning

&gt; Finished chain.





{&#39;input&#39;: &#39;Tom M. Mitchell is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU)what book did he write?&#39;,
 &#39;output&#39;: &#39;Machine Learning&#39;}</code></pre>
<p><strong>2. 使用LangChain内置工具PythonREPLTool</strong></p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents.agent_toolkits <span class="im">import</span> create_python_agent</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.tools.python.tool <span class="im">import</span> PythonREPLTool</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> create_python_agent(</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    llm,  <span class="co">#使用前面一节已经加载的大语言模型</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    tool<span class="op">=</span>PythonREPLTool(), <span class="co">#使用Python交互式环境工具（REPLTool）</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span> <span class="co">#输出中间步骤</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>customer_list <span class="op">=</span> [[<span class="st">&quot;Harrison&quot;</span>, <span class="st">&quot;Chase&quot;</span>], </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Lang&quot;</span>, <span class="st">&quot;Chain&quot;</span>],</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Dolly&quot;</span>, <span class="st">&quot;Too&quot;</span>],</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Elle&quot;</span>, <span class="st">&quot;Elem&quot;</span>], </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Geoff&quot;</span>,<span class="st">&quot;Fusion&quot;</span>], </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Trance&quot;</span>,<span class="st">&quot;Former&quot;</span>],</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>                 [<span class="st">&quot;Jen&quot;</span>,<span class="st">&quot;Ayai&quot;</span>]</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>agent.run(<span class="ss">f&quot;&quot;&quot;Sort these customers by </span><span class="ch">\</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="ss">last name and then first name </span><span class="ch">\</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="ss">and print the output: </span><span class="sc">{</span>customer_list<span class="sc">}</span><span class="ss">&quot;&quot;&quot;</span>) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.
Action: Python_REPL
Action Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))
Observation: 
Thought:The customers have been sorted by last name and then first name.
Final Answer: [[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]

&gt; Finished chain.





&quot;[[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]&quot;</code></pre>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> langchain</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>langchain.debug<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>agent.run(<span class="ss">f&quot;&quot;&quot;Sort these customers by </span><span class="ch">\</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="ss">last name and then first name </span><span class="ch">\</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="ss">and print the output: </span><span class="sc">{</span>customer_list<span class="sc">}</span><span class="ss">&quot;&quot;&quot;</span>) </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>langchain.debug<span class="op">=</span><span class="va">False</span></span></code></pre></div>
<pre><code>[chain/start] [1:chain:AgentExecutor] Entering Chain run with input:
{
  &quot;input&quot;: &quot;Sort these customers by last name and then first name and print the output: [[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]]&quot;
}
[chain/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] Entering Chain run with input:
{
  &quot;input&quot;: &quot;Sort these customers by last name and then first name and print the output: [[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]]&quot;,
  &quot;agent_scratchpad&quot;: &quot;&quot;,
  &quot;stop&quot;: [
    &quot;\nObservation:&quot;,
    &quot;\n\tObservation:&quot;
  ]
}
[llm/start] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] Entering LLM run with input:
{
  &quot;prompts&quot;: [
    &quot;Human: You are an agent designed to write and execute python code to answer questions.\nYou have access to a python REPL, which you can use to execute python code.\nIf you get an error, debug your code and try again.\nOnly use the output of your code to answer the question. \nYou might know the answer without running any code, but you should still run the code to get the answer.\nIf it does not seem like you can write code to answer the question, just return \&quot;I don&#39;t know\&quot; as the answer.\n\n\nPython_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Python_REPL]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: Sort these customers by last name and then first name and print the output: [[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]]\nThought:&quot;
  ]
}
[llm/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain &gt; 3:llm:ChatOpenAI] [4.59s] Exiting LLM run with output:
{
  &quot;generations&quot;: [
    [
      {
        &quot;text&quot;: &quot;I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.\nAction: Python_REPL\nAction Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))&quot;,
        &quot;generation_info&quot;: {
          &quot;finish_reason&quot;: &quot;stop&quot;
        },
        &quot;message&quot;: {
          &quot;lc&quot;: 1,
          &quot;type&quot;: &quot;constructor&quot;,
          &quot;id&quot;: [
            &quot;langchain&quot;,
            &quot;schema&quot;,
            &quot;messages&quot;,
            &quot;AIMessage&quot;
          ],
          &quot;kwargs&quot;: {
            &quot;content&quot;: &quot;I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.\nAction: Python_REPL\nAction Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))&quot;,
            &quot;additional_kwargs&quot;: {}
          }
        }
      }
    ]
  ],
  &quot;llm_output&quot;: {
    &quot;token_usage&quot;: {
      &quot;prompt_tokens&quot;: 328,
      &quot;completion_tokens&quot;: 112,
      &quot;total_tokens&quot;: 440
    },
    &quot;model_name&quot;: &quot;gpt-3.5-turbo&quot;
  },
  &quot;run&quot;: null
}
[chain/end] [1:chain:AgentExecutor &gt; 2:chain:LLMChain] [4.59s] Exiting Chain run with output:
{
  &quot;text&quot;: &quot;I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.\nAction: Python_REPL\nAction Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))&quot;
}
[tool/start] [1:chain:AgentExecutor &gt; 4:tool:Python_REPL] Entering Tool run with input:
&quot;sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))&quot;
[tool/end] [1:chain:AgentExecutor &gt; 4:tool:Python_REPL] [1.35ms] Exiting Tool run with output:
&quot;&quot;
[chain/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] Entering Chain run with input:
{
  &quot;input&quot;: &quot;Sort these customers by last name and then first name and print the output: [[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]]&quot;,
  &quot;agent_scratchpad&quot;: &quot;I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.\nAction: Python_REPL\nAction Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))\nObservation: \nThought:&quot;,
  &quot;stop&quot;: [
    &quot;\nObservation:&quot;,
    &quot;\n\tObservation:&quot;
  ]
}
[llm/start] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt; 6:llm:ChatOpenAI] Entering LLM run with input:
{
  &quot;prompts&quot;: [
    &quot;Human: You are an agent designed to write and execute python code to answer questions.\nYou have access to a python REPL, which you can use to execute python code.\nIf you get an error, debug your code and try again.\nOnly use the output of your code to answer the question. \nYou might know the answer without running any code, but you should still run the code to get the answer.\nIf it does not seem like you can write code to answer the question, just return \&quot;I don&#39;t know\&quot; as the answer.\n\n\nPython_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Python_REPL]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: Sort these customers by last name and then first name and print the output: [[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]]\nThought:I can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting order based on last name and then first name.\nAction: Python_REPL\nAction Input: sorted([[&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Dolly&#39;, &#39;Too&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Jen&#39;, &#39;Ayai&#39;]], key=lambda x: (x[1], x[0]))\nObservation: \nThought:&quot;
  ]
}
[llm/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain &gt; 6:llm:ChatOpenAI] [3.89s] Exiting LLM run with output:
{
  &quot;generations&quot;: [
    [
      {
        &quot;text&quot;: &quot;The customers have been sorted by last name and then first name.\nFinal Answer: [[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]&quot;,
        &quot;generation_info&quot;: {
          &quot;finish_reason&quot;: &quot;stop&quot;
        },
        &quot;message&quot;: {
          &quot;lc&quot;: 1,
          &quot;type&quot;: &quot;constructor&quot;,
          &quot;id&quot;: [
            &quot;langchain&quot;,
            &quot;schema&quot;,
            &quot;messages&quot;,
            &quot;AIMessage&quot;
          ],
          &quot;kwargs&quot;: {
            &quot;content&quot;: &quot;The customers have been sorted by last name and then first name.\nFinal Answer: [[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]&quot;,
            &quot;additional_kwargs&quot;: {}
          }
        }
      }
    ]
  ],
  &quot;llm_output&quot;: {
    &quot;token_usage&quot;: {
      &quot;prompt_tokens&quot;: 445,
      &quot;completion_tokens&quot;: 67,
      &quot;total_tokens&quot;: 512
    },
    &quot;model_name&quot;: &quot;gpt-3.5-turbo&quot;
  },
  &quot;run&quot;: null
}
[chain/end] [1:chain:AgentExecutor &gt; 5:chain:LLMChain] [3.89s] Exiting Chain run with output:
{
  &quot;text&quot;: &quot;The customers have been sorted by last name and then first name.\nFinal Answer: [[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]&quot;
}
[chain/end] [1:chain:AgentExecutor] [8.49s] Exiting Chain run with output:
{
  &quot;output&quot;: &quot;[[&#39;Jen&#39;, &#39;Ayai&#39;], [&#39;Harrison&#39;, &#39;Chase&#39;], [&#39;Lang&#39;, &#39;Chain&#39;], [&#39;Elle&#39;, &#39;Elem&#39;], [&#39;Geoff&#39;, &#39;Fusion&#39;], [&#39;Trance&#39;, &#39;Former&#39;], [&#39;Dolly&#39;, &#39;Too&#39;]]&quot;
}</code></pre>
<p><strong>3. 定义自己的工具并在代理中使用</strong></p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 导入tool函数装饰器</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> tool</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> date</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="at">@tool</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> time(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Returns todays date, use this for any </span><span class="ch">\</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co">    questions related to knowing todays date. </span><span class="ch">\</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">    The input should always be an empty string, </span><span class="ch">\</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">    and this function will always return todays </span><span class="ch">\</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">    date - any date mathmatics should occur </span><span class="ch">\</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">    outside this function.&quot;&quot;&quot;</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">str</span>(date.today())</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>agent<span class="op">=</span> initialize_agent(</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    tools <span class="op">+</span> [time], <span class="co">#将刚刚创建的时间工具加入到已有的工具中</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    llm, <span class="co">#初始化的模型</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    agent<span class="op">=</span>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  <span class="co">#代理类型</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    handle_parsing_errors<span class="op">=</span><span class="va">True</span>, <span class="co">#处理解析错误</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">True</span> <span class="co">#输出中间步骤</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>agent(<span class="st">&quot;whats the date today?&quot;</span>) </span></code></pre></div>
<pre><code>&gt; Entering new AgentExecutor chain...
Question: What&#39;s the date today?
Thought: I can use the `time` tool to get the current date.
Action:
```
{
  &quot;action&quot;: &quot;time&quot;,
  &quot;action_input&quot;: &quot;&quot;
}
```
Observation: 2023-08-09
Thought:I now know the final answer.
Final Answer: The date today is 2023-08-09.

&gt; Finished chain.





{&#39;input&#39;: &#39;whats the date today?&#39;, &#39;output&#39;: &#39;The date today is 2023-08-09.&#39;}</code></pre>
</body>
</html>
